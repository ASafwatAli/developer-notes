(window.webpackJsonp=window.webpackJsonp||[]).push([[267],{"./manual/Kubernetes/Advanced-Topics.md":function(e,n,t){"use strict";t.r(n),t.d(n,"default",function(){return i});var a=t("./node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/objectWithoutProperties.js"),o=(t("./node_modules/react/index.js"),t("./node_modules/@mdx-js/react/dist/index.es.js")),r={},l="wrapper";function i(e){var n=e.components,t=Object(a.a)(e,["components"]);return Object(o.b)(l,Object.assign({},r,t,{components:n,mdxType:"MDXLayout"}),Object(o.b)("h1",{id:"advanced-topics"},"Advanced Topics"),Object(o.b)("h2",{id:"service-discovery"},"Service Discovery"),Object(o.b)("p",null,"As of Kubernetes 1.3, DNS is a ",Object(o.b)("inlineCode",{parentName:"p"},"built-in")," service launched automatically using the addon manager."),Object(o.b)("p",null,"The addons are in the ",Object(o.b)("inlineCode",{parentName:"p"},"/etc/kubernetes/addons")," directory on the master node."),Object(o.b)("p",null,"The service can be used within pods to find other services running on the same cluster."),Object(o.b)("p",null,"Multiple containers within 1 pod don't need this service, as they can contact each other directly. A container in the same pod can just use ",Object(o.b)("inlineCode",{parentName:"p"},"localhost:port"),"."),Object(o.b)("p",null,"To make DNS work, a pod will need a ",Object(o.b)("inlineCode",{parentName:"p"},"service definition"),"."),Object(o.b)("p",null,"How can app 1 reach app 2 using DNS? The container itself can talk to the service of App 2."),Object(o.b)("p",null,"If you ran the host for ",Object(o.b)("inlineCode",{parentName:"p"},"app1-service")," and got back 10.0.0.1, ",Object(o.b)("inlineCode",{parentName:"p"},"host app2-service")," could get back 10.0.0.2."),Object(o.b)("p",null,"Examples from the CL"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-bash"}),"host app1-service\n# has addr 10.0.0.1\nhost app2-service\n# has addr 10.0.0.2\nhost app2-service.default\n# app2-service.default has address 10.0.0.2\nhost app2-service.default.svc.cluster.local\n# app2-service.default.svc.cluster.local has addr 10.0.0.2\n")),Object(o.b)("p",null,"The ",Object(o.b)("inlineCode",{parentName:"p"},"default")," stands for default namespace. Pods and services can be launched in different namespaces (to logically seperate your cluster)."),Object(o.b)("p",null,"So how does this resolution work?"),Object(o.b)("p",null,"Say we have a pod and we run ",Object(o.b)("inlineCode",{parentName:"p"},"kubectl run -i -tty busybox --image=busybox --restart=Never -- sh")," and the from the shell run ",Object(o.b)("inlineCode",{parentName:"p"},"cat /etc/resolv.conf"),", can can see that there will be a ",Object(o.b)("inlineCode",{parentName:"p"},"nameserver"),". If you do a lookup of the service name in this folder, you'll see why the above works with ",Object(o.b)("inlineCode",{parentName:"p"},".default")," and ",Object(o.b)("inlineCode",{parentName:"p"},".default.svc.whatever"),"."),Object(o.b)("h3",{id:"demo-service-discovery"},"Demo: Service Discovery"),Object(o.b)("p",null,"After creating a secrets type, pod type for a database (SQL using the secrets), and a service for exposing certain ports for the database and then deploying three replicas for a ",Object(o.b)("inlineCode",{parentName:"p"},"helloworld-deployment")," that also has a ",Object(o.b)("inlineCode",{parentName:"p"},"index-db.js")," file which we run ",Object(o.b)("inlineCode",{parentName:"p"},"node index-db.js")," which will have code that works on the service. The value of the ",Object(o.b)("inlineCode",{parentName:"p"},"MYSQL_HOST")," being set to ",Object(o.b)("inlineCode",{parentName:"p"},"database-service")," will resolve with the database-service.yml file where the metadata ",Object(o.b)("inlineCode",{parentName:"p"},"name")," is ",Object(o.b)("inlineCode",{parentName:"p"},"database-service"),"."),Object(o.b)("p",null,"Running ",Object(o.b)("inlineCode",{parentName:"p"},"kubectl get pod")," we should see the database plus 3 pods running for the deployment."),Object(o.b)("p",null,"Running ",Object(o.b)("inlineCode",{parentName:"p"},"kubectl logs [deployment-name]")," will also show us the logs for that pod."),Object(o.b)("p",null,"Again, remember that running ",Object(o.b)("inlineCode",{parentName:"p"},"kubectl get svc")," will get all the services available."),Object(o.b)("h2",{id:"configmap"},"ConfigMap"),Object(o.b)("p",null,"Config params that are not secret can be put in the ConfigMap."),Object(o.b)("p",null,"The input is again key-value pairs."),Object(o.b)("p",null,"The ",Object(o.b)("inlineCode",{parentName:"p"},"ConfigMap")," key-value pairs can then be read by the app using:"),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},"Env variables"),Object(o.b)("li",{parentName:"ol"},"Container commandline args in the Pod config"),Object(o.b)("li",{parentName:"ol"},"Using volumes")),Object(o.b)("p",null,"It can also contain full config files eg. a webserver config file. Then that file can then be mounted using volumes where the application expects its config file."),Object(o.b)("p",null,"This was you can ",Object(o.b)("inlineCode",{parentName:"p"},"inject")," config settings into containers without changing the container itself."),Object(o.b)("p",null,"To generate a configmap using files:"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-bash"}),"$ cat << EOF > app.properties\ndriver=jdbc\ndatabase=postgres\nlookandfeel=1\notherparams=xyz\nparam.with.hierarchy=xyz\nEOF\n$ kubectl create configmap app-config --from-file=app.properties\n")),Object(o.b)("p",null,"How to use it? You can create a pod that exposes the ConfigMap using a volume."),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"# pod-helloworld.yml w/ secrets\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nodehelloworld.example.com\n  labels:\n  app: helloworld\nspec:\n  # The containers are listed here\n  containers:\n  - name: k8s-demo\n  image: okeeffed/docker-demo\n  ports:\n  - containerPort: 3000\n  # @@@ This are the envs in a volume mount\n  volumeMounts:\n  - name: credvolume\n    mountPath: /etc/creds\n    readOnly: true\n  # @@@ For the ConfigMap\n  - name: config-volume\n    mountPath: /etc/config\n  volumes:\n  - name: credvolume\n  secret:\n    secretName: db-secrets\n  # @@@ For the ConfigMap\n  - name: config-volume\n  configMap:\n    name: app-config\n")),Object(o.b)("p",null,"From ",Object(o.b)("inlineCode",{parentName:"p"},"/etc/config")," , the config values will be stored in files at ",Object(o.b)("inlineCode",{parentName:"p"},"/etc/config/driver")," and ",Object(o.b)("inlineCode",{parentName:"p"},"/etc/config/param/with/hierarchy"),"."),Object(o.b)("p",null,"This is an example of a pod that exposes the ConfigMap as env variables:"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"# pod-helloworld.yml w/ secrets\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nodehelloworld.example.com\n  labels:\n  app: helloworld\nspec:\n  # The containers are listed here\n  containers:\n  - name: k8s-demo\n  image: okeeffed/docker-demo\n  ports:\n  - containerPort: 3000\n  # @@@ This are the envs in a volume mount\n  env:\n  - name: DRIVER\n    valueFrom: # where you get the value from\n    configMapKeyRef: # ensuring the ref comes from the configMap\n    name: app-config\n    key: driver\n  - name: DATABASE\n  [ ... ]\n")),Object(o.b)("h3",{id:"demo-config-map"},"Demo: Config Map"),Object(o.b)("p",null,"Using an example for a reverse proxy config for NGINX:"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{}),"server {\n  listen  80;\n  server_name localhost;\n\n  location / {\n  proxy_bind 127.0.0.1;\n  proxy_pass http://127.0.0.1:3000;\n  }\n\n  error_page  500 502 503 504 /50x.html;\n  location = /50x.html {\n  root    /usr/share/nginx/html;\n  }\n}\n")),Object(o.b)("p",null,"We could then create this config map with ",Object(o.b)("inlineCode",{parentName:"p"},"kubectl create configmap nginx-config --from-file=reverseproxy.conf"),"."),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"# pod-helloworld.yml w/ secrets\napiVersion: v1\nkind: Pod\nmetadata:\n  name: hellonginx.example.com\n  labels:\n  app: hellonginx\nspec:\n  # The containers are listed here\n  containers:\n    - name: nginx\n    image: nginx:1.11\n    ports:\n    - containerPort: 80\n    # @@@ The import conf stuff\n    volumeMounts:\n    - name: config-volume\n        mountPath: /etc/nginx/conf.d\n  - name: k8s-demo\n  image: okeeffed/docker-demo\n  ports:\n    - containerPort: 3000\n  # @@@ The important mounting\n  volumes:\n    - name: config-volume # @@@ this is referred to above in volumeMounts\n    configMap:\n        name: nginx-config\n        items:\n        - key: reverseproxy.conf\n        path: reverseproxy.conf\n")),Object(o.b)("p",null,"After then also creating the service, we can grab the minikube service url and use curl to get info on that request. From here, would could see that it is ",Object(o.b)("inlineCode",{parentName:"p"},"nginx")," answer the request and transferring it to the Node port."),Object(o.b)("p",null,"If we then want to jump into the nginx container to see what is going on, we can run ",Object(o.b)("inlineCode",{parentName:"p"},"kubectl exec -i -t helloworld-nginx -c nginx -- bash")," (-c flag to specify container) and run ",Object(o.b)("inlineCode",{parentName:"p"},"ps x")," to see the processes and we can ",Object(o.b)("inlineCode",{parentName:"p"},"cat /etc/nginx/conf.d/reverseproxy.conf"),"."),Object(o.b)("p",null,"At this stage, we can enable SSL for NGINX."),Object(o.b)("h2",{id:"ingress-controller"},"Ingress Controller"),Object(o.b)("p",null,"Ingress a solution since Kub 1.1 that allows inbound connections to the cluster."),Object(o.b)("p",null,"It's an alternative to the external ",Object(o.b)("inlineCode",{parentName:"p"},"LoadBalancer")," and ",Object(o.b)("inlineCode",{parentName:"p"},"nodePorts"),". It allows you to easily expose services that need to be accessible from outside to the cluster."),Object(o.b)("p",null,"With ingress you can run your own ingress controller (basically a loudbalancer) within the Kub Cluster."),Object(o.b)("p",null,"There are default ingress controller available, or you can write your own ingress controller."),Object(o.b)("p",null,"How does it work? If you connect over 80/443 you will first hit the ",Object(o.b)("inlineCode",{parentName:"p"},"Ingress Controller"),". You can use the NGINX controller that comes with Kubernetes. That controller will the dirrect all the traffic."),Object(o.b)("p",null,"The ",Object(o.b)("inlineCode",{parentName:"p"},"ingress rules")," could define that if you go to ",Object(o.b)("inlineCode",{parentName:"p"},"host-x.example.com")," you go to ",Object(o.b)("inlineCode",{parentName:"p"},"Pod 1")," etc. You can even redirect slash URLs specifically."),Object(o.b)("p",null,"To create an Ingress Controller:"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"# ingress-controller.yml w/ secrets\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: helloworld-rules\nspec:\n  # @@@ Setting the important rules\n  rules:\n    - host: helloworld-v1.example.com\n      http:\n        paths:\n          - path: /\n          backend:\n            serviceName: helloworld-v1\n            servicePort: 80\n    - host: helloworld-v2.example.com\n      http:\n        paths:\n          - path: /\n          backend:\n            serviceName: helloworld-v2\n            servicePort: 80\n")),Object(o.b)("h3",{id:"demo-ingress-controller"},"Demo: Ingress Controller"),Object(o.b)("p",null,"In the example, the ingress controller is a ",Object(o.b)("inlineCode",{parentName:"p"},"Replication Controller")," to ensure that there is always one up and running."),Object(o.b)("p",null,"After deploying, if we curl with the -H host flag with ",Object(o.b)("inlineCode",{parentName:"p"},"helloworld-v1.whatever.com")," and v2 respectively, it would have the ingress controller route to each server."),Object(o.b)("h2",{id:"external-dns"},"External DNS"),Object(o.b)("p",null,"On public cloud providers, you can use the ingress controller to ",Object(o.b)("strong",{parentName:"p"},"reduce the cost of your LoadBalancers"),"."),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"You could use 1 LoadBalancer that captures all the external traffic and send it to the ingress controller."),Object(o.b)("li",{parentName:"ul"},"IngCont can be configured to route the different traffic to all your apps based on HTTP rules."),Object(o.b)("li",{parentName:"ul"},"Only works for HTTP(s)-based apps")),Object(o.b)("p",null,"The External DNS tool will automatically create the necessary DNS records in your external DNS server (like route53)."),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"For every hostname used in ingress, it'll create a new record to send traffic to load balancer."),Object(o.b)("li",{parentName:"ul"},"The major DNS providers are supported: Route53, Google CloudDNS, CloudFlare etc.")),Object(o.b)("p",null,Object(o.b)("img",{alt:"Diagram",src:"https://res.cloudinary.com/gitgoodclub/image/upload/v1539998347/Screen_Shot_2018-10-20_at_12.18.14_pm.png"})),Object(o.b)("h2",{id:"volumes"},"Volumes"),Object(o.b)("p",null,"How can we run stateful apps?"),Object(o.b)("p",null,"Volumes in kubernetes allow you to store data outside of the container. So far, all the applications have been stateless for this reason. This can be done with external services like a database, caching server (eg MySQL, AWS S3)."),Object(o.b)("p",null,"Persistent Volumes in Kubernetes allow you to attach a volume to a container that exists even when the container stops. Volumes can be attached using different volume plugins. Eg local volume, EBS Storage etc."),Object(o.b)("h3",{id:"using-ebs-storage"},"Using EBS Storage"),Object(o.b)("p",null,"With this, we can keep state. You could run a ",Object(o.b)("inlineCode",{parentName:"p"},"MySQL")," database using persistent volumes, although this may not be ready for production yet."),Object(o.b)("p",null,"The use case is that if your node stops working, the pod can be rescheduled on another node, and the volume can be attached to the new node."),Object(o.b)("p",null,"To use volumes, you first need to create the volume:"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-bash"}),"aws ec2 create-volume --sze 1- --region us-east-1 --availability-zone us-east-1 --volume-type gp2\n")),Object(o.b)("p",null,"Next, we need to create a pod with a volume def:"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"# pod-helloworld.yml w/ secrets\napiVersion: v1\nkind: Pod\nmetadata:\n  name: hellonginx.example.com\n  labels:\n  app: hellonginx\nspec:\n  # The containers are listed here\n  containers:\n    - name: k8s-demo\n    image: okeeffed/k8s-demo\n    volumeMounts:\n    - name: myvolume\n      mountPath: myvolume\n  # @@@ The important mounting\n  volumes:\n    - name: myvolume # @@@ this is referred to above in volumeMounts\n      awsElasticBlockStore:\n        volumeID: vol-9835id\n")),Object(o.b)("h3",{id:"demo-volumes"},"Demo: Volumes"),Object(o.b)("p",null,"Using Vagrant for kops, we can first create a volume using the above mentioned command."),Object(o.b)("p",null,"After receiving a response, you can replace the .yml pod definition config file to attach that volumeID. Once the deployment is created and deployed. "),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"After create and confirmation, we can get the pod name ",Object(o.b)("inlineCode",{parentName:"li"},"kubectl get pod")," and attach ",Object(o.b)("inlineCode",{parentName:"li"},"kubectl exec helloworld-deployment-923id -i -t -- bash")," and then run ",Object(o.b)("inlineCode",{parentName:"li"},"ls -ahl /myvol/")," to check for volume."),Object(o.b)("li",{parentName:"ul"},"If we run ",Object(o.b)("inlineCode",{parentName:"li"},"echo 'test' > /myvol/myvol.txt")," and ",Object(o.b)("inlineCode",{parentName:"li"},"echo 'test 2' > /test.txt"),", we know that the latter file will not persist if the pod is restarted/rescheduled."),Object(o.b)("li",{parentName:"ul"},"If we run ",Object(o.b)("inlineCode",{parentName:"li"},"kubectl drain ip --force")," we can drain the pod. Assuming this is a ",Object(o.b)("inlineCode",{parentName:"li"},"Replication Controller")," or ",Object(o.b)("inlineCode",{parentName:"li"},"Deployment"),", another container should spin up."),Object(o.b)("li",{parentName:"ul"},"Once that pod is attached to another node, we can also attach back to the pod on the new node with the ",Object(o.b)("inlineCode",{parentName:"li"},"exec")," command and we can confirm that the ",Object(o.b)("inlineCode",{parentName:"li"},"/myvol/myvol.txt")," is still there, although the other ",Object(o.b)("inlineCode",{parentName:"li"},"/test.txt")," is no longer there since it was not saved to the volume.")),Object(o.b)("p",null,"If you need to remove the ebs volume, you can run ",Object(o.b)("inlineCode",{parentName:"p"},"aws ec2 delete-volume --volume-id vol-[id]"),"."),Object(o.b)("h2",{id:"volume-provisioning"},"Volume Provisioning"),Object(o.b)("p",null,"The kubs plugins have the capability to ",Object(o.b)("inlineCode",{parentName:"p"},"provision storage")," for you. The AWS Plugin can for instance ",Object(o.b)("inlineCode",{parentName:"p"},"provision storage")," for you by creating the volumes in AWS before attaching them to a node."),Object(o.b)("p",null,"This is done using the ",Object(o.b)("inlineCode",{parentName:"p"},"StorageClass")," object -- this is beta for the course but should be stable soon."),Object(o.b)("p",null,"To use autoprovisioing, create the following:"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"# storage.yml\nkind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n  name: standard\nprovisioner: kubernetes.io/aws-ebs\nparameters:\n  type: gp2\n  zone: ap-southeast-1\n")),Object(o.b)("p",null,"Next, you can create a volume claim and specify the size:"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),'# my-volume-claim.yml\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: myclaim\n  annotations:\n    volume.beta.kubernetes.io/storage-class: "standard"\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 8Gi\n')),Object(o.b)("p",null,"Finally, if launching a pod:"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"# pod-helloworld.yml w/ secrets\napiVersion: v1\nkind: Pod\nmetadata:\n  name: mypod\nspec:\n  # The containers are listed here\n  containers:\n    - name: myfrontend\n    image: nginx\n    volumeMounts:\n    - name: mypd\n      mountPath: '/var/www/html'\n  # @@@ The important mounting\n  volumes:\n    - name: mypd # @@@ this is referred to above in volumeMounts\n      persistentVolumeClaim:\n        claimName: myclaim # @@@ refers to my claim from the previous type definition\n")),Object(o.b)("h2",{id:"demo-using-wordpress-with-volumes"},"Demo: Using Wordpress with Volumes"),Object(o.b)("p",null,"After declaring a ",Object(o.b)("inlineCode",{parentName:"p"},"StorageClass")," class from a yaml file and a ",Object(o.b)("inlineCode",{parentName:"p"},"PersistentVolumeClaim")," class."),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"# storage.yml\nkind: StorageClass\napiVersion: storage.k8s.io/v1beta1\nmetadata:\n  name: standard\nprovisioner: kubernetes.io/aws-ebs\nparameters:\n  type: gp2\n  zone: eu-west-1a\n")),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),'# PV Claim\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: db-storage\n  annotations:\n    volume.beta.kubernetes.io/storage-class: "standard"\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 8Gi\n')),Object(o.b)("p",null,"There is also a simple ReplicationController for the Wordpress DB. In the spe for the container for mysql, we declare where the ",Object(o.b)("inlineCode",{parentName:"p"},"mountPath")," will be."),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),'apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: wordpress-db\nspec:\n  replicas: 1\n  selector:\n    app: wordpress-db\n  template:\n    metadata:\n      name: wordpress-db\n      labels:\n        app: wordpress-db\n    spec:\n      containers:\n      - name: mysql\n        image: mysql:5.7\n        args:\n          - "--ignore-db-dir=lost+found"\n        ports:\n        - name: mysql-port\n          containerPort: 3306\n        env:\n          - name: MYSQL_ROOT_PASSWORD\n            valueFrom:\n              secretKeyRef:\n                name: wordpress-secrets\n                key: db-password\n        volumeMounts:\n        - mountPath: "/var/lib/mysql"\n          name: mysql-storage\n      volumes:\n        - name: mysql-storage\n          persistentVolumeClaim:\n            claimName: db-storage\n')),Object(o.b)("p",null,"Having a makeshift secrets file for secrets:"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"apiVersion: v1\nkind: Secret\nmetadata:\n  name: wordpress-secrets\ntype: Opaque\ndata:\n  db-password: cGFzc3dvcmQ=\n  # random sha1 strings - change all these lines\n  authkey: MTQ3ZDVhMTIzYmU1ZTRiMWQ1NzUyOWFlNWE2YzRjY2FhMDkyZGQ4OA==\n  loggedinkey: MTQ3ZDVhMTIzYmU1ZTRiMWQ1NzUyOWFlNWE2YzRjY2FhMDkyZGQ4OQ==\n  secureauthkey: MTQ3ZDVhMTIzYmU1ZTRiMWQ1NzUyOWFlNWE2YzRjY2FhMDkyZGQ5MQ==\n  noncekey: MTQ3ZDVhMTIzYmU1ZTRiMWQ1NzUyOWFlNWE2YzRjY2FhMDkyZGQ5MA==\n  authsalt: MTQ3ZDVhMTIzYmU1ZTRiMWQ1NzUyOWFlNWE2YzRjY2FhMDkyZGQ5Mg==\n  secureauthsalt: MTQ3ZDVhMTIzYmU1ZTRiMWQ1NzUyOWFlNWE2YzRjY2FhMDkyZGQ5Mw==\n  loggedinsalt: MTQ3ZDVhMTIzYmU1ZTRiMWQ1NzUyOWFlNWE2YzRjY2FhMDkyZGQ5NA==\n  noncesalt: MTQ3ZDVhMTIzYmU1ZTRiMWQ1NzUyOWFlNWE2YzRjY2FhMDkyZGQ5NQ==\n")),Object(o.b)("p",null,"To open up the service for the port:"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"apiVersion: v1\nkind: Service\nmetadata:\n  name: wordpress-db\nspec:\n  ports:\n  - port: 3306\n    protocol: TCP\n  selector:\n    app: wordpress-db\n  type: NodePort\n")),Object(o.b)("p",null,"Opening up the web and web service:"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: wordpress-deployment\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: wordpress\n    spec:\n      containers:\n      - name: wordpress\n        image: wordpress:4-php7.0\n        # uncomment to fix perm issue, see also https://github.com/kubernetes/kubernetes/issues/2630\n        # command: ['bash', '-c', 'chown www-data:www-data /var/www/html/wp-content/uploads && apache2-foreground']\n        ports:\n        - name: http-port\n          containerPort: 80\n        env:\n          - name: WORDPRESS_DB_PASSWORD\n            valueFrom:\n              secretKeyRef:\n                name: wordpress-secrets\n                key: db-password\n          - name: WORDPRESS_AUTH_KEY\n            valueFrom:\n              secretKeyRef:\n                name: wordpress-secrets\n                key: authkey\n          - name: WORDPRESS_LOGGED_IN_KEY\n            valueFrom:\n              secretKeyRef:\n                name: wordpress-secrets\n                key: loggedinkey\n          - name: WORDPRESS_SECURE_AUTH_KEY\n            valueFrom:\n              secretKeyRef:\n                name: wordpress-secrets\n                key: secureauthkey\n          - name: WORDPRESS_NONCE_KEY\n            valueFrom:\n              secretKeyRef:\n                name: wordpress-secrets\n                key: noncekey\n          - name: WORDPRESS_AUTH_SALT\n            valueFrom:\n              secretKeyRef:\n                name: wordpress-secrets\n                key: authsalt\n          - name: WORDPRESS_SECURE_AUTH_SALT\n            valueFrom:\n              secretKeyRef:\n                name: wordpress-secrets\n                key: secureauthsalt\n          - name: WORDPRESS_LOGGED_IN_SALT\n            valueFrom:\n              secretKeyRef:\n                name: wordpress-secrets\n                key: loggedinsalt\n          - name: WORDPRESS_NONCE_SALT\n            valueFrom:\n              secretKeyRef:\n                name: wordpress-secrets\n                key: noncesalt\n          - name: WORDPRESS_DB_HOST\n            value: wordpress-db\n        volumeMounts:\n        # shared storage for things like media\n        - mountPath: /var/www/html/wp-content/uploads\n          name: uploads\n      volumes:\n      - name: uploads\n        nfs:\n          server: eu-west-1a.fs-5714e89e.efs.eu-west-1.amazonaws.com\n          path: /\n")),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"apiVersion: v1\nkind: Service\nmetadata:\n  name: wordpress\nspec:\n  ports:\n  - port: 80\n    targetPort: http-port\n    protocol: TCP\n  selector:\n    app: wordpress\n  type: LoadBalancer\n")),Object(o.b)("p",null,"With the AWS Commandline, you can create a file system and mount target. For the fs, run ",Object(o.b)("inlineCode",{parentName:"p"},"aws efs create-file-system --creation-token")," and then after grabbing the file-system-id and subnet-id, you can run ",Object(o.b)("inlineCode",{parentName:"p"},"aws efs create-mount-target --file-system-id <id> --security-groups <sg>"),". Ensure in the above ",Object(o.b)("inlineCode",{parentName:"p"},"nfs")," volume you update the fs id."),Object(o.b)("h2",{id:"pod-presets"},"Pod Presets"),Object(o.b)("p",null,"Pod presets can inject information into pods at runtime."),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Used to inject Kubernetes Resources like Secrets, ConfigMaps, Volumes and Environment variables. ")),Object(o.b)("p",null,"Imagine you have 20 apps to deploy, all with a specific credential. You can edit the 20 specs and add the creds, or you can use presets to create 1 ",Object(o.b)("strong",{parentName:"p"},"Preset Object"),", which will ",Object(o.b)("strong",{parentName:"p"},"inject an environment variable or config file to all matching pods.")),Object(o.b)("p",null,"When injecting env vars and volume mounts, the Pod Preset will apply the changes to ll containers within the pod."),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"# PodPreset File\napiVersion: settings.k8s.io/v1alpha1\nkind: PodPreset\nmetadata:\n  name: allow-database\nspec:\n  selector:\n    matchLabels:\n      role: frontend\n  env:\n    - name: DB_PORT\n      value: '6379'\n  volumeMounts:\n    - mountPath: /cache\n      name: cache-volume\n  volumes:\n    - name: cache-volume\n      emptyDir: {}\n")),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yml"}),"# Pod file using PodPreset\napiVersion: v1\nkind: Pod\nmetadata:\n  name: website\n  labels:\n    app: website\n    role: frontend\nspec:\n  containers:\n    - name: website\n      image: nginx\n      ports:\n        - containerPort: 80\n")),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-bash"}),"$ kubectl create -f pod-preset.yml\n$ kubectl create -f pod.yml\n")),Object(o.b)("h2",{id:"stateful-sets---formerly-pet-sets"},"Stateful Sets - (formerly Pet Sets)"),Object(o.b)("p",null,"Stateful dist apps - new feature from Kub 1.3."),Object(o.b)("p",null,"It is introduced to be able to run ",Object(o.b)("inlineCode",{parentName:"p"},"stateful applications")," that need:"),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},"A stable pod hostname (instead of podname-randomstr) - will have an index ie podname-0, podname-1 etc."),Object(o.b)("li",{parentName:"ol"},"Stateful app requires multi pods with vols based on their ordinal number. Currently deleting and/or scaling a PetSet down will not deleted volumes associated.")),Object(o.b)("p",null,"A pet set will allow your stateful app to use DNS to find out peers. One running node of the Pet Set is called a ",Object(o.b)("inlineCode",{parentName:"p"},"Pet"),". Using Pet Sets you can run for instance 5 cassandra nodes on Kubs named cass-1 until cass-5."),Object(o.b)("p",null,"The big difference is that you don't want to connect just any specific service, you want to make sure pod whatever definitely connects to another pod."),Object(o.b)("p",null,"This pet set also allows order to startup and teardown of pets."),Object(o.b)("p",null,"Still a lot of work for future work."),Object(o.b)("h2",{id:"daemon-sets"},"Daemon Sets"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Ensure that every single node in the Kubernetes cluster runs the same pod resource. This is useful to ensure a certain pod is running on every single kubernetes node."),Object(o.b)("li",{parentName:"ul"},"When a node is added to the cluster, a new pod will be started automatically"),Object(o.b)("li",{parentName:"ul"},"Same when a node is removed, the pod will not be rescheduled on another node")),Object(o.b)("p",null,"Use cases:"),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},"Logging aggregators"),Object(o.b)("li",{parentName:"ol"},"Monitoring"),Object(o.b)("li",{parentName:"ol"},"Load Balancers/Reverse Proxies/API Gateways")),Object(o.b)("h2",{id:"resource-usage-monitoring"},"Resource Usage Monitoring"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Heapster enables ",Object(o.b)("strong",{parentName:"li"},"Container Cluster Monitoring")," and ",Object(o.b)("strong",{parentName:"li"},"Performance Analysis"),"."),Object(o.b)("li",{parentName:"ul"},"It's providing a monitoring platform for Kubernetes."),Object(o.b)("li",{parentName:"ul"},"It's a prerequisite if you want to do ",Object(o.b)("strong",{parentName:"li"},"pod auto-scaling")," in Kubernetes."),Object(o.b)("li",{parentName:"ul"},"Heapster exports cluster metrix ",Object(o.b)("strong",{parentName:"li"},"via REST endpoints"),"."),Object(o.b)("li",{parentName:"ul"},"You can use different backends with Heapster.",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"Demo uses ",Object(o.b)("strong",{parentName:"li"},"InfluxDB"),", but Kafka is also possible."))),Object(o.b)("li",{parentName:"ul"},"Visualisations can be shown with Grafana. ",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"Kubernetes dashboard will also show graphs once monitoring is enabled."))),Object(o.b)("li",{parentName:"ul"},"All these technologies can be started in pods"),Object(o.b)("li",{parentName:"ul"},"The ",Object(o.b)("strong",{parentName:"li"},"yaml files")," can be found on the github repo of Heapster.")),Object(o.b)("p",null,"Since Heapster is now deprecated, you would have to use ",Object(o.b)("inlineCode",{parentName:"p"},"metrics-server")," or an alternative like ",Object(o.b)("strong",{parentName:"p"},"Prometheus"),"."),Object(o.b)("h2",{id:"horiztonal-pod-autoscaling"},"Horiztonal Pod Autoscaling"),Object(o.b)("p",null,Object(o.b)("a",Object.assign({parentName:"p"},{href:"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/"}),"Link to main Kubernetes site")),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Kubernetes has the possibility to autoscale pods based on metrics.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Kubernetes can autoscale Deployment, Replication Controller or ReplicaSet.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"In Kubernetes 1.3 ",Object(o.b)("strong",{parentName:"p"},"scaling based on CPU")," usage is possible out of the box."),Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"Application based metrics are also available (like queries per second or average request latency).",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"To enable, the cluster has to be started with env var ENABLE_CUSTOM_METRICS to be true."))))),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"It will periodically query the utilization for the targeted pods."),Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"By default 30 sec, can be changed using the ",Object(o.b)("inlineCode",{parentName:"li"},"--horizontal-pod-autoscaler-sync-period"),"flag when launching the controller manager."))),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Requires the metrics system to work."))),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"apiVersion: autoscaling/v1\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: hpa-example-autoscaler\nspec:\n  scaleTargetRef:\n    apiVersion: extensions/v1beta1\n    kind: Deployment\n    name: hpa-example\n  minReplicas: 1\n  maxReplicas: 10\n  targetCPUUtilizationPercentage: 50\n")),Object(o.b)("h2",{id:"affinityanti-affinity"},"Affinity/Anti-Affinity"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"The affinity/anti-affinity feature allows you to do ",Object(o.b)("strong",{parentName:"li"},"more complex scheduling")," than the nodeSelector and also ",Object(o.b)("strong",{parentName:"li"},"works on Pods"),".",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"The language is ",Object(o.b)("strong",{parentName:"li"},"more expressive"),"."),Object(o.b)("li",{parentName:"ul"},"You can create ",Object(o.b)("strong",{parentName:"li"},"rules that are not hard requirements"),", but rather a ",Object(o.b)("strong",{parentName:"li"},"preferred rule"),", meaning that the scheduler will stil be able to schedule your pod, even if the rules cannot be met."),Object(o.b)("li",{parentName:"ul"},"You can create rules to take other pod labels into account",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"Example, you can make sure two different pods are never on the same node."))))),Object(o.b)("li",{parentName:"ul"},"Kubernetes can do ",Object(o.b)("strong",{parentName:"li"},"node affinity")," and ",Object(o.b)("strong",{parentName:"li"},"pod affinity/anti-affinity"),".",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"Node affinity is similar to the nodeSelector."),Object(o.b)("li",{parentName:"ul"},"Pod affinity/anti-affinity allows you to create rules ",Object(o.b)("strong",{parentName:"li"},"how pods should be scheduled taking into account other running pods"),"."),Object(o.b)("li",{parentName:"ul"},"Affinity/anti-affinity mechanism is only relevant during scheduling, once a pod is running, it'll need to be recreated to apply the rules again."))),Object(o.b)("li",{parentName:"ul"},"There are currently 2 types you can use for node affinity:",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"1) requiredDuringSchedulingIgnoredDuringExecution"),Object(o.b)("li",{parentName:"ul"},"2) preferredDuringSchedulingIgnoredDuringExecution"))),Object(o.b)("li",{parentName:"ul"},"The ",Object(o.b)("strong",{parentName:"li"},"first one")," sets a ",Object(o.b)("strong",{parentName:"li"},"hard requirement")," (like the nodeSelector).",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"The rules must be met before the pod can be scheduled."))),Object(o.b)("li",{parentName:"ul"},"The ",Object(o.b)("strong",{parentName:"li"},"second type")," will try to enforce the rule, but it will not guarantee it.",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"Even if the rule is not met, the pod can still be scheduled, it's a soft requirement, a preference.")))),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),"apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: <% helloworld-deployment %>\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: <% app_name %>\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n              - matchExpressions:\n                  - key: env\n                    operator: In\n                    values:\n                      - dev\n          preferredDuringSchedulingIgnoredDuringExecution:\n            - weight: 1 # higher the weighting, the more emphasis on rule\n              preference:\n                matchExpressions:\n                  - key: team\n                    operator: In\n                    values:\n                      - engineering-project1\n      containers:\n        - name: k8s-demo\n          image: <% image_name %>\n          port:\n            - containerPort: 3000\n")),Object(o.b)("p",null,"When scheduling, Kubernetes will score every node by summarizing the weightings per node."),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Eg two different rules with weights 1and 5.",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"If both rules match, score 6."),Object(o.b)("li",{parentName:"ul"},"If only rule with weight 1 matches, score 1."))),Object(o.b)("li",{parentName:"ul"},"The node that has the highest total score, that's where the pod will be scheduled on.")),Object(o.b)("h2",{id:"313-interpod-affinityanti-affinity"},"3.13 Interpod Affinity/Anti-Affinity"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"This allows you to influence scheduling based on the labels of other pods that are ",Object(o.b)("strong",{parentName:"li"},"already running")," on the cluster."),Object(o.b)("li",{parentName:"ul"},"Pods belong to a namespace, so rules apply to namespace (default to pod name).")),Object(o.b)("p",null,"Two types:"),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},"requiredDuringSchedulingIgnoredDuringExecution"),Object(o.b)("li",{parentName:"ol"},"preferredDuringSchedulingIgnoredDuringExecution")),Object(o.b)("p",null,'The required type create rules that must be met for the pod to be scheduled, the preferred type is a "soft" type and the rules may be met.'),Object(o.b)("p",null,"A good use case for ",Object(o.b)("strong",{parentName:"p"},"pod affinity is co-located pods"),"."),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Example, you have an app that uses redis as cache and you want to have the Redis pod on the same node as the app itself."),Object(o.b)("li",{parentName:"ul"},"Another use-case is to co-locate pods within the ",Object(o.b)("strong",{parentName:"li"},"same availability zone"),"."),Object(o.b)("li",{parentName:"ul"},"When writing your pod affinity and anti-affinity rules, you need to specify a ",Object(o.b)("strong",{parentName:"li"},"topology domain"),", called ",Object(o.b)("strong",{parentName:"li"},"topologyKey")," in the rules.",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"Key refers to a node label."),Object(o.b)("li",{parentName:"ul"},"If affinity rule matches, ",Object(o.b)("strong",{parentName:"li"},"new pod")," will only be scheduled on ",Object(o.b)("strong",{parentName:"li"},"nodes")," that have the ",Object(o.b)("strong",{parentName:"li"},"same topologyKey")," value as the ",Object(o.b)("strong",{parentName:"li"},"current running pod"),".")))),Object(o.b)("p",null,Object(o.b)("img",{alt:"Interpod Affinity and anti-affinity",src:"https://res.cloudinary.com/gitgoodclub/image/upload/v1540165720/Screen_Shot_2018-10-22_at_10.48.04_am.png"})),Object(o.b)("p",null,Object(o.b)("img",{alt:"Zone topology",src:"https://res.cloudinary.com/gitgoodclub/image/upload/v1540165853/Screen_Shot_2018-10-22_at_10.50.27_am.png"})),Object(o.b)("h3",{id:"anti-affinity"},"Anti-affinity"),Object(o.b)("p",null,"You can use anti-affinity to make sure a ",Object(o.b)("strong",{parentName:"p"},"pod is only scehduled once on a node"),"."),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Example 3 nodes and you want to schedule 2 pods but they shouldn't be on the same node."),Object(o.b)("li",{parentName:"ul"},"Pod anti-affinity allows you to create a rule that say to ",Object(o.b)("strong",{parentName:"li"},"not schedule on the same host if a pod label matches"),".")),Object(o.b)("p",null,Object(o.b)("img",{alt:"Anti-affinity",src:"https://res.cloudinary.com/gitgoodclub/image/upload/v1540165853/Screen_Shot_2018-10-22_at_10.50.27_am.png"})),Object(o.b)("h3",{id:"topology-operators"},"Topology operators"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"In"),Object(o.b)("li",{parentName:"ul"},"NotIn"),Object(o.b)("li",{parentName:"ul"},"Exists"),Object(o.b)("li",{parentName:"ul"},"DoesNotExist")),Object(o.b)("p",null,"Affinity requires a substantial amount of processor. Take this into account if you have a lot of rules."),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),'# pod-affinity.yml\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: pod-affinity-1\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pod-affinity-1\n    spec:\n      containers:\n      - name: k8s-demo\n        image: wardviaene/k8s-demo\n        ports:\n        - name: nodejs-port\n          containerPort: 3000\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: pod-affinity-2\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pod-affinity-2\n    spec:\n      affinity:\n        podAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            - labelSelector:\n                matchExpressions:\n                  - key: "app"\n                    operator: In\n                    values:\n                    - pod-affinity-1\n              topologyKey: "kubernetes.io/hostname" # this could be change for zoning\n      containers:\n      - name: redis\n        image: redis\n        ports:\n        - name: redis-port\n          containerPort: 6379\n')),Object(o.b)("p",null,"We can then check this is fine by running ",Object(o.b)("inlineCode",{parentName:"p"},"kubectl get pod -o wide")," to see the Node the pods are running on."),Object(o.b)("p",null,"As for anti-affinity:"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: pod-affinity-1\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pod-affinity-1\n    spec:\n      containers:\n      - name: k8s-demo\n        image: wardviaene/k8s-demo\n        ports:\n        - name: nodejs-port\n          containerPort: 3000\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: pod-affinity-2\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: pod-affinity-2\n    spec:\n      affinity:\n        podAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            - labelSelector:\n                matchExpressions:\n                  - key: "app"\n                    operator: In\n                    values:\n                    - pod-affinity-1\n              topologyKey: "kubernetes.io/hostname"\n      containers:\n      - name: redis\n        image: redis\n        ports:\n        - name: redis-port\n          containerPort: 6379\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: pod-affinity-3\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: pod-affinity-3\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            - labelSelector:\n                matchExpressions:\n                  - key: "app"\n                    operator: In\n                    values:\n                    - pod-affinity-1\n              topologyKey: "kubernetes.io/hostname"\n      containers:\n      - name: k8s-demo\n        image: wardviaene/k8s-demo\n        ports:\n        - name: nodejs-port\n          containerPort: 3000\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: pod-affinity-4\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pod-affinity-4\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            - labelSelector:\n                matchExpressions:\n                  - key: "app"\n                    operator: In\n                    values:\n                    - pod-affinity-1\n                    - pod-affinity-3\n              topologyKey: "kubernetes.io/hostname"\n      containers:\n      - name: k8s-demo\n        image: wardviaene/k8s-demo\n        ports:\n        - name: nodejs-port\n          containerPort: 3000\n---\n')),Object(o.b)("p",null,Object(o.b)("img",{alt:"Resulting run with the affinity/anti-affinity",src:"https://res.cloudinary.com/gitgoodclub/image/upload/v1540170357/Screen_Shot_2018-10-22_at_12.05.28_pm.png"})),Object(o.b)("p",null,"Note that there are differences between ",Object(o.b)("strong",{parentName:"p"},"preferred")," and ",Object(o.b)("strong",{parentName:"p"},"required"),". With preferred, you may still have the pod scheduled in events we don't necessarily want as a best case scenario."),Object(o.b)("h2",{id:"314-taints-and-tolerations"},"3.14 Taints and Tolerations"),Object(o.b)("p",null,"Tolerations is the opposite of node affinity."),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Allows a node to ",Object(o.b)("strong",{parentName:"li"},"repels a set of pods"),"."),Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"Taints mark")," a node, tolerations are applied to pods to influence the scheduling of a pod."),Object(o.b)("li",{parentName:"ul"},"One use case for taints is to make sure that when you create a new pod, they're not scheduled on the master (",Object(o.b)("strong",{parentName:"li"},"node-role.kubernetes.io/master:NoSchedule"),"). This is the default.")),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-bash"}),"# To add a taint\n$ kubectl taint nodes node1 key=value:NoSchedule # This will make sure that no pods will be scheduled on node1 as long as they don't have a matching toleration\n")),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-yaml"}),'# tolerations.yml\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: tolerations-1\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: tolerations-1\n    spec:\n      containers:\n      - name: k8s-demo\n        image: wardviaene/k8s-demo\n        ports:\n        - name: nodejs-port\n          containerPort: 3000\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: tolerations-2\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: tolerations-2\n    spec:\n      tolerations:\n      - key: "type"\n        operator: "Equal"\n        value: "specialnode"\n        effect: "NoSchedule"\n      containers:\n      - name: k8s-demo\n        image: wardviaene/k8s-demo\n        ports:\n        - name: nodejs-port\n          containerPort: 3000\n')),Object(o.b)("h3",{id:"tolerations-usage"},"Tolerations usage"),Object(o.b)("pre",null,Object(o.b)("code",Object.assign({parentName:"pre"},{className:"language-bash"}),"# Taint a node\n$ kubectl taint nodes NODE-NAME type=specialnode:NoSchedule\n\n# Taint with NoExecute\n$ kubectl taint nodes NODE-NAME testkey=testvalue:NoExecute\n")),Object(o.b)("h3",{id:"keys"},"Keys"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Operators",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"Equal")," (providing key + value)"),Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"Exists")," (only providing a key, checking only whether a key exists)"))),Object(o.b)("li",{parentName:"ul"},"Effects",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"NoSchedule")," (hard requirement that apod will not be scheduled unless there is a matching toleration)"),Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"PreferNoSchedule")," (avoid placing a pod that doesn't have a matching tolerationg, but it's not a hard requirement)"),Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"NoExecute")," (evict pods with non-matching tolerations)",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"tolerationSeconds")," key can be applied with a time in seconds for how long a node can run before it is evicted.")))))),Object(o.b)("h3",{id:"use-cases"},"Use Cases"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Existing node taints for ",Object(o.b)("strong",{parentName:"li"},"master nodes"),"."),Object(o.b)("li",{parentName:"ul"},"Taint nodes that are ",Object(o.b)("strong",{parentName:"li"},"dedicated")," for a team or user."),Object(o.b)("li",{parentName:"ul"},"Node for ",Object(o.b)("strong",{parentName:"li"},"specific hardware")," (ie GPUs) you can taint them to void running non-specific applications on those nodes."),Object(o.b)("li",{parentName:"ul"},"Alpha but soon-to-be beta feature is to ",Object(o.b)("strong",{parentName:"li"},"taint nodes by condition"),".")),Object(o.b)("h3",{id:"useful-taints-and-tolerations"},"Useful Taints and Tolerations"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"node.kubernetes.io/not-ready")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"node.kubernetes.io/unreachable")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"node.kubernetes.io/out-of-disk")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"node.kubernetes.io/memory-pressure")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"node.kubernetes.io/disk-pressure")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"node.kubernetes.io/network-unavailable")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"node.kubernetes.io/unschedulable"))),Object(o.b)("h2",{id:"315-customer-resource-definitions-crds"},"3.15 Customer Resource Definitions (CRDs)"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Let's you extend Kubernetes API."),Object(o.b)("li",{parentName:"ul"},"Resources are the endpoints in the Kubernetes API that store collections of API Objects (ie Deployment, LoadBalancer)."),Object(o.b)("li",{parentName:"ul"},"Operators use CRDs to extend the Kubernetes API with their own functionality.")),Object(o.b)("h2",{id:"316-operators"},"3.16 Operators"),Object(o.b)("p",null,"An ",Object(o.b)("strong",{parentName:"p"},"Operator")," is a method of ",Object(o.b)("strong",{parentName:"p"},"packaging, deploying and managing")," a Kubernetes Application."),Object(o.b)("p",null,"It puts ",Object(o.b)("strong",{parentName:"p"},"operational knowledge")," in an application."),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Brings the user ",Object(o.b)("strong",{parentName:"li"},"closer to the experience of managed cloud services"),", rather than having to know all the specifics of an application deployed to Kubernetes."),Object(o.b)("li",{parentName:"ul"},"Once an Operator is deployed, it can be ",Object(o.b)("strong",{parentName:"li"},"managed using Custom Resource Definitions")," (arbitraty types that extend the Kubernetes API)."),Object(o.b)("li",{parentName:"ul"},"It also provides a great way to deploy Stateful applications to Kubernetes."),Object(o.b)("li",{parentName:"ul"},"There are operators for Prometheus, Valut, Rook (storage), MySQL, PostgresSQL and so on.")),Object(o.b)("h3",{id:"postgresql-operator-demo"},"PostgreSQL Operator Demo"),Object(o.b)("p",null,"If you just deploy a PostgreSQL container, it'd only start the database. But if you're going to use this ",Object(o.b)("strong",{parentName:"p"},"operator"),", it'll allow you to also ",Object(o.b)("strong",{parentName:"p"},"create replicas, initiate a failover, create backups, scale"),"."),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"An operator contains a lot of the ",Object(o.b)("strong",{parentName:"li"},"management logic")," that you as an administrator or user might want, rather than having to implement it yourself.")),Object(o.b)("h2",{id:"intro-to-kubeadm"},"Intro to kubeadm"),Object(o.b)("p",null,"This is an alternative to running Kubernetes that is not using ",Object(o.b)("inlineCode",{parentName:"p"},"kops")))}i&&i===Object(i)&&Object.isExtensible(i)&&Object.defineProperty(i,"__filemeta",{enumerable:!0,configurable:!0,value:{name:"MDXContent",filename:"manual/Kubernetes/Advanced-Topics.md"}}),i.isMDXComponent=!0}}]);
//# sourceMappingURL=manual-kubernetes-advanced-topics.101a1afd2417ec7a4a77.js.map