{"version":3,"sources":["/Users/dennis.okeeffe/Project-Imposter/developer-notes/manual/Machine-Learning/ML-Decision-Trees.md"],"names":["layoutProps","MDXLayout","MDXContent","_ref","components","props","Object","_Users_dennis_okeeffe_Project_Imposter_developer_notes_node_modules_babel_preset_react_app_node_modules_babel_runtime_helpers_esm_objectWithoutProperties__WEBPACK_IMPORTED_MODULE_0__","_mdx_js_react__WEBPACK_IMPORTED_MODULE_2__","assign","mdxType","id","parentName","href","className","isMDXComponent"],"mappings":"oYAWMA,EAAc,GAGdC,EAAY,UACH,SAASC,EAATC,GAGZ,IAFDC,EAECD,EAFDC,WACGC,EACFC,OAAAC,EAAA,EAAAD,CAAAH,EAAA,gBACD,OAAOG,OAAAE,EAAA,EAAAF,CAACL,EAADK,OAAAG,OAAA,GAAeT,EAAiBK,EAAhC,CAAuCD,WAAYA,EAAYM,QAAQ,cAC5EJ,OAAAE,EAAA,EAAAF,CAAA,KAAQ,CACNK,GAAM,kBADR,kBAMAL,OAAAE,EAAA,EAAAF,CAAA,UACEA,OAAAE,EAAA,EAAAF,CAAA,MAAIM,WAAW,MAAKN,OAAAE,EAAA,EAAAF,CAAA,IAAAA,OAAAG,OAAA,CAAGG,WAAW,MAAS,CACvCC,KAAQ,oBADQ,kBAEOP,OAAAE,EAAA,EAAAF,CAAA,MAAIM,WAAW,MACtCN,OAAAE,EAAA,EAAAF,CAAA,MAAIM,WAAW,MAAKN,OAAAE,EAAA,EAAAF,CAAA,IAAAA,OAAAG,OAAA,CAAGG,WAAW,MAAS,CACvCC,KAAQ,eADQ,cAGpBP,OAAAE,EAAA,EAAAF,CAAA,MAAIM,WAAW,MAAKN,OAAAE,EAAA,EAAAF,CAAA,IAAAA,OAAAG,OAAA,CAAGG,WAAW,MAAS,CACvCC,KAAQ,wCADQ,0CAQ1BP,OAAAE,EAAA,EAAAF,CAAA,KAAQ,CACNK,GAAM,aADR,aAGAL,OAAAE,EAAA,EAAAF,CAAA,SAAGA,OAAAE,EAAA,EAAAF,CAAA,UAAQM,WAAW,KAAnB,8CACHN,OAAAE,EAAA,EAAAF,CAAA,gFACAA,OAAAE,EAAA,EAAAF,CAAA,+EACAA,OAAAE,EAAA,EAAAF,CAAA,2KACAA,OAAAE,EAAA,EAAAF,CAAA,kHACAA,OAAAE,EAAA,EAAAF,CAAA,mGACAA,OAAAE,EAAA,EAAAF,CAAA,0FACAA,OAAAE,EAAA,EAAAF,CAAA,kDACAA,OAAAE,EAAA,EAAAF,CAAA,qHACAA,OAAAE,EAAA,EAAAF,CAAA,SAAGA,OAAAE,EAAA,EAAAF,CAAA,UAAQM,WAAW,KAAnB,cACHN,OAAAE,EAAA,EAAAF,CAAA,wBAAmBA,OAAAE,EAAA,EAAAF,CAAA,cAAYM,WAAW,KAAvB,aAAnB,iDAA0HN,OAAAE,EAAA,EAAAF,CAAA,cAAYM,WAAW,KAAvB,cAA1H,4BAA6MN,OAAAE,EAAA,EAAAF,CAAA,cAAYM,WAAW,KAAvB,aAA7M,oCAAuSN,OAAAE,EAAA,EAAAF,CAAA,cAAYM,WAAW,KAAvB,IAAvS,sBACAN,OAAAE,EAAA,EAAAF,CAAA,qDAAgDA,OAAAE,EAAA,EAAAF,CAAA,cAAYM,WAAW,KAAvB,aAAhD,cAAoHN,OAAAE,EAAA,EAAAF,CAAA,cAAYM,WAAW,KAAvB,aAApH,oBAA8LN,OAAAE,EAAA,EAAAF,CAAA,cAAYM,WAAW,KAAvB,cAA9L,6BAAkRN,OAAAE,EAAA,EAAAF,CAAA,cAAYM,WAAW,KAAvB,aAAlR,oBAA4VN,OAAAE,EAAA,EAAAF,CAAA,cAAYM,WAAW,KAAvB,cAA5V,KACAN,OAAAE,EAAA,EAAAF,CAAA,0GAAqGA,OAAAE,EAAA,EAAAF,CAAA,cAAYM,WAAW,KAAvB,KAArG,yEACAN,OAAAE,EAAA,EAAAF,CAAA,sBAAiBA,OAAAE,EAAA,EAAAF,CAAA,cAAYM,WAAW,KAAvB,kCAAjB,KACAN,OAAAE,EAAA,EAAAF,CAAA,2JACAA,OAAAE,EAAA,EAAAF,CAAA,gKACAA,OAAAE,EAAA,EAAAF,CAAA,KAAQ,CACNK,GAAM,sCADR,sCAGAL,OAAAE,EAAA,EAAAF,CAAA,6PACAA,OAAAE,EAAA,EAAAF,CAAA,+FACAA,OAAAE,EAAA,EAAAF,CAAA,6HACAA,OAAAE,EAAA,EAAAF,CAAA,uEACAA,OAAAE,EAAA,EAAAF,CAAA,mEACAA,OAAAE,EAAA,EAAAF,CAAA,WAAKA,OAAAE,EAAA,EAAAF,CAAA,OAAAA,OAAAG,OAAA,CAAMG,WAAW,OAAU,CAC5BE,UAAa,oBADZ,0XAaLR,OAAAE,EAAA,EAAAF,CAAA,0DACAA,OAAAE,EAAA,EAAAF,CAAA,WAAKA,OAAAE,EAAA,EAAAF,CAAA,OAAAA,OAAAG,OAAA,CAAMG,WAAW,OAAU,CAC5BE,UAAa,oBADZ,iOAULR,OAAAE,EAAA,EAAAF,CAAA,0NACAA,OAAAE,EAAA,EAAAF,CAAA,kIACAA,OAAAE,EAAA,EAAAF,CAAA,SAAGA,OAAAE,EAAA,EAAAF,CAAA,UAAQM,WAAW,KAAnB,+CACHN,OAAAE,EAAA,EAAAF,CAAA,uTAIJJ,EAAWa,gBAAiB","file":"static/js/manual-machine-learning-ml-decision-trees.1e8dd139.js","sourcesContent":["/* @jsx mdx */\n  import React from 'react'\n  import { mdx } from '@mdx-js/react'\n  /* @jsx mdx */\n\n\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\")\n  return <div {...props}/>\n};\n\nconst layoutProps = {\n  \n};\nconst MDXLayout = \"wrapper\"\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n    <h1 {...{\n      \"id\": \"decision-trees\"\n    }}>{`Decision Trees`}</h1>\n    {\n      /* TOC */\n    }\n    <ul>\n      <li parentName=\"ul\"><a parentName=\"li\" {...{\n          \"href\": \"#decision-trees\"\n        }}>{`Decision Trees`}</a><ul parentName=\"li\">\n          <li parentName=\"ul\"><a parentName=\"li\" {...{\n              \"href\": \"#intuition\"\n            }}>{`Intuition`}</a></li>\n          <li parentName=\"ul\"><a parentName=\"li\" {...{\n              \"href\": \"#decision-tree-regression-in-python\"\n            }}>{`Decision Tree Regression in Python`}</a></li>\n        </ul></li>\n    </ul>\n    {\n      /* /TOC */\n    }\n    <h2 {...{\n      \"id\": \"intuition\"\n    }}>{`Intuition`}</h2>\n    <p><strong parentName=\"p\">{`CART: Classification and Regression Trees`}</strong></p>\n    <p>{`We speak about both types, but for now - focus on regression trees.`}</p>\n    <p>{`Regression trees are a bit more complex than classification trees.`}</p>\n    <p>{`Imagine a scatter plot with two IV and we are predicting an DV y (which you wouldn't be able to see on the chart). Essentially the DV would sit on the z axis.`}</p>\n    <p>{`Once you run the regression decision tree algorithm, the scatter plot will be split up into segments.`}</p>\n    <p>{`For example, x1 might be split at 20. Another split may happen for x2 at 170, 200 etc.`}</p>\n    <p>{`The question, are the splits adding value to way we want to group our points?`}</p>\n    <p>{`Each split itself is known as a leaf.`}</p>\n    <p>{`The algorithm can handle mathematical issues and we can focus on the practical element of the algorithm.`}</p>\n    <p><strong parentName=\"p\">{`Splitting`}</strong></p>\n    <p>{`If we split `}<inlineCode parentName=\"p\">{`x[1] < 20`}</inlineCode>{`, we have two options (y/N). If we then split `}<inlineCode parentName=\"p\">{`x[2] < 170`}</inlineCode>{`, we add a child node to `}<inlineCode parentName=\"p\">{`x[1] < 20`}</inlineCode>{` that checks y/N. If we then set `}<inlineCode parentName=\"p\">{``}</inlineCode>{`x`}{`[2]`}{` < 200\\`.`}</p>\n    <p>{`After having a two child tree, if we set `}<inlineCode parentName=\"p\">{`x[1] < 40`}</inlineCode>{` such that `}<inlineCode parentName=\"p\">{`x[1] < 20`}</inlineCode>{` is not true and `}<inlineCode parentName=\"p\">{`x[2] < 170`}</inlineCode>{` is true, we can then set `}<inlineCode parentName=\"p\">{`x[1] < 40`}</inlineCode>{` as the child to `}<inlineCode parentName=\"p\">{`x[2] < 170`}</inlineCode>{`.`}</p>\n    <p>{`Once we start this tree, what do we populate into those boxes? Well, we decide how we predict `}<inlineCode parentName=\"p\">{`y`}</inlineCode>{` with a new observation added to the plane x`}{`[1]`}{` and x`}{`[2]`}{`.`}</p>\n    <p>{`Key note: `}<inlineCode parentName=\"p\">{`Adding splits adds information`}</inlineCode>{`.`}</p>\n    <p>{`What we do is that for each terminal leaf, we take the average and assign the value that we give to any new element that falls into that leaf.`}</p>\n    <p>{`Now, if we have a new value, we check the decision tree where it falls and then assign the new element the value of where it falls as a prediction.`}</p>\n    <h2 {...{\n      \"id\": \"decision-tree-regression-in-python\"\n    }}>{`Decision Tree Regression in Python`}</h2>\n    <p>{`Warning for the decision tree, because we need to consider the entropy and split the result into data points. If we stick to one dimension, how do we have a line that is not horizontal? If the splits are made, they should remain a constant.`}</p>\n    <p>{`Either the intervals are infinite (which they are not), or the model has an issue.`}</p>\n    <p>{`The reason the issue came up, is because of what we have used to create the plot since this is no longer linear.`}</p>\n    <p>{`This is now a non-linear, non-continuous regression model.`}</p>\n    <p>{`What is the best way to view something non-continuous?`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`# Visualising the Decision Tree results\nX_grid = np.arange(min(X), max(X), 0.01)\nX_grid = X_grid.reshape(len(X_grid), 1)\nplt.scatter(X, y, color = 'red')\nplt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\nplt.title('Truth or Bluff (Decision Tree Regression)')\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.savefig('decision-tree.png')\nplt.show()\n`}</code></pre>\n    <p>{`As for getting the decision tree code to run:`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`# Prediciting the Decision Tree results\n# Create the Regressor\nfrom sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor(random_state=0)\nregressor.fit(X, y)\n\ny_pred = regressor.predict(6.5)\n`}</code></pre>\n    <p>{`Ensure you have a higher resolution in order to visualize the splits. Given that the example in the tutorial has just 1 DV and 1 IV, it will come out like steps as the only splits will occur on the x axis.`}</p>\n    <p>{`The model itself is not necessarily that interesting in 1D, but over many dimensions it becomes far more interesting.`}</p>\n    <p><strong parentName=\"p\">{`What happens when you use a random forest?`}</strong></p>\n    <p>{`A Random Forest is a team of decision trees. What happens with a team of 10 trees? 50 trees? 500 trees?`}</p>\n    </MDXLayout>;\n}\n\nMDXContent.isMDXComponent = true;\n  "],"sourceRoot":""}