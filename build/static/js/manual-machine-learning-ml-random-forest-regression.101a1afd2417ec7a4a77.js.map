{"version":3,"sources":["/Users/dennis.okeeffe/Project-Imposter/developer-notes/manual/Machine-Learning/ML-Random-Forest-Regression.md"],"names":["layoutProps","MDXLayout","MDXContent","_ref","components","props","Object","_Users_dennis_okeeffe_Project_Imposter_developer_notes_node_modules_babel_preset_react_app_node_modules_babel_runtime_helpers_esm_objectWithoutProperties__WEBPACK_IMPORTED_MODULE_0__","_mdx_js_react__WEBPACK_IMPORTED_MODULE_2__","assign","mdxType","id","parentName","className","isMDXComponent"],"mappings":"8YAWMA,EAAc,GAGdC,EAAY,UACH,SAASC,EAATC,GAGZ,IAFDC,EAECD,EAFDC,WACGC,EACFC,OAAAC,EAAA,EAAAD,CAAAH,EAAA,gBACD,OAAOG,OAAAE,EAAA,EAAAF,CAACL,EAADK,OAAAG,OAAA,GAAeT,EAAiBK,EAAhC,CAAuCD,WAAYA,EAAYM,QAAQ,cAC5EJ,OAAAE,EAAA,EAAAF,CAAA,KAAQ,CACNK,GAAM,4BADR,4BAGAL,OAAAE,EAAA,EAAAF,CAAA,KAAQ,CACNK,GAAM,aADR,aAGAL,OAAAE,EAAA,EAAAF,CAAA,6DACAA,OAAAE,EAAA,EAAAF,CAAA,qGACAA,OAAAE,EAAA,EAAAF,CAAA,SAAGA,OAAAE,EAAA,EAAAF,CAAA,UAAQM,WAAW,KAAnB,UACHN,OAAAE,EAAA,EAAAF,CAAA,UACEA,OAAAE,EAAA,EAAAF,CAAA,MAAIM,WAAW,MAAf,uDACAN,OAAAE,EAAA,EAAAF,CAAA,MAAIM,WAAW,MAAf,8DACAN,OAAAE,EAAA,EAAAF,CAAA,MAAIM,WAAW,MAAf,gFACAN,OAAAE,EAAA,EAAAF,CAAA,MAAIM,WAAW,MAAf,gFAAqGN,OAAAE,EAAA,EAAAF,CAAA,cAAYM,WAAW,MAAvB,KAArG,uGAA2PN,OAAAE,EAAA,EAAAF,CAAA,cAAYM,WAAW,MAAvB,KAA3P,aAEFN,OAAAE,EAAA,EAAAF,CAAA,8EACAA,OAAAE,EAAA,EAAAF,CAAA,SAAGA,OAAAE,EAAA,EAAAF,CAAA,UAAQM,WAAW,KAAnB,YACHN,OAAAE,EAAA,EAAAF,CAAA,+OACAA,OAAAE,EAAA,EAAAF,CAAA,sHACAA,OAAAE,EAAA,EAAAF,CAAA,KAAQ,CACNK,GAAM,UADR,UAGAL,OAAAE,EAAA,EAAAF,CAAA,4HACAA,OAAAE,EAAA,EAAAF,CAAA,6GACAA,OAAAE,EAAA,EAAAF,CAAA,qEACAA,OAAAE,EAAA,EAAAF,CAAA,WAAKA,OAAAE,EAAA,EAAAF,CAAA,OAAAA,OAAAG,OAAA,CAAMG,WAAW,OAAU,CAC5BC,UAAa,oBADZ,kMAQLP,OAAAE,EAAA,EAAAF,CAAA,uGACAA,OAAAE,EAAA,EAAAF,CAAA,yHACAA,OAAAE,EAAA,EAAAF,CAAA,4HACAA,OAAAE,EAAA,EAAAF,CAAA,iSAIJJ,EAAWY,gBAAiB","file":"static/js/manual-machine-learning-ml-random-forest-regression.90486f1e.js","sourcesContent":["/* @jsx mdx */\n  import React from 'react'\n  import { mdx } from '@mdx-js/react'\n  /* @jsx mdx */\n\n\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\")\n  return <div {...props}/>\n};\n\nconst layoutProps = {\n  \n};\nconst MDXLayout = \"wrapper\"\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n    <h1 {...{\n      \"id\": \"random-forest-regression\"\n    }}>{`Random Forest Regression`}</h1>\n    <h2 {...{\n      \"id\": \"intuition\"\n    }}>{`Intuition`}</h2>\n    <p>{`Random forest is a version of ensemble learning.`}</p>\n    <p>{`It's when you take the same algorithm multiple times and create something more powerful.`}</p>\n    <p><strong parentName=\"p\">{`Steps`}</strong></p>\n    <ol>\n      <li parentName=\"ol\">{`Pick at random K data points from the Training Set.`}</li>\n      <li parentName=\"ol\">{`Build the Decision Tree associated to these K data points.`}</li>\n      <li parentName=\"ol\">{`Choose the number Ntree of trees you want to build and repeat steps 1 and 2.`}</li>\n      <li parentName=\"ol\">{`For a new data point, make each one of your Ntree trees predict the value of `}<inlineCode parentName=\"li\">{`Y`}</inlineCode>{` for the data point in question, and assign the new data point the average across all the predicted `}<inlineCode parentName=\"li\">{`Y`}</inlineCode>{` values.`}</li>\n    </ol>\n    <p>{`Doing this allows you to improve the accuracy of your prediction.`}</p>\n    <p><strong parentName=\"p\">{`Example`}</strong></p>\n    <p>{`How many lollies in a jar? Imagine taking notes of every guess - getting around 1000 and then beginning to average them out or take the median. Statistically speaking, you have a highly likelihood of being closer to the truth.`}</p>\n    <p>{`Once you hit the middle of the normal distribution, you are more likely to be on the money for the guess.`}</p>\n    <h2 {...{\n      \"id\": \"python\"\n    }}>{`PYTHON`}</h2>\n    <p>{`This is the last regression model. If you understand decision tree regression, you'll understand random forest.`}</p>\n    <p>{`From decision tree, we know that we will need the visualisation using the non-continuous result.`}</p>\n    <p>{`For the regressor, we use RandomForestRegressor library.`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`# Prediciting the Random Forest results\n# Create the Regressor\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(random_state=0)\nregressor.fit(X, y)\n`}</code></pre>\n    <p>{`Simply, with these lines, we can already determine that the graph is no longer continuous.`}</p>\n    <p>{`By having several decision trees, we end up with a lot more \"steps\" than we had with just one decision tree.`}</p>\n    <p>{`More tree !== more steps. The more trees you have, the more the average will converge towards the same average.`}</p>\n    <p>{`Generally the steps will become better placed depending on the average.`}</p>\n    </MDXLayout>;\n}\n\nMDXContent.isMDXComponent = true;\n  "],"sourceRoot":""}