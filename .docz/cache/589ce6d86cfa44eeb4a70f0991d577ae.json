{"remainingRequest":"/Users/okeeffe_d/Business/Documentation/node_modules/babel-loader/lib/index.js?{\"presets\":[[\"/Users/okeeffe_d/Business/Documentation/node_modules/babel-preset-docz/dist/index.js\",{\"flow\":true,\"typescript\":false,\"parseProps\":true}]],\"plugins\":[[\"/Users/okeeffe_d/Business/Documentation/node_modules/docz-utils/lib/named-asset-import.js\",{\"loaderMap\":{\"svg\":{\"ReactComponent\":\"@svgr/webpack?-prettier,-svgo![path]\"}}}]],\"babelrc\":false,\"cacheCompression\":true,\"compact\":true}!/Users/okeeffe_d/Business/Documentation/manual/Machine-Learning/ML-Random-Forest-Regression.md","dependencies":[{"path":"/Users/okeeffe_d/Business/Documentation/manual/Machine-Learning/ML-Random-Forest-Regression.md","mtime":1548209344374},{"path":"/Users/okeeffe_d/Business/Documentation/node_modules/cache-loader/dist/cjs.js","mtime":1548134640245},{"path":"/Users/okeeffe_d/Business/Documentation/node_modules/babel-loader/lib/index.js","mtime":1548134640227}],"contextDependencies":[],"result":["function _typeof(obj){if(typeof Symbol===\"function\"&&typeof Symbol.iterator===\"symbol\"){_typeof=function _typeof(obj){return typeof obj;};}else{_typeof=function _typeof(obj){return obj&&typeof Symbol===\"function\"&&obj.constructor===Symbol&&obj!==Symbol.prototype?\"symbol\":typeof obj;};}return _typeof(obj);}function _objectWithoutProperties(source,excluded){if(source==null)return{};var target=_objectWithoutPropertiesLoose(source,excluded);var key,i;if(Object.getOwnPropertySymbols){var sourceSymbolKeys=Object.getOwnPropertySymbols(source);for(i=0;i<sourceSymbolKeys.length;i++){key=sourceSymbolKeys[i];if(excluded.indexOf(key)>=0)continue;if(!Object.prototype.propertyIsEnumerable.call(source,key))continue;target[key]=source[key];}}return target;}function _objectWithoutPropertiesLoose(source,excluded){if(source==null)return{};var target={};var sourceKeys=Object.keys(source);var key,i;for(i=0;i<sourceKeys.length;i++){key=sourceKeys[i];if(excluded.indexOf(key)>=0)continue;target[key]=source[key];}return target;}function _classCallCheck(instance,Constructor){if(!(instance instanceof Constructor)){throw new TypeError(\"Cannot call a class as a function\");}}function _defineProperties(target,props){for(var i=0;i<props.length;i++){var descriptor=props[i];descriptor.enumerable=descriptor.enumerable||false;descriptor.configurable=true;if(\"value\"in descriptor)descriptor.writable=true;Object.defineProperty(target,descriptor.key,descriptor);}}function _createClass(Constructor,protoProps,staticProps){if(protoProps)_defineProperties(Constructor.prototype,protoProps);if(staticProps)_defineProperties(Constructor,staticProps);return Constructor;}function _possibleConstructorReturn(self,call){if(call&&(_typeof(call)===\"object\"||typeof call===\"function\")){return call;}return _assertThisInitialized(self);}function _assertThisInitialized(self){if(self===void 0){throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");}return self;}function _getPrototypeOf(o){_getPrototypeOf=Object.setPrototypeOf?Object.getPrototypeOf:function _getPrototypeOf(o){return o.__proto__||Object.getPrototypeOf(o);};return _getPrototypeOf(o);}function _inherits(subClass,superClass){if(typeof superClass!==\"function\"&&superClass!==null){throw new TypeError(\"Super expression must either be null or a function\");}subClass.prototype=Object.create(superClass&&superClass.prototype,{constructor:{value:subClass,writable:true,configurable:true}});if(superClass)_setPrototypeOf(subClass,superClass);}function _setPrototypeOf(o,p){_setPrototypeOf=Object.setPrototypeOf||function _setPrototypeOf(o,p){o.__proto__=p;return o;};return _setPrototypeOf(o,p);}import React from'react';import{MDXTag}from'@mdx-js/tag';var MDXContent=/*#__PURE__*/function(_React$Component){_inherits(MDXContent,_React$Component);function MDXContent(props){var _this;_classCallCheck(this,MDXContent);_this=_possibleConstructorReturn(this,_getPrototypeOf(MDXContent).call(this,props));_this.layout=null;return _this;}_createClass(MDXContent,[{key:\"render\",value:function render(){var _this$props=this.props,components=_this$props.components,props=_objectWithoutProperties(_this$props,[\"components\"]);return React.createElement(MDXTag,{name:\"wrapper\",components:components},React.createElement(MDXTag,{name:\"h1\",components:components,props:{\"id\":\"random-forest-regression\"}},\"Random Forest Regression\"),React.createElement(MDXTag,{name:\"h2\",components:components,props:{\"id\":\"intuition\"}},\"Intuition\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Random forest is a version of ensemble learning.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"It's when you take the same algorithm multiple times and create something more powerful.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Steps\")),React.createElement(MDXTag,{name:\"ol\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ol\"},\"Pick at random K data points from the Training Set.\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ol\"},\"Build the Decision Tree associated to these K data points.\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ol\"},\"Choose the number Ntree of trees you want to build and repeat steps 1 and 2.\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ol\"},\"For a new data point, make each one of your Ntree trees predict the value of \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"li\"},\"Y\"),\" for the data point in question, and assign the new data point the average across all the predicted \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"li\"},\"Y\"),\" values.\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Doing this allows you to improve the accuracy of your prediction.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Example\")),React.createElement(MDXTag,{name:\"p\",components:components},\"How many lollies in a jar? Imagine taking notes of every guess - getting around 1000 and then beginning to average them out or take the median. Statistically speaking, you have a highly likelihood of being closer to the truth.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Once you hit the middle of the normal distribution, you are more likely to be on the money for the guess.\"),React.createElement(MDXTag,{name:\"h2\",components:components,props:{\"id\":\"python\"}},\"PYTHON\"),React.createElement(MDXTag,{name:\"p\",components:components},\"This is the last regression model. If you understand decision tree regression, you'll understand random forest.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"From decision tree, we know that we will need the visualisation using the non-continuous result.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"For the regressor, we use RandomForestRegressor library.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{\"className\":\"language-python\"}},\"# Prediciting the Random Forest results\\n# Create the Regressor\\nfrom sklearn.ensemble import RandomForestRegressor\\nregressor = RandomForestRegressor(random_state=0)\\nregressor.fit(X, y)\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Simply, with these lines, we can already determine that the graph is no longer continuous.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"By having several decision trees, we end up with a lot more \\\"steps\\\" than we had with just one decision tree.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"More tree !== more steps. The more trees you have, the more the average will converge towards the same average.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Generally the steps will become better placed depending on the average.\"));}}]);return MDXContent;}(React.Component);export{MDXContent as default};MDXContent.__docgenInfo={\"description\":\"\",\"methods\":[],\"displayName\":\"MDXContent\"};",{"version":3,"sources":["/Users/okeeffe_d/Business/Documentation/manual/Machine-Learning/ML-Random-Forest-Regression.md"],"names":["React","MDXTag","MDXContent","props","layout","components","Component"],"mappings":"omFACE,MAAOA,CAAAA,KAAP,KAAkB,OAAlB,CACA,OAASC,MAAT,KAAuB,aAAvB,C,GAGmBC,CAAAA,U,gFACnB,oBAAYC,KAAZ,CAAmB,4CACjB,4EAAMA,KAAN,GACA,MAAKC,MAAL,CAAc,IAAd,CAFiB,aAGlB,C,8DACQ,iBAC0B,KAAKD,KAD/B,CACCE,UADD,aACCA,UADD,CACgBF,KADhB,sDAGP,MAAO,qBAAC,MAAD,EACE,IAAI,CAAC,SADP,CAGE,UAAU,CAAEE,UAHd,EAG0B,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,0BAAN,CAAjD,6BAH1B,CAIX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,WAAN,CAAjD,cAJW,CAKX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,qDALW,CAMX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6FANW,CAOX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,UAAzC,CAPW,CAQX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,wDADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,+DAFA,CAGA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,iFAHA,CAIA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,kFAA2I,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,IAA7D,MAA3I,wGAAmU,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,IAA7D,MAAnU,YAJA,CARW,CAcX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,sEAdW,CAeX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,YAAzC,CAfW,CAgBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,uOAhBW,CAiBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,8GAjBW,CAkBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,QAAN,CAAjD,WAlBW,CAmBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,oHAnBW,CAoBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,qGApBW,CAqBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6DArBW,CAsBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,CAAC,YAAY,iBAAb,CAApE,kMAA3C,CAtBW,CA4BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,+FA5BW,CA6BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,mHA7BW,CA8BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,oHA9BW,CA+BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,4EA/BW,CAAP,CAiCD,C,wBAzCqCL,KAAK,CAACM,S,SAAzBJ,U","sourcesContent":["\n  import React from 'react'\n  import { MDXTag } from '@mdx-js/tag'\n  \n\nexport default class MDXContent extends React.Component {\n  constructor(props) {\n    super(props)\n    this.layout = null\n  }\n  render() {\n    const { components, ...props } = this.props\n\n    return <MDXTag\n             name=\"wrapper\"\n             \n             components={components}><MDXTag name=\"h1\" components={components} props={{\"id\":\"random-forest-regression\"}}>{`Random Forest Regression`}</MDXTag>\n<MDXTag name=\"h2\" components={components} props={{\"id\":\"intuition\"}}>{`Intuition`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Random forest is a version of ensemble learning.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`It's when you take the same algorithm multiple times and create something more powerful.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Steps`}</MDXTag></MDXTag>\n<MDXTag name=\"ol\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ol\">{`Pick at random K data points from the Training Set.`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ol\">{`Build the Decision Tree associated to these K data points.`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ol\">{`Choose the number Ntree of trees you want to build and repeat steps 1 and 2.`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ol\">{`For a new data point, make each one of your Ntree trees predict the value of `}<MDXTag name=\"inlineCode\" components={components} parentName=\"li\">{`Y`}</MDXTag>{` for the data point in question, and assign the new data point the average across all the predicted `}<MDXTag name=\"inlineCode\" components={components} parentName=\"li\">{`Y`}</MDXTag>{` values.`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Doing this allows you to improve the accuracy of your prediction.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Example`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`How many lollies in a jar? Imagine taking notes of every guess - getting around 1000 and then beginning to average them out or take the median. Statistically speaking, you have a highly likelihood of being closer to the truth.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Once you hit the middle of the normal distribution, you are more likely to be on the money for the guess.`}</MDXTag>\n<MDXTag name=\"h2\" components={components} props={{\"id\":\"python\"}}>{`PYTHON`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`This is the last regression model. If you understand decision tree regression, you'll understand random forest.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`From decision tree, we know that we will need the visualisation using the non-continuous result.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`For the regressor, we use RandomForestRegressor library.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{\"className\":\"language-python\"}}>{`# Prediciting the Random Forest results\n# Create the Regressor\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(random_state=0)\nregressor.fit(X, y)\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Simply, with these lines, we can already determine that the graph is no longer continuous.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`By having several decision trees, we end up with a lot more \"steps\" than we had with just one decision tree.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`More tree !== more steps. The more trees you have, the more the average will converge towards the same average.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Generally the steps will become better placed depending on the average.`}</MDXTag>\n           </MDXTag>\n  }\n}\n  "]}]}