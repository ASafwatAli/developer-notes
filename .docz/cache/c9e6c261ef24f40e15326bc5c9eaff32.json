{"remainingRequest":"/Users/okeeffe_d/Business/Documentation/node_modules/babel-loader/lib/index.js?{\"presets\":[[\"/Users/okeeffe_d/Business/Documentation/node_modules/babel-preset-docz/dist/index.js\",{\"flow\":true,\"typescript\":false,\"parseProps\":true}]],\"plugins\":[[\"/Users/okeeffe_d/Business/Documentation/node_modules/docz-utils/lib/named-asset-import.js\",{\"loaderMap\":{\"svg\":{\"ReactComponent\":\"@svgr/webpack?-prettier,-svgo![path]\"}}}]],\"babelrc\":false,\"cacheCompression\":true,\"compact\":true}!/Users/okeeffe_d/Business/Documentation/manual/Machine-Learning/Machine-Learning-Intro.md","dependencies":[{"path":"/Users/okeeffe_d/Business/Documentation/manual/Machine-Learning/Machine-Learning-Intro.md","mtime":1548209344381},{"path":"/Users/okeeffe_d/Business/Documentation/node_modules/cache-loader/dist/cjs.js","mtime":1548134640245},{"path":"/Users/okeeffe_d/Business/Documentation/node_modules/babel-loader/lib/index.js","mtime":1548134640227}],"contextDependencies":[],"result":["function _typeof(obj){if(typeof Symbol===\"function\"&&typeof Symbol.iterator===\"symbol\"){_typeof=function _typeof(obj){return typeof obj;};}else{_typeof=function _typeof(obj){return obj&&typeof Symbol===\"function\"&&obj.constructor===Symbol&&obj!==Symbol.prototype?\"symbol\":typeof obj;};}return _typeof(obj);}function _objectWithoutProperties(source,excluded){if(source==null)return{};var target=_objectWithoutPropertiesLoose(source,excluded);var key,i;if(Object.getOwnPropertySymbols){var sourceSymbolKeys=Object.getOwnPropertySymbols(source);for(i=0;i<sourceSymbolKeys.length;i++){key=sourceSymbolKeys[i];if(excluded.indexOf(key)>=0)continue;if(!Object.prototype.propertyIsEnumerable.call(source,key))continue;target[key]=source[key];}}return target;}function _objectWithoutPropertiesLoose(source,excluded){if(source==null)return{};var target={};var sourceKeys=Object.keys(source);var key,i;for(i=0;i<sourceKeys.length;i++){key=sourceKeys[i];if(excluded.indexOf(key)>=0)continue;target[key]=source[key];}return target;}function _classCallCheck(instance,Constructor){if(!(instance instanceof Constructor)){throw new TypeError(\"Cannot call a class as a function\");}}function _defineProperties(target,props){for(var i=0;i<props.length;i++){var descriptor=props[i];descriptor.enumerable=descriptor.enumerable||false;descriptor.configurable=true;if(\"value\"in descriptor)descriptor.writable=true;Object.defineProperty(target,descriptor.key,descriptor);}}function _createClass(Constructor,protoProps,staticProps){if(protoProps)_defineProperties(Constructor.prototype,protoProps);if(staticProps)_defineProperties(Constructor,staticProps);return Constructor;}function _possibleConstructorReturn(self,call){if(call&&(_typeof(call)===\"object\"||typeof call===\"function\")){return call;}return _assertThisInitialized(self);}function _assertThisInitialized(self){if(self===void 0){throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");}return self;}function _getPrototypeOf(o){_getPrototypeOf=Object.setPrototypeOf?Object.getPrototypeOf:function _getPrototypeOf(o){return o.__proto__||Object.getPrototypeOf(o);};return _getPrototypeOf(o);}function _inherits(subClass,superClass){if(typeof superClass!==\"function\"&&superClass!==null){throw new TypeError(\"Super expression must either be null or a function\");}subClass.prototype=Object.create(superClass&&superClass.prototype,{constructor:{value:subClass,writable:true,configurable:true}});if(superClass)_setPrototypeOf(subClass,superClass);}function _setPrototypeOf(o,p){_setPrototypeOf=Object.setPrototypeOf||function _setPrototypeOf(o,p){o.__proto__=p;return o;};return _setPrototypeOf(o,p);}import React from'react';import{MDXTag}from'@mdx-js/tag';var MDXContent=/*#__PURE__*/function(_React$Component){_inherits(MDXContent,_React$Component);function MDXContent(props){var _this;_classCallCheck(this,MDXContent);_this=_possibleConstructorReturn(this,_getPrototypeOf(MDXContent).call(this,props));_this.layout=null;return _this;}_createClass(MDXContent,[{key:\"render\",value:function render(){var _this$props=this.props,components=_this$props.components,props=_objectWithoutProperties(_this$props,[\"components\"]);return React.createElement(MDXTag,{name:\"wrapper\",components:components},React.createElement(MDXTag,{name:\"h1\",components:components,props:{\"id\":\"intro-to-machine-learning\"}},\"Intro to Machine Learning\"),React.createElement(MDXTag,{name:\"h2\",components:components,props:{\"id\":\"table-of-contents\"}},\"Table of Contents\"),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#intro-to-machine-learning\"}},\"Intro to Machine Learning\"),React.createElement(MDXTag,{name:\"ul\",components:components,parentName:\"li\"},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#table-of-contents\"}},\"Table of Contents\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#what-is-machine-learning\"}},\"What is Machine Learning?\"),React.createElement(MDXTag,{name:\"ul\",components:components,parentName:\"li\"},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----basic-model-prediction\"}},\"---- Basic Model Prediction\")))),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#classification-regression-clustering\"}},\"Classification, Regression, Clustering\"),React.createElement(MDXTag,{name:\"ul\",components:components,parentName:\"li\"},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----classification-example-filtering-spam\"}},\"---- Classification Example: Filtering Spam\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----regression-example-linkedin-views\"}},\"---- Regression Example: LinkedIn Views\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----clustering-example-separating-the-iris-species\"}},\"---- Clustering Example: Separating the Iris Species\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----supervised-vs-unsupervised\"}},\"---- Supervised vs. Unsupervised\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----getting-practical-with-supervised-learning\"}},\"---- Getting practical with supervised learning\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----getting-practical-with-unsupervised-learning\"}},\"---- Getting practical with unsupervised learning\")))),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#performance-measures\"}},\"Performance Measures\"),React.createElement(MDXTag,{name:\"ul\",components:components,parentName:\"li\"},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----confusion-matrix\"}},\"---- Confusion Matrix\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----calculating-the-rmse-of-air-data\"}},\"---- Calculating the RMSE of air data\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----clustering-dataset-example\"}},\"---- Clustering dataset example\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----training-set-and-test-set\"}},\"---- Training Set and Test Set\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----split-the-sets\"}},\"---- Split the Sets\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----using-cross-validation\"}},\"---- Using Cross Validation\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----bias-and-variance\"}},\"---- Bias and Variance\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----overfitting-the-spam\"}},\"---- Overfitting the Spam\")))),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#classification\"}},\"Classification\"),React.createElement(MDXTag,{name:\"ul\",components:components,parentName:\"li\"},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----learn-a-decision-tree\"}},\"---- Learn a Decision Tree\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----classify-with-the-decision-tree\"}},\"---- Classify with the Decision Tree\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----pruning-the-tree\"}},\"---- Pruning the Tree\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----gini-criterion\"}},\"---- Gini Criterion\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----k-nearest-neighbors\"}},\"---- k-Nearest Neighbors\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----scaling-example\"}},\"---- Scaling Example\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"a\",components:components,parentName:\"li\",props:{\"href\":\"#-----interpreting-a-voronoi-diagram\"}},\"---- Interpreting a Voronoi Diagram\"))))))),React.createElement(MDXTag,{name:\"hr\",components:components}),React.createElement(MDXTag,{name:\"h2\",components:components,props:{\"id\":\"what-is-machine-learning\"}},\"What is Machine Learning?\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Construction/use of algorithms that learn from data.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"We decide that it can learn when it has higher performance after learning more information.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Example: label squares based on size and edge.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"If some squares were, however, solved by people - then these instances can be used to give an informed reply.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"For input knowledge, we can use pre-labeled squares that may give us an indication of which way to go.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"We can make ground on this by constructing a data frame.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"These can be used in R to get more information.\\n\\ndim()\\nstr()\\nsummary()\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"The goal is to build models for prediction.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"We can use things like regression to help predict these things.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"em\",components:components,parentName:\"p\"},\"Formulation\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Input -> \",React.createElement(MDXTag,{name:\"em\",components:components,parentName:\"p\"},\"Estimated Function\"),\" -> Output\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# Reveal number of observations and variables in two different ways\\n> str(iris)\\n'data.frame':   150 obs. of  5 variables:\\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\\n $ Species     : Factor w/ 3 levels \\\"setosa\\\",\\\"versicolor\\\",..: 1 1 1 1 1 1 1 1 1 1 ...\\n> dim(iris)\\n[1] 150   5\\n>\\n>\\n# Show first and last observations in the iris data set\\n> head(iris)\\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\\n1          5.1         3.5          1.4         0.2  setosa\\n2          4.9         3.0          1.4         0.2  setosa\\n3          4.7         3.2          1.3         0.2  setosa\\n4          4.6         3.1          1.5         0.2  setosa\\n5          5.0         3.6          1.4         0.2  setosa\\n6          5.4         3.9          1.7         0.4  setosa\\n> tail(iris)\\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\\n145          6.7         3.3          5.7         2.5 virginica\\n146          6.7         3.0          5.2         2.3 virginica\\n147          6.3         2.5          5.0         1.9 virginica\\n148          6.5         3.0          5.2         2.0 virginica\\n149          6.2         3.4          5.4         2.3 virginica\\n150          5.9         3.0          5.1         1.8 virginica\\n>\\n>\\n# Summarize the iris data set\\n> summary(iris)\\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width\\n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \\n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \\n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \\n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \\n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \\n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \\n       Species  \\n setosa    :50  \\n versicolor:50  \\n virginica :50  \\n\")),React.createElement(\"div\",{id:\"subsection\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----basic-model-prediction\"}},\"---- Basic Model Prediction\"),React.createElement(MDXTag,{name:\"p\",components:components},\"You'll be working with the Wage dataset. It contains the wage and some general information for workers in the mid-Atlantic region of the US.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"As we briefly discussed in the video, there could be a relationship between a worker's age and his wage. Older workers tend to have more experience on average than their younger counterparts, hence you could expect an increasing trend in wage as workers age. So we built a linear regression model for you, using lm(): lm_wage. This model predicts the wage of a worker based only on the worker's age.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"With this linear model lm_wage, which is built with data that contain information on workers' age and their corresponding wage, you can predict the wage of a worker given the age of that worker. For example, suppose you want to predict the wage of a 60 year old worker. You can use the predict() function for this. This generic function takes a model as the first argument. The second argument should be some unseen observations as a data frame. predict() is then able to predict outcomes for these observations.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"> str(Wage)\\n'data.frame':   3000 obs. of  12 variables:\\n $ year      : int  2006 2004 2003 2003 2005 2008 2009 2008 2006 2004 ...\\n $ age       : int  18 24 45 43 50 54 44 30 41 52 ...\\n $ sex       : Factor w/ 2 levels \\\"1. Male\\\",\\\"2. Female\\\": 1 1 1 1 1 1 1 1 1 1 ...\\n $ maritl    : Factor w/ 5 levels \\\"1. Never Married\\\",..: 1 1 2 2 4 2 2 1 1 2 ...\\n $ race      : Factor w/ 4 levels \\\"1. White\\\",\\\"2. Black\\\",..: 1 1 1 3 1 1 4 3 2 1 ...\\n $ education : Factor w/ 5 levels \\\"1. < HS Grad\\\",..: 1 4 3 4 2 4 3 3 3 2 ...\\n $ region    : Factor w/ 9 levels \\\"1. New England\\\",..: 2 2 2 2 2 2 2 2 2 2 ...\\n $ jobclass  : Factor w/ 2 levels \\\"1. Industrial\\\",..: 1 2 1 2 2 2 1 2 2 2 ...\\n $ health    : Factor w/ 2 levels \\\"1. <=Good\\\",\\\"2. >=Very Good\\\": 1 2 1 2 1 2 2 1 2 2 ...\\n $ health_ins: Factor w/ 2 levels \\\"1. Yes\\\",\\\"2. No\\\": 2 2 1 1 1 1 1 1 1 1 ...\\n $ logwage   : num  4.32 4.26 4.88 5.04 4.32 ...\\n $ wage      : num  75 70.5 131 154.7 75 ...\\n>\\n# Build Linear Model: lm_wage (coded already)\\n> lm_wage <- lm(wage ~ age, data = Wage)\\n>\\n# Define data.frame: unseen (coded already)\\n> unseen <- data.frame(age = 60)\\n>\\n# Predict the wage for a 60-year old worker\\n> predict(lm_wage, unseen)\\n       1\\n124.1413\\n\")),React.createElement(\"div\",{id:\"newSection\"}),React.createElement(MDXTag,{name:\"hr\",components:components}),React.createElement(MDXTag,{name:\"h2\",components:components,props:{\"id\":\"classification-regression-clustering\"}},\"Classification, Regression, Clustering\"),React.createElement(MDXTag,{name:\"p\",components:components},\"These are the three common types of ML Problems.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Classification\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Predicting category through historical classifying.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Earlier Observations\"),\" -> \",React.createElement(MDXTag,{name:\"em\",components:components,parentName:\"p\"},\"estimate\"),\" -> \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"CLASSIFIER\")),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Unseen Data\"),\" -> \",React.createElement(MDXTag,{name:\"em\",components:components,parentName:\"p\"},\"CLASSIFIER\"),\" -> \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Class\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Application: Medical Diagnosis, Animal Recognition\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Important: Qualitative Output, Predefined Classes\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Regression\")),React.createElement(MDXTag,{name:\"p\",components:components},\"We are trying to estimate a function that will render the correct response.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Eg. knowing height and weight, is there a relationship? Is it linear? Can we predict a height given a weight?\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"PREDICTORS\"),\" -> \",React.createElement(MDXTag,{name:\"em\",components:components,parentName:\"p\"},\"Regression Function\"),\" -> \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"RESPONSE\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Application: Modelling Payments for Credit Scores, YouTube Subscriptions over time, Job dependent on Grades.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Important: Quantitative Output, previous input-output observations\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Clustering\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Grouping objects that are \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"similar\"),\" in clusters and \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"dissimilar\"),\" between clusters. It's like classification without saying which class an object need to relate to.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Eg. Grouping similar animal photos\"),React.createElement(MDXTag,{name:\"p\",components:components},\"There \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"no labels, no right or wrong, and plenty of possible clusterings\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Another example is k-Means can do things like cluster in similar groups.\"),React.createElement(\"div\",{id:\"spam\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----classification-example-filtering-spam\"}},\"---- Classification Example: Filtering Spam\"),React.createElement(MDXTag,{name:\"p\",components:components},\"In the following exercise you'll work with the dataset emails, which is loaded in your workspace (Source: UCI Machine Learning Repository). Here, several emails have been labeled by humans as spam (1) or not spam (0) and the results are found in the column spam. The considered feature in emails to predict whether it was spam or not is avgCapitalSeq. It is the average amount of sequential capital letters found in each email.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"In the code, you'll find a crude spam filter we built for you, spamClassifier() that uses avgCapitalSeq to predict whether an email is spam or not. In the function definition, it's important to realize that x refers to avgCapitalSeq. So where the avgCapitalSeq is greater than 4, spamClassifier() predicts the email is spam (1), if avgCapitalSeq is inclusively between 3 and 4, it predicts not spam (0), and so on. This classifier's methodology of predicting whether an email is spam or not seems pretty random, but let's see how it does anyways!\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Your job is to inspect the emails dataset, apply spamClassifier to it, and compare the predicted labels with the true labels.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# Show the dimensions of emails\\n> dim(emails)\\n[1] 13  2\\n>\\n# Inspect definition of spam_classifier()\\n> spam_classifier <- function(x){\\n    prediction <- rep(NA, length(x)) # initialize prediction vector\\n    prediction[x > 4] <- 1\\n    prediction[x >= 3 & x <= 4] <- 0\\n    prediction[x >= 2.2 & x < 3] <- 1\\n    prediction[x >= 1.4 & x < 2.2] <- 0\\n    prediction[x > 1.25 & x < 1.4] <- 1\\n    prediction[x <= 1.25] <- 0\\n    return(prediction) # prediction is either 0 or 1\\n  }\\n>\\n# Apply the classifier to the avgCapitalSeq column: spam_pred\\n> spamPred <- sapply(emails$avgCapitalSeq, spamClassifier)\\n>\\n# Compare spam_pred to emails$spam. Use ==\\n> spam_pred == emails$spam\\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\\n\")),React.createElement(\"div\",{id:\"linkedinviews\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----regression-example-linkedin-views\"}},\"---- Regression Example: LinkedIn Views\"),React.createElement(MDXTag,{name:\"p\",components:components},\"It's time for you to make another prediction with regression! More precisely, you'll analyze the number of views of your LinkedIn profile. With your growing network and your data science skills improving daily, you wonder if you can predict how often your profile will be visited in the future based on the number of days it's been since you created your LinkedIn account.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"The instructions will help you predict the number of profile views for the next 3 days, based on the views for the past 3 weeks. The linkedin vector, which contains this information, is already available in your workspace.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# linkedin is already available in your workspace\\n>\\n# Create the days vector\\n> days <- c(seq(1:21))\\n>\\n# Fit a linear model called on the linkedin views per day: linkedin_lm\\n> linkedin_lm <- lm(linkedin ~ days)\\n>\\n# Predict the number of views for the next three days: linkedin_pred\\n> future_days <- data.frame(days = 22:24)\\n> linkedin_pred <- predict(linkedin_lm, future_days)\\n>\\n# Plot historical data and predictions\\n> plot(linkedin ~ days, xlim = c(1, 24))\\n> points(22:24, linkedin_pred, col = \\\"green\\\")\\n\")),React.createElement(\"div\",{id:\"clusteriris\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----clustering-example-separating-the-iris-species\"}},\"---- Clustering Example: Separating the Iris Species\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Last but not least, there's clustering. This technique tries to group your objects. It does this without any prior knowledge of what these groups could or should look like. For clustering, the concepts of prior knowledge and unseen observations are less meaningful than for classification and regression.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"In this exercise, you'll group irises in 3 distinct clusters, based on several flower characteristics in the iris dataset. It has already been chopped up in a data frame my_iris and a vector species, as shown in the sample code on the right.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"The clustering itself will be done with the kmeans() function. How the algorithm actually works, will be explained in the last chapter. For now, just try it out to gain some intuition!\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Note: In problems that have a random aspect (like this problem with kmeans()), the set.seed() function will be used to enforce reproducibility. If you fix the seed, the random numbers that are generated (e.g. in kmeans()) are always the same.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# Set random seed. Don't remove this line.\\n> set.seed(1)\\n>\\n# Chop up iris in my_iris and species\\n> my_iris <- iris[-5]\\n> species <- iris$Species\\n>\\n# Perform k-means clustering on my_iris: kmeans_iris\\n> kmeans_iris <- kmeans(my_iris, 3)\\n>\\n# Compare the actual Species to the clustering using table()\\n> table(species, kmeans_iris$cluster)\\n\\nspecies       1  2  3\\n  setosa     50  0  0\\n  versicolor  0  2 48\\n  virginica   0 36 14\\n>\\n# Plot Petal.Width against Petal.Length, coloring by cluster\\n> plot(Petal.Length ~ Petal.Width, data = my_iris, col = kmeans_iris$cluster)\\n\")),React.createElement(\"div\",{id:\"super\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----supervised-vs-unsupervised\"}},\"---- Supervised vs. Unsupervised\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Classification and Regression have similar traits.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"If we can \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"find\"),\" function f which can be used to assign a class or value to unseen observations \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"given\"),\" a set of labeled observations, we call this \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Supervised Learning\"),\".\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Labelling\"),\" can be tedious and are normally done by humans. Those that don't require labels is known as \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Unsupervised Learning\"),\" - example being the clustering that we did before. Clustering will find group observations that are similar.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Performance of the model\")),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Supervised learning - \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"li\"},\"Compare\"),\" real labels with \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"li\"},\"predicted\"),\" labels\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Unsupervised Learning - No real labels to compare - Techniques will be explained later down the track - Things aren't always black and white\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Semi-Supervised Learning - Mixed of unlabeled and labeled observationed - Eg clustering information and classes of labeled observations to assign a class to unlabeled observations - More labeled observations for \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"li\"},\"supervised learning\"))),React.createElement(\"div\",{id:\"superPrac\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----getting-practical-with-supervised-learning\"}},\"---- Getting practical with supervised learning\"),React.createElement(MDXTag,{name:\"p\",components:components},\"In this exercise, you will use the same dataset. But instead of dropping the Species labels, you will use them do some supervised learning using recursive partitioning! Don't worry if you don't know what that is yet. Recursive partitioning (a.k.a. decision trees) will be explained in Chapter 3.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Take a look at the iris dataset, using str() and summary().\"),React.createElement(MDXTag,{name:\"p\",components:components},\"The code that builds a supervised learning model with the rpart() function from the rpart package is already provided for you. This model trains a decision tree on the iris dataset.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Use the predict() function with the tree model as the first argument. The second argument should be a data frame containing observations of which you want to predict the label. In this case, you can use the predefined unseen data frame. The third argument should be type = \\\"class\\\".\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Simply print out the result of this prediction step.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# Set random seed. Don't remove this line.\\n> set.seed(1)\\n>\\n# Take a look at the iris dataset\\n> str(iris)\\n'data.frame':   150 obs. of  5 variables:\\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\\n $ Species     : Factor w/ 3 levels \\\"setosa\\\",\\\"versicolor\\\",..: 1 1 1 1 1 1 1 1 1 1 ...\\n> summary(iris)\\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width\\n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \\n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \\n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \\n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \\n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \\n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \\n       Species  \\n setosa    :50  \\n versicolor:50  \\n virginica :50\\n>\\n# A decision tree model has been built for you\\n> tree <- rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,\\n                data = iris, method = \\\"class\\\")\\n>\\n# A dataframe containing unseen observations\\n> unseen <- data.frame(Sepal.Length = c(5.3, 7.2),\\n                       Sepal.Width = c(2.9, 3.9),\\n                       Petal.Length = c(1.7, 5.4),\\n                       Petal.Width = c(0.8, 2.3))\\n>\\n# Predict the label of the unseen observations. Print out the result.\\n> predict(tree, unseen, type=\\\"class\\\")\\n        1         2\\n   setosa virginica\\nLevels: setosa versicolor virginica\\n\")),React.createElement(\"div\",{id:\"unsuperPrac\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----getting-practical-with-unsupervised-learning\"}},\"---- Getting practical with unsupervised learning\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"> head(cars)\\n                     wt  hp\\nMazda RX4         2.620 110\\nMazda RX4 Wag     2.875 110\\nDatsun 710        2.320  93\\nHornet 4 Drive    3.215 110\\nHornet Sportabout 3.440 175\\nValiant           3.460 105\\n> # The cars data frame is pre-loaded\\n>\\n> # Set random seed. Don't remove this line.\\n> set.seed(1)\\n>\\n> # Explore the cars dataset\\n>\\n> str(cars)\\n'data.frame':   32 obs. of  2 variables:\\n $ wt: num  2.62 2.88 2.32 3.21 3.44 ...\\n $ hp: num  110 110 93 110 175 105 245 62 95 123 ...\\n> summary(cars)\\n       wt              hp\\n Min.   :1.513   Min.   : 52.0  \\n 1st Qu.:2.581   1st Qu.: 96.5  \\n Median :3.325   Median :123.0  \\n Mean   :3.217   Mean   :146.7  \\n 3rd Qu.:3.610   3rd Qu.:180.0  \\n Max.   :5.424   Max.   :335.0  \\n>\\n> # Group the dataset into two clusters: km_cars\\n> km_cars <- kmeans(cars, 2)\\n>\\n> # Print out the contents of each cluster\\n> km_cars$cluster\\n          Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive\\n                  1                   1                   1                   1\\n  Hornet Sportabout             Valiant          Duster 360           Merc 240D\\n                  2                   1                   2                   1\\n           Merc 230            Merc 280           Merc 280C          Merc 450SE\\n                  1                   1                   1                   2\\n         Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental\\n                  2                   2                   2                   2\\n  Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla\\n                  2                   1                   1                   1\\n      Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28\\n                  1                   1                   1                   2\\n   Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa\\n                  2                   1                   1                   1\\n     Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E\\n                  2                   2                   2                   1\\n\\n# see km_cars in general\\n> km_cars\\nK-means clustering with 2 clusters of sizes 19, 13\\n\\nCluster means:\\n        wt        hp\\n1 2.692000  99.47368\\n2 3.984923 215.69231\\n\\nClustering vector:\\n          Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive\\n                  1                   1                   1                   1\\n  Hornet Sportabout             Valiant          Duster 360           Merc 240D\\n                  2                   1                   2                   1\\n           Merc 230            Merc 280           Merc 280C          Merc 450SE\\n                  1                   1                   1                   2\\n         Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental\\n                  2                   2                   2                   2\\n  Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla\\n                  2                   1                   1                   1\\n      Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28\\n                  1                   1                   1                   2\\n   Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa\\n                  2                   1                   1                   1\\n     Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E\\n                  2                   2                   2                   1\\n\\nWithin cluster sum of squares by cluster:\\n[1] 14085.06 27403.23\\n (between_SS / total_SS =  71.5 %)\\n\\nAvailable components:\\n\\n[1] \\\"cluster\\\"      \\\"centers\\\"      \\\"totss\\\"        \\\"withinss\\\"     \\\"tot.withinss\\\"\\n[6] \\\"betweenss\\\"    \\\"size\\\"         \\\"iter\\\"         \\\"ifault\\\"\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"An important part in machine learning is understanding your results. In the case of clustering, visualization is key to interpretation! One way to achieve this is by plotting the features of the cars and coloring the points based on their corresponding cluster.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"In this exercise you'll summarize your results in a comprehensive figure. The dataset cars is already available in your workspace; the code to perform the clustering is already available.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# The cars data frame is pre-loaded\\n>\\n# Set random seed. Don't remove this line\\n> set.seed(1)\\n>\\n# Group the dataset into two clusters: km_cars\\n> km_cars <- kmeans(cars, 2)\\n>\\n# Add code: color the points in the plot based on the clusters\\n> plot(cars, col=km_cars$cluster)\\n>\\n# Print out the cluster centroids\\n> km_cars$centers\\n        wt        hp\\n1 2.692000  99.47368\\n2 3.984923 215.69231\\n>\\n# Replace the ___ part: add the centroids to the plot\\n> points(km_cars$centers, pch = 22, bg = c(1, 2), cex = 2)\\n\")),React.createElement(\"div\",{id:\"performance\"}),React.createElement(MDXTag,{name:\"hr\",components:components}),React.createElement(MDXTag,{name:\"h2\",components:components,props:{\"id\":\"performance-measures\"}},\"Performance Measures\"),React.createElement(MDXTag,{name:\"p\",components:components},\"How is our model any good? It depends on how you define performance. This could be...\"),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Accuracy\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Computation Time\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Interpretability\")),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Classification Testing\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Accuray and Error are how we can help define classification performance.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Accuray = corrct / total\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Eg. Square with 2 features. If each square can be coloured/not coloured (binary classification problem)\"),React.createElement(MDXTag,{name:\"p\",components:components},\"If the model only classifies 3/5 correct, then that is our accuracy (60%).\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"em\",components:components,parentName:\"p\"},\"Limits of accuracy\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Confusion matrix: rows and columns with each available labels.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Each cell contains frequency of instances that are classified in a certain way.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"For a binary classifier, we have positive or negative in this case (1 or 0). Our matrix then becomes a square table of Truth vs. Prediction. TP, FN, FP, TN.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"From this we can calculation \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Precision as TP/(TP+FP)\"),\" and \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Recall is TP/(TP+FN)\"),\". Back on the square example, we can talk about which were correctly classified.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Accuracy calculation then becomes \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"(TP+TN)/sum(all squares)\"),\".\"),React.createElement(MDXTag,{name:\"p\",components:components},\"This means for the \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"rare heart disease\"),\" example, we could be looking at a recall of 0% and other results that are \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"undefined\"),\".\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Regression Testing\")),React.createElement(MDXTag,{name:\"p\",components:components},\"RMSE: Root Mean Squared Error.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Clustering Testing\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Here, we have no label info, so we need to go with distance metrics between points.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Performance measure consists of 2 elements.\"),React.createElement(MDXTag,{name:\"ol\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ol\"},\"Similarity within each cluster - we want this to be high\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ol\"},\"Similarity between clusters - we want this to be low\")),React.createElement(MDXTag,{name:\"p\",components:components},\"There are a number techniques.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Within clusters:\"),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Within sum of squares(WSS)\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Diameter\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Minimize\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Between clusters:\"),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Between cluster sum of squares (BSS)\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Intercluster distance\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Maximise\")),React.createElement(MDXTag,{name:\"p\",components:components},\"A popular index for comparing is the Dunn's index: \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"minimal intercluster distance/maximal diameter\")),React.createElement(\"div\",{id:\"perf2\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----confusion-matrix\"}},\"---- Confusion Matrix\"),React.createElement(MDXTag,{name:\"p\",components:components},\"In this exercise, a decision tree is learned on this dataset. The tree aims to predict whether a person would have survived the accident based on the variables Age, Sex and Pclass (travel class). The decision the tree makes can be deemed correct or incorrect if we know what the person's true outcome was. That is, if it's a supervised learning problem.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Since the true fate of the passengers, Survived, is also provided in titanic, you can compare it to the prediction made by the tree. As you've seen in the video, the results can be summarized in a confusion matrix. In R, you can use the table() function for this.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"In this exercise, you will only focus on assessing the performance of the decision tree. In chapter 3, you will learn how to actually build a decision tree yourself.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Note: As in the previous chapter, there are functions that have a random aspect. The set.seed() function is used to enforce reproducibility. Don't worry about it, just don't remove it!\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# The titanic dataset is already loaded into your workspace\\n>\\n# Set random seed. Don't remove this line\\n> set.seed(1)\\n>\\n# Have a look at the structure of titanic\\n> str(titanic)\\n'data.frame':   714 obs. of  4 variables:\\n $ Survived: Factor w/ 2 levels \\\"1\\\",\\\"0\\\": 2 1 1 1 2 2 2 1 1 1 ...\\n $ Pclass  : int  3 1 3 1 3 1 3 3 2 3 ...\\n $ Sex     : Factor w/ 2 levels \\\"female\\\",\\\"male\\\": 2 1 1 1 2 2 2 1 1 1 ...\\n $ Age     : num  22 38 26 35 35 54 2 27 14 4 ...\\n>\\n# A decision tree classification model is built on the data\\n> tree <- rpart(Survived ~ ., data = titanic, method = \\\"class\\\")\\n>\\n# Use the predict() method to make predictions, assign to pred\\n> pred <- predict(tree, titanic, type=\\\"class\\\")\\n>\\n# Use the table() method to make the confusion matrix\\n> table(titanic$Survived, pred)\\n   pred\\n      1   0\\n  1 212  78\\n  0  53 371\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"The confusion matrix from the last exercise provides you with the raw performance of the decision tree:\"),React.createElement(MDXTag,{name:\"p\",components:components},\"The survivors correctly predicted to have survived: true positives (TP)\\nThe deceased who were wrongly predicted to have survived: false positives (FP)\\nThe survivors who were wrongly predicted to have perished: false negatives (FN)\\nThe deceased who were correctly predicted to have perished: true negatives (TN)\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"> conf\\n\\n      1   0\\n  1 212  78\\n  0  53 371\\n# The confusion matrix is available in your workspace as conf\\n>\\n# Assign TP, FN, FP and TN using conf\\n> TP <- conf[1, 1] # this will be 212\\n> FN <- conf[1, 2] # this will be 78\\n> FP <- conf[2, 1] # fill in\\n> TN <- conf[2, 2] # fill in\\n>\\n# Calculate and print the accuracy: acc\\n> acc <- (TP + TN) / (TP + FN + FP + TN)\\n> acc\\n[1] 0.8165266\\n>\\n# Calculate and print out the precision: prec\\n> prec <- TP/(TP+FP)\\n> prec\\n[1] 0.8\\n>\\n# Calculate and print out the recall: rec\\n> rec <- TP/(TP+FN)\\n> rec\\n[1] 0.7310345\\n\")),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----calculating-the-rmse-of-air-data\"}},\"---- Calculating the RMSE of air data\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# The air dataset is already loaded into your workspace\\n>\\n# Take a look at the structure of air\\n> str(air)\\n'data.frame':   1503 obs. of  6 variables:\\n $ freq     : int  800 1000 1250 1600 2000 2500 3150 4000 5000 6300 ...\\n $ angle    : num  0 0 0 0 0 0 0 0 0 0 ...\\n $ ch_length: num  0.305 0.305 0.305 0.305 0.305 ...\\n $ velocity : num  71.3 71.3 71.3 71.3 71.3 71.3 71.3 71.3 71.3 71.3 ...\\n $ thickness: num  0.00266 0.00266 0.00266 0.00266 0.00266 ...\\n $ dec      : num  126 125 126 128 127 ...\\n>\\n# Inspect your colleague's code to build the model\\n> fit <- lm(dec ~ freq + angle + ch_length, data = air)\\n>\\n# Use the model to predict for all values: pred\\n> pred <- predict(fit)\\n>\\n# Use air$dec and pred to calculate the RMSE\\n> rmse <- sqrt((1/nrow(air)) * sum( (air$dec - pred) ^ 2))\\n>\\n# Print out rmse\\n> rmse\\n[1] 5.215778\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Using the \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"rmse\"),\" result for comparison with another result\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# Previous model\\n> fit <- lm(dec ~ freq + angle + ch_length, data = air)\\n> pred <- predict(fit)\\n> rmse <- sqrt(sum( (air$dec - pred) ^ 2) / nrow(air))\\n> rmse\\n[1] 5.215778\\n>\\n# Your colleague's more complex model\\n> fit2 <- lm(dec ~ freq + angle + ch_length + velocity + thickness, data = air)\\n>\\n# Use the model to predict for all values: pred2\\n> pred2 <- predict(fit2)\\n>\\n# Calculate rmse2\\n> rmse2 <- sqrt(sum( (air$dec - pred2) ^ 2) / nrow(air))\\n>\\n# Print out rmse2\\n> rmse2\\n[1] 4.799244\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Adding complexity seems to have caused the RMSE to decrease, from 5.216 to 4.799. But there's more going on here; perhaps adding more variables to a regression always leads to a decrease of your RMSE? There will be more on this later.\"),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----clustering-dataset-example\"}},\"---- Clustering dataset example\"),React.createElement(MDXTag,{name:\"p\",components:components},\"In the dataset seeds you can find various metrics such as area, perimeter and compactness for 210 seeds. (Source: UCIMLR). However, the seeds' labels were lost. Hence, we don't know which metrics belong to which type of seed. What we do know, is that there were three types of seeds.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"The code on the right groups the seeds into three clusters (km_seeds), but is it likely that these three clusters represent our seed types? Let's find out.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"There are two initial steps you could take:\"),React.createElement(MDXTag,{name:\"ol\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ol\"},React.createElement(MDXTag,{name:\"p\",components:components,parentName:\"li\"},\"Visualize the distribution of cluster assignments among two variables, for example length and compactness.\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ol\"},React.createElement(MDXTag,{name:\"p\",components:components,parentName:\"li\"},\"Verify if the clusters are well separated and compact. To do this, you can calculate the between and within cluster sum of squares respectively.\"))),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# The seeds dataset is already loaded into your workspace\\n>\\n# Set random seed. Don't remove this line\\n> set.seed(1)\\n>\\n# Explore the structure of the dataset\\n> str(seeds)\\n'data.frame':   210 obs. of  7 variables:\\n $ area         : num  15.3 14.9 14.3 13.8 16.1 ...\\n $ perimeter    : num  14.8 14.6 14.1 13.9 15 ...\\n $ compactness  : num  0.871 0.881 0.905 0.895 0.903 ...\\n $ length       : num  5.76 5.55 5.29 5.32 5.66 ...\\n $ width        : num  3.31 3.33 3.34 3.38 3.56 ...\\n $ asymmetry    : num  2.22 1.02 2.7 2.26 1.35 ...\\n $ groove_length: num  5.22 4.96 4.83 4.8 5.17 ...\\n>\\n# Group the seeds in three clusters\\n> km_seeds <- kmeans(seeds, 3)\\n>\\n# Color the points in the plot based on the clusters\\n> plot(length ~ compactness, data = seeds, col = km_seeds$cluster)\\n>\\n# Print out the ratio of the WSS to the BSS\\n> km_seeds$tot.withinss / km_seeds$betweenss\\n[1] 0.2762846\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"The within sum of squares is far lower than the between sum of squares. Indicating the clusters are well seperated and overall compact. This is further strengthened by the plot you made, where the clusters you made were visually distinct for these two variables. It's likely that these three clusters represent the three seed types well, even if there's no way to truly verify this.\"),React.createElement(\"div\",{id:\"sets\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----training-set-and-test-set\"}},\"---- Training Set and Test Set\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Looking at the different between supervised learning, Machine learning and other data models.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Supervised learning will have a strong predictive power. - unseen observations\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Classical statistics: model must fit data - explain or describe data\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Predictive Model - Training - \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"not\"),\" on complete dataset - training set - \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Test set\"),\" to evaluate performance of model - Sets are \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"disjoint\"),\" - NO OVERLAP - Model testing on \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"unseen\"),\" observations - Generalization!\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Split the dataset\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Assume you have a dataset with N observations: x, K features: F and Class labels: y.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"We can break this down into a training set and a test set.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"The test set are used for the observations from x(r+1).\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"When do we use this?\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Only important for supervised learning set. It would not be relevant to things like clustering where the data itself isn't labelled.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"How to split the sets?\")),React.createElement(MDXTag,{name:\"p\",components:components},\"The \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"training set\"),\" should be larger than the \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"test set\"),\". Typically a ratio of 3:1 - although this is arbitrary. The more data you use to train, the better the model. Although, we still don't want the \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"test set\"),\" to be too small!\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Wisely choose which elements you put into these sets. They should have similar distributions. Avoid a class not being in a set.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"em\",components:components,parentName:\"p\"},\"Regression and Classification\"),\" - it is always a smart idea to shuffle the data set before splitting it.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"em\",components:components,parentName:\"p\"},\"Effect of smapling\"),\" - sampling can affect performance measures. Add \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"robustness\"),\" to these measures with \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"cross-validation\"),\".\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"em\",components:components,parentName:\"p\"},\"Cross-validation\"),\" - Eg. 4-folds validation. This means the splitting the data set and doing this for 4-folds. - n-fold validation means doing this n times with each test set being 1/n large.\"),React.createElement(\"div\",{id:\"split\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----split-the-sets\"}},\"---- Split the Sets\"),React.createElement(MDXTag,{name:\"p\",components:components},\"In exercises 2 and 3 you calculated a confusion matrix to assess the tree's performance. However, the tree was built using the entire set of observations. Therefore, the confusion matrix doesn't assess the predictive power of the tree. The training set and the test set were one and the same thing: this can be improved!\"),React.createElement(MDXTag,{name:\"p\",components:components},\"First, you'll want to split the dataset into train and test sets. You'll notice that the titanic dataset is sorted on titanic$Survived , so you'll need to first shuffle the dataset in order to have a fair distribution of the output variable in each set.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"For example, you could use the following commands to shuffle a data frame df and divide it into training and test sets with a 60/40 split between the two.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"n <- nrow(df)\\nshuffled_df <- df[sample(n), ]\\ntrain_indices <- 1:round(0.6 * n)\\ntrain <- shuffled_df[train_indices, ]\\ntest_indices <- (round(0.6 * n) + 1):n\\ntest <- shuffled_df[test_indices, ]\\n\")),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# The titanic dataset is already loaded into your workspace\\n>\\n# Set random seed. Don't remove this line.\\n> set.seed(1)\\n>\\n# Shuffle the dataset, call the result shuffled\\n> n <- nrow(titanic)\\n> shuffled <- titanic[sample(n),]\\n>\\n# Split the data in train and test\\n> train_indices <- 1:round(0.7 * n)\\n> train <- shuffled[train_indices, ]\\n> test_indices <- (round(0.7 * n) + 1):n\\n> test <- shuffled[test_indices, ]\\n>\\n# Print the structure of train and test\\n> str(train)\\n'data.frame':   500 obs. of  4 variables:\\n $ Survived: Factor w/ 2 levels \\\"1\\\",\\\"0\\\": 2 2 2 1 2 1 1 1 1 2 ...\\n $ Pclass  : int  3 3 2 1 3 1 2 3 2 3 ...\\n $ Sex     : Factor w/ 2 levels \\\"female\\\",\\\"male\\\": 2 2 1 2 2 2 1 2 1 2 ...\\n $ Age     : num  32 19 44 27 7 56 48 9 29 26 ...\\n> str(test)\\n'data.frame':   214 obs. of  4 variables:\\n $ Survived: Factor w/ 2 levels \\\"1\\\",\\\"0\\\": 1 2 2 1 2 2 2 2 2 2 ...\\n $ Pclass  : int  2 3 2 2 1 1 3 3 2 3 ...\\n $ Sex     : Factor w/ 2 levels \\\"female\\\",\\\"male\\\": 1 2 2 1 2 2 2 2 2 1 ...\\n $ Age     : num  18 16 36 45 61 31 40.5 28 30 2 ...\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Time to redo the model training from before. The titanic data frame is again available in your workspace. This time, however, you'll want to build a decision tree on the training set, and next assess its predictive power on a set that has not been used for training: the test set.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"On the right, the code that splits titanic up in train and test has already been included. Also, the old code that builds a decision tree on the entire set is included. Up to you to correct it and connect the dots to get a good estimate of the model's predictive ability.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# The titanic dataset is already loaded into your workspace\\n>\\n# Set random seed. Don't remove this line.\\n> set.seed(1)\\n>\\n# Shuffle the dataset; build train and test\\n> n <- nrow(titanic)\\n> shuffled <- titanic[sample(n),]\\n> train <- shuffled[1:round(0.7 * n),]\\n> test <- shuffled[(round(0.7 * n) + 1):n,]\\n>\\n# Fill in the model that has been learned.\\n> tree <- rpart(Survived ~ ., train, method = \\\"class\\\")\\n>\\n# Predict the outcome on the test set with tree: pred\\n> pred <- predict(tree, test, type=\\\"class\\\")\\n>\\n# Calculate the confusion matrix: conf\\n> conf <- table(test$Survived, pred)\\n>\\n# Print this confusion matrix\\n> conf\\n   pred\\n      1   0\\n  1  58  31\\n  0  23 102\\n\")),React.createElement(\"div\",{id:\"xvalid\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----using-cross-validation\"}},\"---- Using Cross Validation\"),React.createElement(MDXTag,{name:\"p\",components:components},\"In this exercise, you will fold the dataset 6 times and calculate the accuracy for each fold. The mean of these accuracies forms a more robust estimation of the model's true accuracy of predicting unseen data, because it is less dependent on the choice of training and test sets.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Note: Other performance measures, such as recall or precision, could also be used here.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# Set random seed. Don't remove this line.\\n> set.seed(1)\\n>\\n# Initialize the accs vector\\n> accs <- rep(0,6)\\n>\\n> for (i in 1:6) {\\n    # These indices indicate the interval of the test set\\n    indices <- (((i-1) * round((1/6)*nrow(shuffled))) + 1):((i*round((1/6) * nrow(shuffled))))\\n\\n    # Exclude them from the train set\\n    train <- shuffled[-indices,]\\n\\n    # Include them in the test set\\n    test <- shuffled[indices,]\\n\\n    # A model is learned using each training set\\n    tree <- rpart(Survived ~ ., train, method = \\\"class\\\")\\n\\n    # Make a prediction on the test set using tree\\n    pred <- predict(tree, test, type=\\\"class\\\")\\n\\n    # Assign the confusion matrix to conf\\n    conf <- table(test$Survived, pred)\\n\\n    # Assign the accuracy of this model to the ith index in accs\\n    accs[i] <- sum(diag(conf))/sum(conf)\\n  }\\n>\\n> accs\\n[1] 0.7983193 0.7983193 0.7899160 0.8067227 0.8235294 0.7899160\\n# Print out the mean of accs\\n> mean(accs)\\n[1] 0.8011204\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"This estimate will be a more robust measure of your accuracy. It will be less susceptible to the randomness of splitting the dataset.\"),React.createElement(\"div\",{id:\"bias\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----bias-and-variance\"}},\"---- Bias and Variance\"),React.createElement(MDXTag,{name:\"p\",components:components},\"How does splitting affect the accuracy?\"),React.createElement(MDXTag,{name:\"p\",components:components},\"We use \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Bias\"),\" and \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Variance\"),\" as our keys.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"The main goal of course is \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"prediction\"),\". The \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"prediction error\"),\" can be split into the \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"reducible error\"),\" and the \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"irreducible error\"),\".\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Irreducible: noise - don't minimize!\\nReducible: error due to unfit model - this we want to minimize!\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"em\",components:components,parentName:\"p\"},\"Bias Error\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Error due to bias: wrong assumptions.\\nDifference in predictions and truth. - using models trained by specific \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"learning algorithm\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Eg. suppose you have points on a x/y map that can be fit by quadratic data. If you decide to use linear regression here, you will have a high error since you are restricting your model.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"em\",components:components,parentName:\"p\"},\"Variance Error\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Error due to variance: error due to the sampling of the \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"training set\"),\"\\nModel with high variance fits training set closely!\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Example: quadratic data.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"It may fit the model well - there will be few restrictions but high variance. If you change the training set, the model will change completely.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"em\",components:components,parentName:\"p\"},\"Bias/Variance Tradeoff\")),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"Low bias = high variance\\nLow variance = high bias\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Overfitting and Underfitting\")),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Accuracy\"),\" will depend on dataset split (train/test)\\nHigh variance will heavily depend on split.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Overfitting = model fits training set a lot better than test set\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"The model is too specific\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Underfitting = restricting the model too much\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Eg. if you need to decide if email is spam.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Email Training set - exception with 50 capital letters and 30 exclamation marks.\\n-> capital letters\\n-> exclamation marks\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Our trust set has yes to both of the above data sets are spam and not if no.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"An \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"underfit\"),\" model may mark spam if more than 10 capital letters. This is \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"too general\"),\".\"),React.createElement(\"div\",{id:\"overfit\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----overfitting-the-spam\"}},\"---- Overfitting the Spam\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# The spam filter that has been 'learned' for you\\n> spam_classifier <- function(x){\\n    prediction <- rep(NA, length(x)) # initialize prediction vector\\n    prediction[x > 4] <- 1\\n    prediction[x >= 3 & x <= 4] <- 0\\n    prediction[x >= 2.2 & x < 3] <- 1\\n    prediction[x >= 1.4 & x < 2.2] <- 0\\n    prediction[x > 1.25 & x < 1.4] <- 1\\n    prediction[x <= 1.25] <- 0\\n    return(factor(prediction, levels = c(\\\"1\\\", \\\"0\\\"))) # prediction is either 0 or 1\\n  }\\n>\\n# Apply spam_classifier to emails_full: pred_full\\n> pred_full <- spam_classifier(emails_full$avg_capital_seq)\\n>\\n# Build confusion matrix for emails_full: conf_full\\n> conf_full <- table(emails_full$spam, pred_full)\\n>\\n# Calculate the accuracy with conf_full: acc_full\\n> acc_full <- sum(diag(conf_full))/sum(conf_full)\\n>\\n# Print acc_full\\n> acc_full\\n[1] 0.6561617\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"This hard-coded classifier gave you an accuracy of around 65% on the full dataset, which is way worse than the 100% you had on the small dataset back in chapter 1. Hence, the classifier does not generalize well at all!\"),React.createElement(MDXTag,{name:\"p\",components:components},\"It's official now, the spamClassifier() from chapter 1 is bogus. It simply overfits on the emailsSmall set and, as a result, doesn't generalize to larger datasets such as emailsFull.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"So let's try something else. On average, emails with a high frequency of sequential capital letters are spam. What if you simply filtered spam based on one threshold for avgCapitalSeq?\"),React.createElement(MDXTag,{name:\"p\",components:components},\"For example, you could filter all emails with avgCapitalSeq > 4 as spam. By doing this, you increase the interpretability of the classifier and restrict its complexity. However, this increases the bias, i.e. the error due to restricting your model.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Your job is to simplify the rules of spamClassifier and calculate the accuracy for the full set emailsFull. Next, compare it to that of the small set emailsSmall, which is coded for you. Does the model generalize now?\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# The all-knowing classifier that has been learned for you\\n# You should change the code of the classifier, simplifying it\\n> spam_classifier <- function(x){\\n    prediction <- rep(NA, length(x))\\n    prediction[x > 4] <- 1\\n    prediction[x <= 4] <- 0\\n    return(factor(prediction, levels = c(\\\"1\\\", \\\"0\\\")))\\n  }\\n>\\n# conf_small and acc_small have been calculated for you\\n> conf_small <- table(emails_small$spam, spam_classifier(emails_small$avg_capital_seq))\\n> acc_small <- sum(diag(conf_small)) / sum(conf_small)\\n> acc_small\\n[1] 0.7692308\\n>\\n# Apply spam_classifier to emails_full and calculate the confusion matrix: conf_full\\n> conf_full <- table(emails_full$spam, spam_classifier(emails_full$avg_capital_seq))\\n>\\n# Calculate acc_full\\n> acc_full <- sum(diag(conf_full)) / sum(conf_full)\\n>\\n# Print acc_full\\n> acc_full\\n[1] 0.7259291\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"The model no longer fits the small dataset perfectly but it fits the big dataset better. You increased the bias on the model and caused it to generalize better over the complete dataset. While the first classifier overfits the data, an accuracy of 73% is far from satisfying for a spam filter.\"),React.createElement(\"div\",{id:\"classification\"}),React.createElement(MDXTag,{name:\"hr\",components:components}),React.createElement(MDXTag,{name:\"h2\",components:components,props:{\"id\":\"classification\"}},\"Classification\"),React.createElement(MDXTag,{name:\"p\",components:components},\"The task of automatically classifying fields given features.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Observation\"),\": vector of features, with a class.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"The classification model will automatically assign a class based on previous observations.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Binary classification\"),\": Two classes.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Multiclass classification\"),\": More than two classes.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Example\")),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"a dataset consisting of persons\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"features: age, weight and income\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"class: - binary: happy or not happy - multiclass: happy, satisfied, not happy\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"features can be numerical - height - age\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"features can be categorical - travel class\")),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Decision Trees\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Suppose you want a patient as sick or not sick (1 or 0).\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Best task would be to start asking some questions.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Eg. are they young or old?\\nIf old, have you smoked more than 10 years?\\nIf young, is the patient vaccinated against measles?\"),React.createElement(MDXTag,{name:\"p\",components:components},\"These questions will begin to form a tree.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"The tree consists of nodes and edges.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"The start of the tree is the roots and the ends are the leafs.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"There is also a parent-child relation.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"The questions on the tree are simply queries about the features.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Categorical feature\")),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Can be a feature test on itself\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"travelClass: coach, business or first\")),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Learn a tree\")),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"use a training set\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"come up with queries (feature tests) at each node\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"at each node - iterate over different feature tests - choose the best one\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"comes down to two parts - make a list - choose the best one\")),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Construct list of tests\")),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"categorical - people/categories who haven't used the test yet\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"numerical - choose feature - choose threshold for split\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"choose best feature test - more complex - use splitting criteria to decide which is the best to use - \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"li\"},\"information gain\"),\" - entropy\")),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Information Gain\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Defines how much info you gain about your training instances when you perform the split based on the feature test.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"If tests lead to nicely divided classees -> high information gain.\\nIf tests lead to scrambled classes -> low information gain.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Choose the test with the best information gain.\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"strong\",components:components,parentName:\"p\"},\"Pruning\")),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"number of nodes influences the chance of overfit.\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"restrict size - higher bias - decreases the chance of an overfit\")),React.createElement(\"div\",{id:\"classification1\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----learn-a-decision-tree\"}},\"---- Learn a Decision Tree\"),React.createElement(MDXTag,{name:\"p\",components:components},\"To test your classification skills, you can build a decision tree that uses a person's age, gender, and travel class to predict whether or not they survived the Titanic. The titanic data frame has already been divided into training and test sets (named train and test).\"),React.createElement(MDXTag,{name:\"p\",components:components},\"In this exercise, you'll need train to build a decision tree. You can use the rpart() function of the rpart package for this. Behind the scenes, it performs the steps that Vincent explained in the video: coming up with possible feature tests and building a tree with the best of these tests.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Finally, a fancy plot can help you interpret the tree. You will need the rattle, rpart.plot, and RColorBrewer packages to display this.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# The train and test set are loaded into your workspace.\\n>\\n# Set random seed. Don't remove this line\\n> set.seed(1)\\n>\\n# Load the rpart, rattle, rpart.plot and RColorBrewer package\\n> library(rpart)\\n> library(rattle)\\n> library(rpart.plot)\\n> library(RColorBrewer)\\n>\\n# Fill in the ___, build a tree model: tree\\n> tree <- rpart(Survived ~ ., train, method=\\\"class\\\")\\n>\\n# Draw the decision tree - this in the console generates the decision tree\\n> fancyRpartPlot(tree)\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Remember how Vincent told you that a tree is learned by separating the training set step-by-step? In an ideal world, the separations lead to subsets that all have the same class. In reality, however, each division will contain both positive and negative training observations. In this node, 76% of the training instances are positive and 24% are negative. The majority class thus is positive, or 1, which is signaled by the number 1 on top. The 36% bit tells you which percentage of the entire training set passes through this particular node. On each tree level, these percentages thus sum up to 100%. Finally, the Pclass = 1,2 bit specifies the feature test on which this node will be separated next. If the test comes out positive, the left branch is taken; if it's negative, the right branch is taken.\"),React.createElement(\"div\",{id:\"classification2\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----classify-with-the-decision-tree\"}},\"---- Classify with the Decision Tree\"),React.createElement(MDXTag,{name:\"p\",components:components},\"The previous learning step involved proposing different tests on which to split nodes and then to select the best tests using an appropriate splitting criterion. You were spared from all the implementation hassles that come with that: the rpart() function did all of that for you.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Now you are going to classify the instances that are in the test set. As before, the data frames titanic, train and test are available in your workspace. You'll only want to work with the test set, though.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# The train and test set are loaded into your workspace.\\n>\\n# Code from previous exercise\\n> set.seed(1)\\n> library(rpart)\\n> tree <- rpart(Survived ~ ., train, method = \\\"class\\\")\\n>\\n# Predict the values of the test set: pred\\n> pred <- predict(tree, test, type=\\\"class\\\")\\n>\\n# Construct the confusion matrix: conf\\n> conf <- table(test$Survived, pred)\\n>\\n# Print out the accuracy\\n> sum(diag(conf)) / sum(conf)\\n[1] 0.7990654\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Looking good! What does the accuracy tell you? Around 80 percent of all test instances have been classified correctly. That's not bad!\"),React.createElement(\"div\",{id:\"classification3\"}),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----pruning-the-tree\"}},\"---- Pruning the Tree\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# Calculation of a complex tree\\n> set.seed(1)\\n> tree <- rpart(Survived ~ ., train, method = \\\"class\\\", control = rpart.control(cp=0.00001))\\n>\\n# Draw the complex tree\\n> fancyRpartPlot(tree)\\n>\\n# Prune the tree: pruned\\n> pruned <- prune(tree, cp=0.01)\\n>\\n# Draw pruned\\n> fancyRpartPlot(pruned)\\n\")),React.createElement(MDXTag,{name:\"p\",components:components},\"Another way to check if you overfit your model is by comparing the accuracy on the training set with the accuracy on the test set. You'd see that the difference between those two is smaller for the simpler tree. You can also set the \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"cp\"),\" argument while learning the tree with \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"rpart()\"),\" using \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"rpart.control\"),\".\"),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----gini-criterion\"}},\"---- Gini Criterion\"),React.createElement(MDXTag,{name:\"p\",components:components},React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"rpart\"),\" by default uses the \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"Gini Criterion\"),\" for making decision trees.\"),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# Set random seed. Don't remove this line.\\n> set.seed(1)\\n>\\n# Train and test tree with gini criterion\\n> tree_g <- rpart(spam ~ ., train, method = \\\"class\\\")\\n> pred_g <- predict(tree_g, test, type = \\\"class\\\")\\n> conf_g <- table(test$spam, pred_g)\\n> acc_g <- sum(diag(conf_g)) / sum(conf_g)\\n>\\n# Change the first line of code to use information gain as splitting criterion\\n> tree_i <- rpart(spam ~ ., train, method = \\\"class\\\", parms = list(split = \\\"information\\\"))\\n> pred_i <- predict(tree_i, test, type = \\\"class\\\")\\n> conf_i <- table(test$spam, pred_i)\\n> acc_i <- sum(diag(conf_i)) / sum(conf_i)\\n>\\n# Draw a fancy plot of both tree_g and tree_i\\n> fancyRpartPlot(tree_g)\\n> fancyRpartPlot(tree_i)\\n>\\n>\\n# Print out acc_g and acc_i\\n> acc_i\\n[1] 0.8963768\\n> acc_g\\n[1] 0.8905797\\n\")),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----k-nearest-neighbors\"}},\"---- k-Nearest Neighbors\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Getting acquinted with instance based learning.\"),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Save training set in memory\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"No real model like \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"li\"},\"decision tree\")),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"li\"},\"Compare\"),\" unseen instances to training set\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"li\"},\"Predict\"),\" using the \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"li\"},\"comparison\"),\" of \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"li\"},\"unseen data\"),\" and the \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"li\"},\"training set\"))),React.createElement(MDXTag,{name:\"p\",components:components},\"k-Nearest Neighbour example\"),React.createElement(MDXTag,{name:\"p\",components:components},\"2 features: x1, x2\"),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"all have red or blue class - binary classification problem\")),React.createElement(MDXTag,{name:\"p\",components:components},\"This will save the complete training set\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Given unseen observation with features, it will compare the new features with the old training set. It will find the closest observation and assign the same class.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"This is essentially a Euclidian distance measurement.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"That is for k = 1.\"),React.createElement(MDXTag,{name:\"p\",components:components},\"If k = 5, it will use the 5 most similar observations (neighbours).\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Distance metric is important. We can use the standard Euclidian Distance. We can also use the Manhattan distance:\"),React.createElement(MDXTag,{name:\"p\",components:components},\"Euclidian Distance: \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"sqr(sum((a[i]-b[i])**2))\"),\"\\nManhattan Distance: \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"p\"},\"sum(abs(a[i] - b[i]))\")),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----scaling-example\"}},\"---- Scaling Example\"),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Dataset with\",React.createElement(MDXTag,{name:\"ul\",components:components,parentName:\"li\"},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"2 features: weight and height\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"3 observations\")))),React.createElement(MDXTag,{name:\"ol\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ol\"},\"Normalize all features - eg rescale values between 0 and 1\")),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"this gives a better measurement between the distances\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"don't forget to scale the new observations accordingly\")),React.createElement(MDXTag,{name:\"ol\",components:components,props:{\"start\":2}},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ol\"},\"Categorical features\")),React.createElement(MDXTag,{name:\"ul\",components:components},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"How to use in distance metric?\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"Use \",React.createElement(MDXTag,{name:\"inlineCode\",components:components,parentName:\"li\"},\"dummy\"),\" variables\"),React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"eg mother tongue: Spanish, Italian or French.\",React.createElement(MDXTag,{name:\"ul\",components:components,parentName:\"li\"},React.createElement(MDXTag,{name:\"li\",components:components,parentName:\"ul\"},\"create new features with possible 1 or 0\")))),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"> train_labels <- train$Survived\\n> test_labels <- test$Survived\\n>\\n# Copy train and test to knn_train and knn_test\\n> knn_train <- train\\n> knn_test <- test\\n>\\n# Drop Survived column for knn_train and knn_test\\n> knn_train$Survived <- NULL\\n> knn_test$Survived <- NULL\\n>\\n# Normalize Pclass\\n> min_class <- min(knn_train$Pclass)\\n> max_class <- max(knn_train$Pclass)\\n> knn_train$Pclass <- (knn_train$Pclass - min_class) / (max_class - min_class)\\n> knn_test$Pclass <- (knn_test$Pclass - min_class) / (max_class - min_class)\\n>\\n# Normalize Age\\n> min_age <- min(knn_train$Age)\\n> max_age <- max(knn_train$Age)\\n> knn_train$Age <- (knn_train$Age - min_age) / (max_age - min_age)\\n> knn_test$Age <- (knn_test$Age - min_age) / (max_age - min_age)\\n\")),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# knn_train, knn_test, train_labels and test_labels are pre-loaded\\n>\\n# Set random seed. Don't remove this line.\\n> set.seed(1)\\n>\\n# Load the class package\\n> library(class)\\n>\\n# Fill in the ___, make predictions using knn: pred\\n> pred <- knn(train = knn_train, test = knn_test, cl = train_labels, k = 5)\\n>\\n# Construct the confusion matrix: conf\\n> conf <- table(test_labels, pred)\\n>\\n# Print out the confusion matrix\\n> conf\\n           pred\\ntest_labels   1   0\\n          1  61  24\\n          0  17 112\\n\")),React.createElement(MDXTag,{name:\"pre\",components:components},React.createElement(MDXTag,{name:\"code\",components:components,parentName:\"pre\",props:{}},\"# knn_train, knn_test, train_labels and test_labels are pre-loaded\\n>\\n# Set random seed. Don't remove this line.\\n> set.seed(1)\\n>\\n# Load the class package, define range and accs\\n> library(class)\\n> range <- 1:round(0.2 * nrow(knn_train))\\n> accs <- rep(0, length(range))\\n>\\n> for (k in range) {\\n\\n    # Fill in the ___, make predictions using knn: pred\\n    pred <- knn(train = knn_train, test = knn_test, cl = train_labels, k = k)\\n\\n    # Fill in the ___, construct the confusion matrix: conf\\n    conf <- table(test_labels, pred)\\n\\n    # Fill in the ___, calculate the accuracy and store it in accs[k]\\n    accs[k] <- sum(diag(conf)/sum(conf))\\n  }\\n>\\n# Plot the accuracies. Title of x-axis is \\\"k\\\".\\n> plot(range, accs, xlab = \\\"k\\\")\\n>\\n# Calculate the best k\\n> which.max(accs)\\n[1] 73\\n\")),React.createElement(MDXTag,{name:\"h3\",components:components,props:{\"id\":\"-----interpreting-a-voronoi-diagram\"}},\"---- Interpreting a Voronoi Diagram\"),React.createElement(MDXTag,{name:\"p\",components:components},\"A cool way to visualize how 1-Nearest Neighbor works with two-dimensional features is the Voronoi Diagram. It's basically a plot of all the training instances, together with a set of tiles around the points. This tile represents the region of influence of each point. When you want to classify a new observation, it will receive the class of the tile in which the coordinates fall. Pretty cool, right?\"),React.createElement(MDXTag,{name:\"p\",components:components},\"In the plot on the right you can see training instances that belong to either the blue or the red class. Each instance has two features: xx and yy. The top left instance, for example, has an xx value of around 0.05 and a yy value of 0.9.\"));}}]);return MDXContent;}(React.Component);export{MDXContent as default};MDXContent.__docgenInfo={\"description\":\"\",\"methods\":[],\"displayName\":\"MDXContent\"};",{"version":3,"sources":["/Users/okeeffe_d/Business/Documentation/manual/Machine-Learning/Machine-Learning-Intro.md"],"names":["React","MDXTag","MDXContent","props","layout","components","Component"],"mappings":"omFACE,MAAOA,CAAAA,KAAP,KAAkB,OAAlB,CACA,OAASC,MAAT,KAAuB,aAAvB,C,GAGmBC,CAAAA,U,gFACnB,oBAAYC,KAAZ,CAAmB,4CACjB,4EAAMA,KAAN,GACA,MAAKC,MAAL,CAAc,IAAd,CAFiB,aAGlB,C,8DACQ,iBAC0B,KAAKD,KAD/B,CACCE,UADD,aACCA,UADD,CACgBF,KADhB,sDAGP,MAAO,qBAAC,MAAD,EACE,IAAI,CAAC,SADP,CAGE,UAAU,CAAEE,UAHd,EAG0B,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,2BAAN,CAAjD,8BAH1B,CAIX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,mBAAN,CAAjD,sBAJW,CAMX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,4BAAR,CAAhE,8BAA1D,CAAuM,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EACvM,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,oBAAR,CAAhE,sBAA1D,CADuM,CAEvM,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,2BAAR,CAAhE,8BAA1D,CAAsM,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EACtM,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,8BAAR,CAAhE,gCAA1D,CADsM,CAAtM,CAFuM,CAKvM,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,uCAAR,CAAhE,2CAA1D,CAA+N,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAC/N,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,6CAAR,CAAhE,gDAA1D,CAD+N,CAE/N,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,yCAAR,CAAhE,4CAA1D,CAF+N,CAG/N,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,sDAAR,CAAhE,yDAA1D,CAH+N,CAI/N,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,kCAAR,CAAhE,qCAA1D,CAJ+N,CAK/N,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,kDAAR,CAAhE,oDAA1D,CAL+N,CAM/N,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,oDAAR,CAAhE,sDAA1D,CAN+N,CAA/N,CALuM,CAavM,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,uBAAR,CAAhE,yBAA1D,CAA6L,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAC7L,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,wBAAR,CAAhE,0BAA1D,CAD6L,CAE7L,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,wCAAR,CAAhE,0CAA1D,CAF6L,CAG7L,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,kCAAR,CAAhE,oCAA1D,CAH6L,CAI7L,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,iCAAR,CAAhE,mCAA1D,CAJ6L,CAK7L,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,sBAAR,CAAhE,wBAA1D,CAL6L,CAM7L,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,8BAAR,CAAhE,gCAA1D,CAN6L,CAO7L,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,yBAAR,CAAhE,2BAA1D,CAP6L,CAQ7L,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,4BAAR,CAAhE,8BAA1D,CAR6L,CAA7L,CAbuM,CAuBvM,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,iBAAR,CAAhE,mBAA1D,CAAiL,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EACjL,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,6BAAR,CAAhE,+BAA1D,CADiL,CAEjL,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,uCAAR,CAAhE,yCAA1D,CAFiL,CAGjL,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,wBAAR,CAAhE,0BAA1D,CAHiL,CAIjL,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,sBAAR,CAAhE,wBAA1D,CAJiL,CAKjL,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,2BAAR,CAAhE,6BAA1D,CALiL,CAMjL,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,uBAAR,CAAhE,yBAA1D,CANiL,CAOjL,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,CAAyD,KAAK,CAAE,CAAC,OAAO,sCAAR,CAAhE,wCAA1D,CAPiL,CAAjL,CAvBuM,CAAvM,CADA,CANW,CA0CX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EA1CW,CA2CX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,0BAAN,CAAjD,8BA3CW,CA4CX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,yDA5CW,CA6CX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gGA7CW,CA8CX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,mDA9CW,CA+CX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,kHA/CW,CAgDX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,2GAhDW,CAiDX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6DAjDW,CAkDX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,iFAA3C,CAlDW,CAwDX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gDAxDW,CAyDX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,oEAzDW,CA0DX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,GAArD,gBAAzC,CA1DW,CA2DX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,cAAsD,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,GAArD,uBAAtD,cA3DW,CA4DX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,mhEAA3C,CA5DW,CAyGX,2BAAK,EAAE,CAAC,YAAR,EAzGW,CA0GX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,6BAAN,CAAjD,gCA1GW,CA2GX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,iJA3GW,CA4GX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,oZA5GW,CA6GX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,qgBA7GW,CA8GX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,mtCAA3C,CA9GW,CAwIX,2BAAK,EAAE,CAAC,YAAR,EAxIW,CAyIX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EAzIW,CA0IX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,sCAAN,CAAjD,2CA1IW,CA2IX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,qDA3IW,CA4IX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,mBAAzC,CA5IW,CA6IX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,wDA7IW,CA8IX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,yBAAzC,QAAmJ,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,GAArD,aAAnJ,QAAyO,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,eAAzO,CA9IW,CA+IX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,gBAAzC,QAA0I,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,GAArD,eAA1I,QAAkO,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,UAAlO,CA/IW,CAgJX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,uDAhJW,CAiJX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,sDAjJW,CAkJX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,eAAzC,CAlJW,CAmJX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gFAnJW,CAoJX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,kHApJW,CAqJX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,eAAzC,QAAyI,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,GAArD,wBAAzI,QAA0O,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,aAA1O,CArJW,CAsJX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,iHAtJW,CAuJX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,uEAvJW,CAwJX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,eAAzC,CAxJW,CAyJX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,+BAAuE,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,YAAvE,qBAAiL,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,eAAjL,uGAzJW,CA0JX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,uCA1JW,CA2JX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,WAAmD,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,qEAAnD,CA3JW,CA4JX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6EA5JW,CA6JX,2BAAK,EAAE,CAAC,MAAR,EA7JW,CA8JX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,4CAAN,CAAjD,gDA9JW,CA+JX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gbA/JW,CAgKX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,uiBAhKW,CAiKX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,kIAjKW,CAkKX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,4vBAA3C,CAlKW,CAyLX,2BAAK,EAAE,CAAC,eAAR,EAzLW,CA0LX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,wCAAN,CAAjD,4CA1LW,CA2LX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,yXA3LW,CA4LX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,mOA5LW,CA6LX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,8gBAA3C,CA7LW,CA6MX,2BAAK,EAAE,CAAC,aAAR,EA7MW,CA8MX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,qDAAN,CAAjD,yDA9MW,CA+MX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,qTA/MW,CAgNX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,sPAhNW,CAiNX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6LAjNW,CAkNX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,uPAlNW,CAmNX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,glBAA3C,CAnNW,CAwOX,2BAAK,EAAE,CAAC,OAAR,EAxOW,CAyOX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,iCAAN,CAAjD,qCAzOW,CA0OX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,uDA1OW,CA2OX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,eAAuD,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,SAAvD,oFAA6N,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,UAA7N,iDAAiW,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,wBAAjW,KA3OW,CA4OX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,cAAzC,iGAAiO,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,0BAAjO,iHA5OW,CA6OX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,6BAAzC,CA7OW,CA8OX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,2BAAoF,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,IAA7D,YAApF,sBAAgM,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,IAA7D,cAAhM,WADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,iJAFA,CAGA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,yNAAkR,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,IAA7D,wBAAlR,CAHA,CA9OW,CAmPX,2BAAK,EAAE,CAAC,WAAR,EAnPW,CAoPX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,iDAAN,CAAjD,oDApPW,CAqPX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,4SArPW,CAsPX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gEAtPW,CAuPX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,0LAvPW,CAwPX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gSAxPW,CAyPX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,yDAzPW,CA0PX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,2pDAA3C,CA1PW,CAkSX,2BAAK,EAAE,CAAC,aAAR,EAlSW,CAmSX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,mDAAN,CAAjD,sDAnSW,CAoSX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,k5HAA3C,CApSW,CA0XX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,0QA1XW,CA2XX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gMA3XW,CA4XX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,+gBAA3C,CA5XW,CAgZX,2BAAK,EAAE,CAAC,aAAR,EAhZW,CAiZX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EAjZW,CAkZX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,sBAAN,CAAjD,yBAlZW,CAmZX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,0FAnZW,CAoZX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,aADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,qBAFA,CAGA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,qBAHA,CApZW,CAyZX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,2BAAzC,CAzZW,CA0ZX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6EA1ZW,CA2ZX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,6BAAzC,CA3ZW,CA4ZX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,4GA5ZW,CA6ZX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,+EA7ZW,CA8ZX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,GAArD,uBAAzC,CA9ZW,CA+ZX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,mEA/ZW,CAgaX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,oFAhaW,CAiaX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,iKAjaW,CAkaX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,kCAA0E,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,4BAA1E,SAAwL,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,yBAAxL,oFAlaW,CAmaX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,uCAA+E,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,6BAA/E,KAnaW,CAoaX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,wBAAgE,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,uBAAhE,+EAA+O,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,cAA/O,KApaW,CAqaX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,uBAAzC,CAraW,CAsaX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,mCAtaW,CAuaX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,uBAAzC,CAvaW,CAwaX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,wFAxaW,CAyaX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gDAzaW,CA0aX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,6DADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,yDAFA,CA1aW,CA8aX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,mCA9aW,CA+aX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,qBA/aW,CAgbX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,+BADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,aAFA,CAGA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,aAHA,CAhbW,CAqbX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,sBArbW,CAsbX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,yCADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,0BAFA,CAGA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,aAHA,CAtbW,CA2bX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,wDAAgG,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,mDAAhG,CA3bW,CA4bX,2BAAK,EAAE,CAAC,OAAR,EA5bW,CA6bX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,uBAAN,CAAjD,0BA7bW,CA8bX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,sWA9bW,CA+bX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,4QA/bW,CAgcX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,0KAhcW,CAicX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6LAjcW,CAkcX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,61BAA3C,CAlcW,CA4dX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,4GA5dW,CA6dX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,8TA7dW,CAieX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,skBAA3C,CAjeW,CA6fX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,uCAAN,CAAjD,0CA7fW,CA8fX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,q1BAA3C,CA9fW,CAuhBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,eAAuD,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,SAAvD,8CAvhBW,CAwhBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,6fAA3C,CAxhBW,CA4iBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,+OA5iBW,CA6iBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,iCAAN,CAAjD,oCA7iBW,CA8iBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gSA9iBW,CA+iBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gKA/iBW,CAgjBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gDAhjBW,CAijBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,+GADA,CADA,CAIA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,CAAyC,UAAU,CAAC,IAApD,qJADA,CAJA,CAjjBW,CAyjBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,u4BAA3C,CAzjBW,CAmlBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,mYAnlBW,CAolBX,2BAAK,EAAE,CAAC,MAAR,EAplBW,CAqlBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,gCAAN,CAAjD,mCArlBW,CAslBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,kGAtlBW,CAulBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,mFAvlBW,CAwlBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,yEAxlBW,CAylBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,mCAA2E,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,QAA3E,0CAAsM,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,aAAtM,iDAA6U,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,aAA7U,qCAAwc,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,WAAxc,mCAzlBW,CA0lBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,sBAAzC,CA1lBW,CA2lBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,yFA3lBW,CA4lBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,+DA5lBW,CA6lBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,4DA7lBW,CA8lBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,yBAAzC,CA9lBW,CA+lBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,yIA/lBW,CAgmBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,2BAAzC,CAhmBW,CAimBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,SAAiD,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,iBAAjD,+BAA0K,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,aAA1K,qJAAqZ,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,aAArZ,qBAjmBW,CAkmBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,oIAlmBW,CAmmBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,GAArD,kCAAzC,6EAnmBW,CAomBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,GAArD,uBAAzC,qDAAsL,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,eAAtL,4BAA0S,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,qBAA1S,KApmBW,CAqmBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,GAArD,qBAAzC,iLArmBW,CAsmBX,2BAAK,EAAE,CAAC,OAAR,EAtmBW,CAumBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,qBAAN,CAAjD,wBAvmBW,CAwmBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,qUAxmBW,CAymBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,kQAzmBW,CA0mBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,+JA1mBW,CA2mBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,2MAA3C,CA3mBW,CAknBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,ijCAA3C,CAlnBW,CA+oBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6RA/oBW,CAgpBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,oRAhpBW,CAipBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,2rBAA3C,CAjpBW,CA4qBX,2BAAK,EAAE,CAAC,QAAR,EA5qBW,CA6qBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,6BAAN,CAAjD,gCA7qBW,CA8qBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,4RA9qBW,CA+qBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,4FA/qBW,CAgrBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,89BAA3C,CAhrBW,CAmtBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,0IAntBW,CAotBX,2BAAK,EAAE,CAAC,MAAR,EAptBW,CAqtBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,wBAAN,CAAjD,2BArtBW,CAstBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,4CAttBW,CAutBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,YAAoD,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,SAApD,SAA+I,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,aAA/I,iBAvtBW,CAwtBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gCAAwE,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,eAAxE,UAA0K,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,qBAA1K,2BAAmS,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,oBAAnS,aAA6Y,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,sBAA7Y,KAxtBW,CAytBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,0GAztBW,CA2tBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,GAArD,eAAzC,CA3tBW,CA4tBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,oHAC0E,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,uBAD1E,CA5tBW,CA8tBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,8LA9tBW,CA+tBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,GAArD,mBAAzC,CA/tBW,CAguBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6DAAqG,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,iBAArG,yDAhuBW,CAkuBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6BAluBW,CAmuBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,oJAnuBW,CAouBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,GAArD,2BAAzC,CApuBW,CAquBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,yDAA3C,CAruBW,CAwuBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,iCAAzC,CAxuBW,CAyuBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,aAAzC,2FAzuBW,CA2uBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,qEA3uBW,CA4uBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,8BAAzC,CA5uBW,CA6uBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,kDA7uBW,CA8uBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gDA9uBW,CA+uBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,+HA/uBW,CAkvBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,iFAlvBW,CAmvBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,QAAgD,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,aAAhD,kEAAwM,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,gBAAxM,KAnvBW,CAovBX,2BAAK,EAAE,CAAC,SAAR,EApvBW,CAqvBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,2BAAN,CAAjD,8BArvBW,CAsvBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,+0BAA3C,CAtvBW,CA+wBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,+NA/wBW,CAgxBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,2LAhxBW,CAixBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6LAjxBW,CAkxBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6PAlxBW,CAmxBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,8NAnxBW,CAoxBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,w1BAA3C,CApxBW,CA6yBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,0SA7yBW,CA8yBX,2BAAK,EAAE,CAAC,gBAAR,EA9yBW,CA+yBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EA/yBW,CAgzBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,gBAAN,CAAjD,mBAhzBW,CAizBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,iEAjzBW,CAkzBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,gBAAzC,uCAlzBW,CAmzBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,+FAnzBW,CAozBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,0BAAzC,kBApzBW,CAqzBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,8BAAzC,4BArzBW,CAszBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,YAAzC,CAtzBW,CAuzBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,oCADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,qCAFA,CAGA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,kFAHA,CAIA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,6CAJA,CAKA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,+CALA,CAvzBW,CA8zBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,mBAAzC,CA9zBW,CA+zBX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6DA/zBW,CAg0BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,uDAh0BW,CAi0BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,kIAj0BW,CAo0BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,+CAp0BW,CAq0BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,0CAr0BW,CAs0BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,mEAt0BW,CAu0BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,2CAv0BW,CAw0BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,qEAx0BW,CAy0BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,wBAAzC,CAz0BW,CA00BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,oCADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,0CAFA,CA10BW,CA80BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,iBAAzC,CA90BW,CA+0BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,uBADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,sDAFA,CAGA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,8EAHA,CAIA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,gEAJA,CA/0BW,CAq1BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,4BAAzC,CAr1BW,CAs1BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,kEADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,4DAFA,CAGA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,2GAAoK,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,IAA7D,qBAApK,cAHA,CAt1BW,CA21BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,qBAAzC,CA31BW,CA41BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,uHA51BW,CA61BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,oIA71BW,CA+1BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,oDA/1BW,CAg2BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,QAAb,CAAsB,UAAU,CAAEA,UAAlC,CAA8C,UAAU,CAAC,GAAzD,YAAzC,CAh2BW,CAi2BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,sDADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,qEAFA,CAj2BW,CAq2BX,2BAAK,EAAE,CAAC,iBAAR,EAr2BW,CAs2BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,4BAAN,CAAjD,+BAt2BW,CAu2BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,kRAv2BW,CAw2BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,wSAx2BW,CAy2BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,4IAz2BW,CA02BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,keAA3C,CA12BW,CA23BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,0yBA33BW,CA43BX,2BAAK,EAAE,CAAC,iBAAR,EA53BW,CA63BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,sCAAN,CAAjD,yCA73BW,CA83BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6RA93BW,CA+3BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,kNA/3BW,CAg4BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,sbAA3C,CAh4BW,CAi5BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,2IAj5BW,CAk5BX,2BAAK,EAAE,CAAC,iBAAR,EAl5BW,CAm5BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,uBAAN,CAAjD,0BAn5BW,CAo5BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,mTAA3C,CAp5BW,CAi6BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,8OAAsR,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,OAAtR,2CAAiZ,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,YAAjZ,WAAif,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,kBAAjf,KAj6BW,CAk6BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,qBAAN,CAAjD,wBAl6BW,CAm6BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,EAAyC,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,UAAzC,yBAAqJ,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,mBAArJ,+BAn6BW,CAo6BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,+xBAA3C,CAp6BW,CA87BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,0BAAN,CAAjD,6BA97BW,CA+7BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,oDA/7BW,CAg8BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,gCADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,wBAAiF,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,IAA7D,kBAAjF,CAFA,CAGA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,IAA7D,YAA1D,qCAHA,CAIA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAA0D,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,IAA7D,YAA1D,eAA+J,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,IAA7D,eAA/J,QAAgQ,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,IAA7D,gBAAhQ,aAAuW,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,IAA7D,iBAAvW,CAJA,CAh8BW,CAs8BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,gCAt8BW,CAu8BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,uBAv8BW,CAw8BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,+DADA,CAx8BW,CA28BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,6CA38BW,CA48BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,wKA58BW,CA68BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,0DA78BW,CA88BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,uBA98BW,CA+8BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,wEA/8BW,CAg9BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,sHAh9BW,CAi9BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,yBAAiE,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,6BAAjE,0BACsB,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,GAA7D,0BADtB,CAj9BW,CAm9BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,sBAAN,CAAjD,yBAn9BW,CAo9BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,iBAA0E,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAC1E,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,kCAD0E,CAE1E,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,mBAF0E,CAA1E,CADA,CAp9BW,CA09BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,+DADA,CA19BW,CA69BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,0DADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,2DAFA,CA79BW,CAi+BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,QAAQ,CAAT,CAAjD,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,yBADA,CAj+BW,CAo+BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,EACA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,mCADA,CAEA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,SAAkE,oBAAC,MAAD,EAAQ,IAAI,CAAC,YAAb,CAA0B,UAAU,CAAEA,UAAtC,CAAkD,UAAU,CAAC,IAA7D,UAAlE,cAFA,CAGA,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,kDAA2G,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,EAC3G,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,UAAU,CAAC,IAArD,6CAD2G,CAA3G,CAHA,CAp+BW,CA2+BX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,mvBAA3C,CA3+BW,CAkgCX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,ugBAA3C,CAlgCW,CAuhCX,oBAAC,MAAD,EAAQ,IAAI,CAAC,KAAb,CAAmB,UAAU,CAAEA,UAA/B,EAA2C,oBAAC,MAAD,EAAQ,IAAI,CAAC,MAAb,CAAoB,UAAU,CAAEA,UAAhC,CAA4C,UAAU,CAAC,KAAvD,CAA6D,KAAK,CAAE,EAApE,uyBAA3C,CAvhCW,CAojCX,oBAAC,MAAD,EAAQ,IAAI,CAAC,IAAb,CAAkB,UAAU,CAAEA,UAA9B,CAA0C,KAAK,CAAE,CAAC,KAAK,qCAAN,CAAjD,wCApjCW,CAqjCX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,sZArjCW,CAsjCX,oBAAC,MAAD,EAAQ,IAAI,CAAC,GAAb,CAAiB,UAAU,CAAEA,UAA7B,kPAtjCW,CAAP,CAwjCD,C,wBAhkCqCL,KAAK,CAACM,S,SAAzBJ,U","sourcesContent":["\n  import React from 'react'\n  import { MDXTag } from '@mdx-js/tag'\n  \n\nexport default class MDXContent extends React.Component {\n  constructor(props) {\n    super(props)\n    this.layout = null\n  }\n  render() {\n    const { components, ...props } = this.props\n\n    return <MDXTag\n             name=\"wrapper\"\n             \n             components={components}><MDXTag name=\"h1\" components={components} props={{\"id\":\"intro-to-machine-learning\"}}>{`Intro to Machine Learning`}</MDXTag>\n<MDXTag name=\"h2\" components={components} props={{\"id\":\"table-of-contents\"}}>{`Table of Contents`}</MDXTag>\n{/* TOC */}\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#intro-to-machine-learning\"}}>{`Intro to Machine Learning`}</MDXTag><MDXTag name=\"ul\" components={components} parentName=\"li\">\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#table-of-contents\"}}>{`Table of Contents`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#what-is-machine-learning\"}}>{`What is Machine Learning?`}</MDXTag><MDXTag name=\"ul\" components={components} parentName=\"li\">\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----basic-model-prediction\"}}>{`---- Basic Model Prediction`}</MDXTag></MDXTag>\n</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#classification-regression-clustering\"}}>{`Classification, Regression, Clustering`}</MDXTag><MDXTag name=\"ul\" components={components} parentName=\"li\">\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----classification-example-filtering-spam\"}}>{`---- Classification Example: Filtering Spam`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----regression-example-linkedin-views\"}}>{`---- Regression Example: LinkedIn Views`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----clustering-example-separating-the-iris-species\"}}>{`---- Clustering Example: Separating the Iris Species`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----supervised-vs-unsupervised\"}}>{`---- Supervised vs. Unsupervised`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----getting-practical-with-supervised-learning\"}}>{`---- Getting practical with supervised learning`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----getting-practical-with-unsupervised-learning\"}}>{`---- Getting practical with unsupervised learning`}</MDXTag></MDXTag>\n</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#performance-measures\"}}>{`Performance Measures`}</MDXTag><MDXTag name=\"ul\" components={components} parentName=\"li\">\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----confusion-matrix\"}}>{`---- Confusion Matrix`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----calculating-the-rmse-of-air-data\"}}>{`---- Calculating the RMSE of air data`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----clustering-dataset-example\"}}>{`---- Clustering dataset example`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----training-set-and-test-set\"}}>{`---- Training Set and Test Set`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----split-the-sets\"}}>{`---- Split the Sets`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----using-cross-validation\"}}>{`---- Using Cross Validation`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----bias-and-variance\"}}>{`---- Bias and Variance`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----overfitting-the-spam\"}}>{`---- Overfitting the Spam`}</MDXTag></MDXTag>\n</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#classification\"}}>{`Classification`}</MDXTag><MDXTag name=\"ul\" components={components} parentName=\"li\">\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----learn-a-decision-tree\"}}>{`---- Learn a Decision Tree`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----classify-with-the-decision-tree\"}}>{`---- Classify with the Decision Tree`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----pruning-the-tree\"}}>{`---- Pruning the Tree`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----gini-criterion\"}}>{`---- Gini Criterion`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----k-nearest-neighbors\"}}>{`---- k-Nearest Neighbors`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----scaling-example\"}}>{`---- Scaling Example`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#-----interpreting-a-voronoi-diagram\"}}>{`---- Interpreting a Voronoi Diagram`}</MDXTag></MDXTag>\n</MDXTag></MDXTag>\n</MDXTag></MDXTag>\n</MDXTag>\n{/* /TOC */}\n<MDXTag name=\"hr\" components={components}></MDXTag>\n<MDXTag name=\"h2\" components={components} props={{\"id\":\"what-is-machine-learning\"}}>{`What is Machine Learning?`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Construction/use of algorithms that learn from data.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`We decide that it can learn when it has higher performance after learning more information.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Example: label squares based on size and edge.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`If some squares were, however, solved by people - then these instances can be used to give an informed reply.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`For input knowledge, we can use pre-labeled squares that may give us an indication of which way to go.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`We can make ground on this by constructing a data frame.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`These can be used in R to get more information.\n\ndim()\nstr()\nsummary()\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`The goal is to build models for prediction.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`We can use things like regression to help predict these things.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"em\" components={components} parentName=\"p\">{`Formulation`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Input -> `}<MDXTag name=\"em\" components={components} parentName=\"p\">{`Estimated Function`}</MDXTag>{` -> Output`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# Reveal number of observations and variables in two different ways\n> str(iris)\n'data.frame':   150 obs. of  5 variables:\n \\$ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n \\$ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n \\$ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n \\$ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n \\$ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n> dim(iris)\n[1] 150   5\n>\n>\n# Show first and last observations in the iris data set\n> head(iris)\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n> tail(iris)\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n145          6.7         3.3          5.7         2.5 virginica\n146          6.7         3.0          5.2         2.3 virginica\n147          6.3         2.5          5.0         1.9 virginica\n148          6.5         3.0          5.2         2.0 virginica\n149          6.2         3.4          5.4         2.3 virginica\n150          5.9         3.0          5.1         1.8 virginica\n>\n>\n# Summarize the iris data set\n> summary(iris)\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width\n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n`}</MDXTag></MDXTag>\n<div id=\"subsection\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----basic-model-prediction\"}}>{`---- Basic Model Prediction`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`You'll be working with the Wage dataset. It contains the wage and some general information for workers in the mid-Atlantic region of the US.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`As we briefly discussed in the video, there could be a relationship between a worker's age and his wage. Older workers tend to have more experience on average than their younger counterparts, hence you could expect an increasing trend in wage as workers age. So we built a linear regression model for you, using lm(): lm_wage. This model predicts the wage of a worker based only on the worker's age.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`With this linear model lm_wage, which is built with data that contain information on workers' age and their corresponding wage, you can predict the wage of a worker given the age of that worker. For example, suppose you want to predict the wage of a 60 year old worker. You can use the predict() function for this. This generic function takes a model as the first argument. The second argument should be some unseen observations as a data frame. predict() is then able to predict outcomes for these observations.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`> str(Wage)\n'data.frame':   3000 obs. of  12 variables:\n \\$ year      : int  2006 2004 2003 2003 2005 2008 2009 2008 2006 2004 ...\n \\$ age       : int  18 24 45 43 50 54 44 30 41 52 ...\n \\$ sex       : Factor w/ 2 levels \"1. Male\",\"2. Female\": 1 1 1 1 1 1 1 1 1 1 ...\n \\$ maritl    : Factor w/ 5 levels \"1. Never Married\",..: 1 1 2 2 4 2 2 1 1 2 ...\n \\$ race      : Factor w/ 4 levels \"1. White\",\"2. Black\",..: 1 1 1 3 1 1 4 3 2 1 ...\n \\$ education : Factor w/ 5 levels \"1. < HS Grad\",..: 1 4 3 4 2 4 3 3 3 2 ...\n \\$ region    : Factor w/ 9 levels \"1. New England\",..: 2 2 2 2 2 2 2 2 2 2 ...\n \\$ jobclass  : Factor w/ 2 levels \"1. Industrial\",..: 1 2 1 2 2 2 1 2 2 2 ...\n \\$ health    : Factor w/ 2 levels \"1. <=Good\",\"2. >=Very Good\": 1 2 1 2 1 2 2 1 2 2 ...\n \\$ health_ins: Factor w/ 2 levels \"1. Yes\",\"2. No\": 2 2 1 1 1 1 1 1 1 1 ...\n \\$ logwage   : num  4.32 4.26 4.88 5.04 4.32 ...\n \\$ wage      : num  75 70.5 131 154.7 75 ...\n>\n# Build Linear Model: lm_wage (coded already)\n> lm_wage <- lm(wage ~ age, data = Wage)\n>\n# Define data.frame: unseen (coded already)\n> unseen <- data.frame(age = 60)\n>\n# Predict the wage for a 60-year old worker\n> predict(lm_wage, unseen)\n       1\n124.1413\n`}</MDXTag></MDXTag>\n<div id=\"newSection\"></div>\n<MDXTag name=\"hr\" components={components}></MDXTag>\n<MDXTag name=\"h2\" components={components} props={{\"id\":\"classification-regression-clustering\"}}>{`Classification, Regression, Clustering`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`These are the three common types of ML Problems.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Classification`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Predicting category through historical classifying.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Earlier Observations`}</MDXTag>{` -> `}<MDXTag name=\"em\" components={components} parentName=\"p\">{`estimate`}</MDXTag>{` -> `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`CLASSIFIER`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Unseen Data`}</MDXTag>{` -> `}<MDXTag name=\"em\" components={components} parentName=\"p\">{`CLASSIFIER`}</MDXTag>{` -> `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Class`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Application: Medical Diagnosis, Animal Recognition`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Important: Qualitative Output, Predefined Classes`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Regression`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`We are trying to estimate a function that will render the correct response.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Eg. knowing height and weight, is there a relationship? Is it linear? Can we predict a height given a weight?`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`PREDICTORS`}</MDXTag>{` -> `}<MDXTag name=\"em\" components={components} parentName=\"p\">{`Regression Function`}</MDXTag>{` -> `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`RESPONSE`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Application: Modelling Payments for Credit Scores, YouTube Subscriptions over time, Job dependent on Grades.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Important: Quantitative Output, previous input-output observations`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Clustering`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Grouping objects that are `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`similar`}</MDXTag>{` in clusters and `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`dissimilar`}</MDXTag>{` between clusters. It's like classification without saying which class an object need to relate to.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Eg. Grouping similar animal photos`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`There `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`no labels, no right or wrong, and plenty of possible clusterings`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Another example is k-Means can do things like cluster in similar groups.`}</MDXTag>\n<div id=\"spam\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----classification-example-filtering-spam\"}}>{`---- Classification Example: Filtering Spam`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In the following exercise you'll work with the dataset emails, which is loaded in your workspace (Source: UCI Machine Learning Repository). Here, several emails have been labeled by humans as spam (1) or not spam (0) and the results are found in the column spam. The considered feature in emails to predict whether it was spam or not is avgCapitalSeq. It is the average amount of sequential capital letters found in each email.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In the code, you'll find a crude spam filter we built for you, spamClassifier() that uses avgCapitalSeq to predict whether an email is spam or not. In the function definition, it's important to realize that x refers to avgCapitalSeq. So where the avgCapitalSeq is greater than 4, spamClassifier() predicts the email is spam (1), if avgCapitalSeq is inclusively between 3 and 4, it predicts not spam (0), and so on. This classifier's methodology of predicting whether an email is spam or not seems pretty random, but let's see how it does anyways!`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Your job is to inspect the emails dataset, apply spamClassifier to it, and compare the predicted labels with the true labels.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# Show the dimensions of emails\n> dim(emails)\n[1] 13  2\n>\n# Inspect definition of spam_classifier()\n> spam_classifier <- function(x){\n    prediction <- rep(NA, length(x)) # initialize prediction vector\n    prediction[x > 4] <- 1\n    prediction[x >= 3 & x <= 4] <- 0\n    prediction[x >= 2.2 & x < 3] <- 1\n    prediction[x >= 1.4 & x < 2.2] <- 0\n    prediction[x > 1.25 & x < 1.4] <- 1\n    prediction[x <= 1.25] <- 0\n    return(prediction) # prediction is either 0 or 1\n  }\n>\n# Apply the classifier to the avgCapitalSeq column: spam_pred\n> spamPred <- sapply(emails\\$avgCapitalSeq, spamClassifier)\n>\n# Compare spam_pred to emails\\$spam. Use ==\n> spam_pred == emails\\$spam\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n`}</MDXTag></MDXTag>\n<div id=\"linkedinviews\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----regression-example-linkedin-views\"}}>{`---- Regression Example: LinkedIn Views`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`It's time for you to make another prediction with regression! More precisely, you'll analyze the number of views of your LinkedIn profile. With your growing network and your data science skills improving daily, you wonder if you can predict how often your profile will be visited in the future based on the number of days it's been since you created your LinkedIn account.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The instructions will help you predict the number of profile views for the next 3 days, based on the views for the past 3 weeks. The linkedin vector, which contains this information, is already available in your workspace.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# linkedin is already available in your workspace\n>\n# Create the days vector\n> days <- c(seq(1:21))\n>\n# Fit a linear model called on the linkedin views per day: linkedin_lm\n> linkedin_lm <- lm(linkedin ~ days)\n>\n# Predict the number of views for the next three days: linkedin_pred\n> future_days <- data.frame(days = 22:24)\n> linkedin_pred <- predict(linkedin_lm, future_days)\n>\n# Plot historical data and predictions\n> plot(linkedin ~ days, xlim = c(1, 24))\n> points(22:24, linkedin_pred, col = \"green\")\n`}</MDXTag></MDXTag>\n<div id=\"clusteriris\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----clustering-example-separating-the-iris-species\"}}>{`---- Clustering Example: Separating the Iris Species`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Last but not least, there's clustering. This technique tries to group your objects. It does this without any prior knowledge of what these groups could or should look like. For clustering, the concepts of prior knowledge and unseen observations are less meaningful than for classification and regression.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In this exercise, you'll group irises in 3 distinct clusters, based on several flower characteristics in the iris dataset. It has already been chopped up in a data frame my_iris and a vector species, as shown in the sample code on the right.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The clustering itself will be done with the kmeans() function. How the algorithm actually works, will be explained in the last chapter. For now, just try it out to gain some intuition!`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Note: In problems that have a random aspect (like this problem with kmeans()), the set.seed() function will be used to enforce reproducibility. If you fix the seed, the random numbers that are generated (e.g. in kmeans()) are always the same.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# Set random seed. Don't remove this line.\n> set.seed(1)\n>\n# Chop up iris in my_iris and species\n> my_iris <- iris[-5]\n> species <- iris\\$Species\n>\n# Perform k-means clustering on my_iris: kmeans_iris\n> kmeans_iris <- kmeans(my_iris, 3)\n>\n# Compare the actual Species to the clustering using table()\n> table(species, kmeans_iris\\$cluster)\n\nspecies       1  2  3\n  setosa     50  0  0\n  versicolor  0  2 48\n  virginica   0 36 14\n>\n# Plot Petal.Width against Petal.Length, coloring by cluster\n> plot(Petal.Length ~ Petal.Width, data = my_iris, col = kmeans_iris\\$cluster)\n`}</MDXTag></MDXTag>\n<div id=\"super\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----supervised-vs-unsupervised\"}}>{`---- Supervised vs. Unsupervised`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Classification and Regression have similar traits.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`If we can `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`find`}</MDXTag>{` function f which can be used to assign a class or value to unseen observations `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`given`}</MDXTag>{` a set of labeled observations, we call this `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Supervised Learning`}</MDXTag>{`.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Labelling`}</MDXTag>{` can be tedious and are normally done by humans. Those that don't require labels is known as `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Unsupervised Learning`}</MDXTag>{` - example being the clustering that we did before. Clustering will find group observations that are similar.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Performance of the model`}</MDXTag></MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Supervised learning - `}<MDXTag name=\"inlineCode\" components={components} parentName=\"li\">{`Compare`}</MDXTag>{` real labels with `}<MDXTag name=\"inlineCode\" components={components} parentName=\"li\">{`predicted`}</MDXTag>{` labels`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Unsupervised Learning - No real labels to compare - Techniques will be explained later down the track - Things aren't always black and white`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Semi-Supervised Learning - Mixed of unlabeled and labeled observationed - Eg clustering information and classes of labeled observations to assign a class to unlabeled observations - More labeled observations for `}<MDXTag name=\"inlineCode\" components={components} parentName=\"li\">{`supervised learning`}</MDXTag></MDXTag>\n</MDXTag>\n<div id=\"superPrac\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----getting-practical-with-supervised-learning\"}}>{`---- Getting practical with supervised learning`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In this exercise, you will use the same dataset. But instead of dropping the Species labels, you will use them do some supervised learning using recursive partitioning! Don't worry if you don't know what that is yet. Recursive partitioning (a.k.a. decision trees) will be explained in Chapter 3.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Take a look at the iris dataset, using str() and summary().`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The code that builds a supervised learning model with the rpart() function from the rpart package is already provided for you. This model trains a decision tree on the iris dataset.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Use the predict() function with the tree model as the first argument. The second argument should be a data frame containing observations of which you want to predict the label. In this case, you can use the predefined unseen data frame. The third argument should be type = \"class\".`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Simply print out the result of this prediction step.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# Set random seed. Don't remove this line.\n> set.seed(1)\n>\n# Take a look at the iris dataset\n> str(iris)\n'data.frame':   150 obs. of  5 variables:\n \\$ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n \\$ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n \\$ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n \\$ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n \\$ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n> summary(iris)\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width\n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50\n>\n# A decision tree model has been built for you\n> tree <- rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,\n                data = iris, method = \"class\")\n>\n# A dataframe containing unseen observations\n> unseen <- data.frame(Sepal.Length = c(5.3, 7.2),\n                       Sepal.Width = c(2.9, 3.9),\n                       Petal.Length = c(1.7, 5.4),\n                       Petal.Width = c(0.8, 2.3))\n>\n# Predict the label of the unseen observations. Print out the result.\n> predict(tree, unseen, type=\"class\")\n        1         2\n   setosa virginica\nLevels: setosa versicolor virginica\n`}</MDXTag></MDXTag>\n<div id=\"unsuperPrac\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----getting-practical-with-unsupervised-learning\"}}>{`---- Getting practical with unsupervised learning`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`> head(cars)\n                     wt  hp\nMazda RX4         2.620 110\nMazda RX4 Wag     2.875 110\nDatsun 710        2.320  93\nHornet 4 Drive    3.215 110\nHornet Sportabout 3.440 175\nValiant           3.460 105\n> # The cars data frame is pre-loaded\n>\n> # Set random seed. Don't remove this line.\n> set.seed(1)\n>\n> # Explore the cars dataset\n>\n> str(cars)\n'data.frame':   32 obs. of  2 variables:\n \\$ wt: num  2.62 2.88 2.32 3.21 3.44 ...\n \\$ hp: num  110 110 93 110 175 105 245 62 95 123 ...\n> summary(cars)\n       wt              hp\n Min.   :1.513   Min.   : 52.0  \n 1st Qu.:2.581   1st Qu.: 96.5  \n Median :3.325   Median :123.0  \n Mean   :3.217   Mean   :146.7  \n 3rd Qu.:3.610   3rd Qu.:180.0  \n Max.   :5.424   Max.   :335.0  \n>\n> # Group the dataset into two clusters: km_cars\n> km_cars <- kmeans(cars, 2)\n>\n> # Print out the contents of each cluster\n> km_cars\\$cluster\n          Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive\n                  1                   1                   1                   1\n  Hornet Sportabout             Valiant          Duster 360           Merc 240D\n                  2                   1                   2                   1\n           Merc 230            Merc 280           Merc 280C          Merc 450SE\n                  1                   1                   1                   2\n         Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental\n                  2                   2                   2                   2\n  Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla\n                  2                   1                   1                   1\n      Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28\n                  1                   1                   1                   2\n   Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa\n                  2                   1                   1                   1\n     Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E\n                  2                   2                   2                   1\n\n# see km_cars in general\n> km_cars\nK-means clustering with 2 clusters of sizes 19, 13\n\nCluster means:\n        wt        hp\n1 2.692000  99.47368\n2 3.984923 215.69231\n\nClustering vector:\n          Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive\n                  1                   1                   1                   1\n  Hornet Sportabout             Valiant          Duster 360           Merc 240D\n                  2                   1                   2                   1\n           Merc 230            Merc 280           Merc 280C          Merc 450SE\n                  1                   1                   1                   2\n         Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental\n                  2                   2                   2                   2\n  Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla\n                  2                   1                   1                   1\n      Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28\n                  1                   1                   1                   2\n   Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa\n                  2                   1                   1                   1\n     Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E\n                  2                   2                   2                   1\n\nWithin cluster sum of squares by cluster:\n[1] 14085.06 27403.23\n (between_SS / total_SS =  71.5 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`An important part in machine learning is understanding your results. In the case of clustering, visualization is key to interpretation! One way to achieve this is by plotting the features of the cars and coloring the points based on their corresponding cluster.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In this exercise you'll summarize your results in a comprehensive figure. The dataset cars is already available in your workspace; the code to perform the clustering is already available.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# The cars data frame is pre-loaded\n>\n# Set random seed. Don't remove this line\n> set.seed(1)\n>\n# Group the dataset into two clusters: km_cars\n> km_cars <- kmeans(cars, 2)\n>\n# Add code: color the points in the plot based on the clusters\n> plot(cars, col=km_cars\\$cluster)\n>\n# Print out the cluster centroids\n> km_cars\\$centers\n        wt        hp\n1 2.692000  99.47368\n2 3.984923 215.69231\n>\n# Replace the ___ part: add the centroids to the plot\n> points(km_cars\\$centers, pch = 22, bg = c(1, 2), cex = 2)\n`}</MDXTag></MDXTag>\n<div id=\"performance\"></div>\n<MDXTag name=\"hr\" components={components}></MDXTag>\n<MDXTag name=\"h2\" components={components} props={{\"id\":\"performance-measures\"}}>{`Performance Measures`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`How is our model any good? It depends on how you define performance. This could be...`}</MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Accuracy`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Computation Time`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Interpretability`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Classification Testing`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Accuray and Error are how we can help define classification performance.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Accuray = corrct / total`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Eg. Square with 2 features. If each square can be coloured/not coloured (binary classification problem)`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`If the model only classifies 3/5 correct, then that is our accuracy (60%).`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"em\" components={components} parentName=\"p\">{`Limits of accuracy`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Confusion matrix: rows and columns with each available labels.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Each cell contains frequency of instances that are classified in a certain way.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`For a binary classifier, we have positive or negative in this case (1 or 0). Our matrix then becomes a square table of Truth vs. Prediction. TP, FN, FP, TN.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`From this we can calculation `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Precision as TP/(TP+FP)`}</MDXTag>{` and `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Recall is TP/(TP+FN)`}</MDXTag>{`. Back on the square example, we can talk about which were correctly classified.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Accuracy calculation then becomes `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`(TP+TN)/sum(all squares)`}</MDXTag>{`.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`This means for the `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`rare heart disease`}</MDXTag>{` example, we could be looking at a recall of 0% and other results that are `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`undefined`}</MDXTag>{`.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Regression Testing`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`RMSE: Root Mean Squared Error.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Clustering Testing`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Here, we have no label info, so we need to go with distance metrics between points.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Performance measure consists of 2 elements.`}</MDXTag>\n<MDXTag name=\"ol\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ol\">{`Similarity within each cluster - we want this to be high`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ol\">{`Similarity between clusters - we want this to be low`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"p\" components={components}>{`There are a number techniques.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Within clusters:`}</MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Within sum of squares(WSS)`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Diameter`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Minimize`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Between clusters:`}</MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Between cluster sum of squares (BSS)`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Intercluster distance`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Maximise`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"p\" components={components}>{`A popular index for comparing is the Dunn's index: `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`minimal intercluster distance/maximal diameter`}</MDXTag></MDXTag>\n<div id=\"perf2\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----confusion-matrix\"}}>{`---- Confusion Matrix`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In this exercise, a decision tree is learned on this dataset. The tree aims to predict whether a person would have survived the accident based on the variables Age, Sex and Pclass (travel class). The decision the tree makes can be deemed correct or incorrect if we know what the person's true outcome was. That is, if it's a supervised learning problem.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Since the true fate of the passengers, Survived, is also provided in titanic, you can compare it to the prediction made by the tree. As you've seen in the video, the results can be summarized in a confusion matrix. In R, you can use the table() function for this.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In this exercise, you will only focus on assessing the performance of the decision tree. In chapter 3, you will learn how to actually build a decision tree yourself.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Note: As in the previous chapter, there are functions that have a random aspect. The set.seed() function is used to enforce reproducibility. Don't worry about it, just don't remove it!`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# The titanic dataset is already loaded into your workspace\n>\n# Set random seed. Don't remove this line\n> set.seed(1)\n>\n# Have a look at the structure of titanic\n> str(titanic)\n'data.frame':   714 obs. of  4 variables:\n \\$ Survived: Factor w/ 2 levels \"1\",\"0\": 2 1 1 1 2 2 2 1 1 1 ...\n \\$ Pclass  : int  3 1 3 1 3 1 3 3 2 3 ...\n \\$ Sex     : Factor w/ 2 levels \"female\",\"male\": 2 1 1 1 2 2 2 1 1 1 ...\n \\$ Age     : num  22 38 26 35 35 54 2 27 14 4 ...\n>\n# A decision tree classification model is built on the data\n> tree <- rpart(Survived ~ ., data = titanic, method = \"class\")\n>\n# Use the predict() method to make predictions, assign to pred\n> pred <- predict(tree, titanic, type=\"class\")\n>\n# Use the table() method to make the confusion matrix\n> table(titanic\\$Survived, pred)\n   pred\n      1   0\n  1 212  78\n  0  53 371\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`The confusion matrix from the last exercise provides you with the raw performance of the decision tree:`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The survivors correctly predicted to have survived: true positives (TP)\nThe deceased who were wrongly predicted to have survived: false positives (FP)\nThe survivors who were wrongly predicted to have perished: false negatives (FN)\nThe deceased who were correctly predicted to have perished: true negatives (TN)`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`> conf\n\n      1   0\n  1 212  78\n  0  53 371\n# The confusion matrix is available in your workspace as conf\n>\n# Assign TP, FN, FP and TN using conf\n> TP <- conf[1, 1] # this will be 212\n> FN <- conf[1, 2] # this will be 78\n> FP <- conf[2, 1] # fill in\n> TN <- conf[2, 2] # fill in\n>\n# Calculate and print the accuracy: acc\n> acc <- (TP + TN) / (TP + FN + FP + TN)\n> acc\n[1] 0.8165266\n>\n# Calculate and print out the precision: prec\n> prec <- TP/(TP+FP)\n> prec\n[1] 0.8\n>\n# Calculate and print out the recall: rec\n> rec <- TP/(TP+FN)\n> rec\n[1] 0.7310345\n`}</MDXTag></MDXTag>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----calculating-the-rmse-of-air-data\"}}>{`---- Calculating the RMSE of air data`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# The air dataset is already loaded into your workspace\n>\n# Take a look at the structure of air\n> str(air)\n'data.frame':   1503 obs. of  6 variables:\n \\$ freq     : int  800 1000 1250 1600 2000 2500 3150 4000 5000 6300 ...\n \\$ angle    : num  0 0 0 0 0 0 0 0 0 0 ...\n \\$ ch_length: num  0.305 0.305 0.305 0.305 0.305 ...\n \\$ velocity : num  71.3 71.3 71.3 71.3 71.3 71.3 71.3 71.3 71.3 71.3 ...\n \\$ thickness: num  0.00266 0.00266 0.00266 0.00266 0.00266 ...\n \\$ dec      : num  126 125 126 128 127 ...\n>\n# Inspect your colleague's code to build the model\n> fit <- lm(dec ~ freq + angle + ch_length, data = air)\n>\n# Use the model to predict for all values: pred\n> pred <- predict(fit)\n>\n# Use air\\$dec and pred to calculate the RMSE\n> rmse <- sqrt((1/nrow(air)) * sum( (air\\$dec - pred) ^ 2))\n>\n# Print out rmse\n> rmse\n[1] 5.215778\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Using the `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`rmse`}</MDXTag>{` result for comparison with another result`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# Previous model\n> fit <- lm(dec ~ freq + angle + ch_length, data = air)\n> pred <- predict(fit)\n> rmse <- sqrt(sum( (air\\$dec - pred) ^ 2) / nrow(air))\n> rmse\n[1] 5.215778\n>\n# Your colleague's more complex model\n> fit2 <- lm(dec ~ freq + angle + ch_length + velocity + thickness, data = air)\n>\n# Use the model to predict for all values: pred2\n> pred2 <- predict(fit2)\n>\n# Calculate rmse2\n> rmse2 <- sqrt(sum( (air\\$dec - pred2) ^ 2) / nrow(air))\n>\n# Print out rmse2\n> rmse2\n[1] 4.799244\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Adding complexity seems to have caused the RMSE to decrease, from 5.216 to 4.799. But there's more going on here; perhaps adding more variables to a regression always leads to a decrease of your RMSE? There will be more on this later.`}</MDXTag>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----clustering-dataset-example\"}}>{`---- Clustering dataset example`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In the dataset seeds you can find various metrics such as area, perimeter and compactness for 210 seeds. (Source: UCIMLR). However, the seeds' labels were lost. Hence, we don't know which metrics belong to which type of seed. What we do know, is that there were three types of seeds.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The code on the right groups the seeds into three clusters (km_seeds), but is it likely that these three clusters represent our seed types? Let's find out.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`There are two initial steps you could take:`}</MDXTag>\n<MDXTag name=\"ol\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ol\">\n<MDXTag name=\"p\" components={components} parentName=\"li\">{`Visualize the distribution of cluster assignments among two variables, for example length and compactness.`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ol\">\n<MDXTag name=\"p\" components={components} parentName=\"li\">{`Verify if the clusters are well separated and compact. To do this, you can calculate the between and within cluster sum of squares respectively.`}</MDXTag>\n</MDXTag>\n</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# The seeds dataset is already loaded into your workspace\n>\n# Set random seed. Don't remove this line\n> set.seed(1)\n>\n# Explore the structure of the dataset\n> str(seeds)\n'data.frame':   210 obs. of  7 variables:\n \\$ area         : num  15.3 14.9 14.3 13.8 16.1 ...\n \\$ perimeter    : num  14.8 14.6 14.1 13.9 15 ...\n \\$ compactness  : num  0.871 0.881 0.905 0.895 0.903 ...\n \\$ length       : num  5.76 5.55 5.29 5.32 5.66 ...\n \\$ width        : num  3.31 3.33 3.34 3.38 3.56 ...\n \\$ asymmetry    : num  2.22 1.02 2.7 2.26 1.35 ...\n \\$ groove_length: num  5.22 4.96 4.83 4.8 5.17 ...\n>\n# Group the seeds in three clusters\n> km_seeds <- kmeans(seeds, 3)\n>\n# Color the points in the plot based on the clusters\n> plot(length ~ compactness, data = seeds, col = km_seeds\\$cluster)\n>\n# Print out the ratio of the WSS to the BSS\n> km_seeds\\$tot.withinss / km_seeds\\$betweenss\n[1] 0.2762846\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`The within sum of squares is far lower than the between sum of squares. Indicating the clusters are well seperated and overall compact. This is further strengthened by the plot you made, where the clusters you made were visually distinct for these two variables. It's likely that these three clusters represent the three seed types well, even if there's no way to truly verify this.`}</MDXTag>\n<div id=\"sets\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----training-set-and-test-set\"}}>{`---- Training Set and Test Set`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Looking at the different between supervised learning, Machine learning and other data models.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Supervised learning will have a strong predictive power. - unseen observations`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Classical statistics: model must fit data - explain or describe data`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Predictive Model - Training - `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`not`}</MDXTag>{` on complete dataset - training set - `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Test set`}</MDXTag>{` to evaluate performance of model - Sets are `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`disjoint`}</MDXTag>{` - NO OVERLAP - Model testing on `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`unseen`}</MDXTag>{` observations - Generalization!`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Split the dataset`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Assume you have a dataset with N observations: x, K features: F and Class labels: y.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`We can break this down into a training set and a test set.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The test set are used for the observations from x(r+1).`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`When do we use this?`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Only important for supervised learning set. It would not be relevant to things like clustering where the data itself isn't labelled.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`How to split the sets?`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`The `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`training set`}</MDXTag>{` should be larger than the `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`test set`}</MDXTag>{`. Typically a ratio of 3:1 - although this is arbitrary. The more data you use to train, the better the model. Although, we still don't want the `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`test set`}</MDXTag>{` to be too small!`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Wisely choose which elements you put into these sets. They should have similar distributions. Avoid a class not being in a set.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"em\" components={components} parentName=\"p\">{`Regression and Classification`}</MDXTag>{` - it is always a smart idea to shuffle the data set before splitting it.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"em\" components={components} parentName=\"p\">{`Effect of smapling`}</MDXTag>{` - sampling can affect performance measures. Add `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`robustness`}</MDXTag>{` to these measures with `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`cross-validation`}</MDXTag>{`.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"em\" components={components} parentName=\"p\">{`Cross-validation`}</MDXTag>{` - Eg. 4-folds validation. This means the splitting the data set and doing this for 4-folds. - n-fold validation means doing this n times with each test set being 1/n large.`}</MDXTag>\n<div id=\"split\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----split-the-sets\"}}>{`---- Split the Sets`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In exercises 2 and 3 you calculated a confusion matrix to assess the tree's performance. However, the tree was built using the entire set of observations. Therefore, the confusion matrix doesn't assess the predictive power of the tree. The training set and the test set were one and the same thing: this can be improved!`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`First, you'll want to split the dataset into train and test sets. You'll notice that the titanic dataset is sorted on titanic\\$Survived , so you'll need to first shuffle the dataset in order to have a fair distribution of the output variable in each set.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`For example, you could use the following commands to shuffle a data frame df and divide it into training and test sets with a 60/40 split between the two.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`n <- nrow(df)\nshuffled_df <- df[sample(n), ]\ntrain_indices <- 1:round(0.6 * n)\ntrain <- shuffled_df[train_indices, ]\ntest_indices <- (round(0.6 * n) + 1):n\ntest <- shuffled_df[test_indices, ]\n`}</MDXTag></MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# The titanic dataset is already loaded into your workspace\n>\n# Set random seed. Don't remove this line.\n> set.seed(1)\n>\n# Shuffle the dataset, call the result shuffled\n> n <- nrow(titanic)\n> shuffled <- titanic[sample(n),]\n>\n# Split the data in train and test\n> train_indices <- 1:round(0.7 * n)\n> train <- shuffled[train_indices, ]\n> test_indices <- (round(0.7 * n) + 1):n\n> test <- shuffled[test_indices, ]\n>\n# Print the structure of train and test\n> str(train)\n'data.frame':   500 obs. of  4 variables:\n \\$ Survived: Factor w/ 2 levels \"1\",\"0\": 2 2 2 1 2 1 1 1 1 2 ...\n \\$ Pclass  : int  3 3 2 1 3 1 2 3 2 3 ...\n \\$ Sex     : Factor w/ 2 levels \"female\",\"male\": 2 2 1 2 2 2 1 2 1 2 ...\n \\$ Age     : num  32 19 44 27 7 56 48 9 29 26 ...\n> str(test)\n'data.frame':   214 obs. of  4 variables:\n \\$ Survived: Factor w/ 2 levels \"1\",\"0\": 1 2 2 1 2 2 2 2 2 2 ...\n \\$ Pclass  : int  2 3 2 2 1 1 3 3 2 3 ...\n \\$ Sex     : Factor w/ 2 levels \"female\",\"male\": 1 2 2 1 2 2 2 2 2 1 ...\n \\$ Age     : num  18 16 36 45 61 31 40.5 28 30 2 ...\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Time to redo the model training from before. The titanic data frame is again available in your workspace. This time, however, you'll want to build a decision tree on the training set, and next assess its predictive power on a set that has not been used for training: the test set.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`On the right, the code that splits titanic up in train and test has already been included. Also, the old code that builds a decision tree on the entire set is included. Up to you to correct it and connect the dots to get a good estimate of the model's predictive ability.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# The titanic dataset is already loaded into your workspace\n>\n# Set random seed. Don't remove this line.\n> set.seed(1)\n>\n# Shuffle the dataset; build train and test\n> n <- nrow(titanic)\n> shuffled <- titanic[sample(n),]\n> train <- shuffled[1:round(0.7 * n),]\n> test <- shuffled[(round(0.7 * n) + 1):n,]\n>\n# Fill in the model that has been learned.\n> tree <- rpart(Survived ~ ., train, method = \"class\")\n>\n# Predict the outcome on the test set with tree: pred\n> pred <- predict(tree, test, type=\"class\")\n>\n# Calculate the confusion matrix: conf\n> conf <- table(test\\$Survived, pred)\n>\n# Print this confusion matrix\n> conf\n   pred\n      1   0\n  1  58  31\n  0  23 102\n`}</MDXTag></MDXTag>\n<div id=\"xvalid\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----using-cross-validation\"}}>{`---- Using Cross Validation`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In this exercise, you will fold the dataset 6 times and calculate the accuracy for each fold. The mean of these accuracies forms a more robust estimation of the model's true accuracy of predicting unseen data, because it is less dependent on the choice of training and test sets.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Note: Other performance measures, such as recall or precision, could also be used here.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# Set random seed. Don't remove this line.\n> set.seed(1)\n>\n# Initialize the accs vector\n> accs <- rep(0,6)\n>\n> for (i in 1:6) {\n    # These indices indicate the interval of the test set\n    indices <- (((i-1) * round((1/6)*nrow(shuffled))) + 1):((i*round((1/6) * nrow(shuffled))))\n\n    # Exclude them from the train set\n    train <- shuffled[-indices,]\n\n    # Include them in the test set\n    test <- shuffled[indices,]\n\n    # A model is learned using each training set\n    tree <- rpart(Survived ~ ., train, method = \"class\")\n\n    # Make a prediction on the test set using tree\n    pred <- predict(tree, test, type=\"class\")\n\n    # Assign the confusion matrix to conf\n    conf <- table(test\\$Survived, pred)\n\n    # Assign the accuracy of this model to the ith index in accs\n    accs[i] <- sum(diag(conf))/sum(conf)\n  }\n>\n> accs\n[1] 0.7983193 0.7983193 0.7899160 0.8067227 0.8235294 0.7899160\n# Print out the mean of accs\n> mean(accs)\n[1] 0.8011204\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`This estimate will be a more robust measure of your accuracy. It will be less susceptible to the randomness of splitting the dataset.`}</MDXTag>\n<div id=\"bias\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----bias-and-variance\"}}>{`---- Bias and Variance`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`How does splitting affect the accuracy?`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`We use `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Bias`}</MDXTag>{` and `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Variance`}</MDXTag>{` as our keys.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The main goal of course is `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`prediction`}</MDXTag>{`. The `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`prediction error`}</MDXTag>{` can be split into the `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`reducible error`}</MDXTag>{` and the `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`irreducible error`}</MDXTag>{`.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Irreducible: noise - don't minimize!\nReducible: error due to unfit model - this we want to minimize!`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"em\" components={components} parentName=\"p\">{`Bias Error`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Error due to bias: wrong assumptions.\nDifference in predictions and truth. - using models trained by specific `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`learning algorithm`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Eg. suppose you have points on a x/y map that can be fit by quadratic data. If you decide to use linear regression here, you will have a high error since you are restricting your model.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"em\" components={components} parentName=\"p\">{`Variance Error`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Error due to variance: error due to the sampling of the `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`training set`}</MDXTag>{`\nModel with high variance fits training set closely!`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Example: quadratic data.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`It may fit the model well - there will be few restrictions but high variance. If you change the training set, the model will change completely.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"em\" components={components} parentName=\"p\">{`Bias/Variance Tradeoff`}</MDXTag></MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`Low bias = high variance\nLow variance = high bias\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Overfitting and Underfitting`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Accuracy`}</MDXTag>{` will depend on dataset split (train/test)\nHigh variance will heavily depend on split.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Overfitting = model fits training set a lot better than test set`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`The model is too specific`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Underfitting = restricting the model too much`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Eg. if you need to decide if email is spam.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Email Training set - exception with 50 capital letters and 30 exclamation marks.\n-> capital letters\n-> exclamation marks`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Our trust set has yes to both of the above data sets are spam and not if no.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`An `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`underfit`}</MDXTag>{` model may mark spam if more than 10 capital letters. This is `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`too general`}</MDXTag>{`.`}</MDXTag>\n<div id=\"overfit\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----overfitting-the-spam\"}}>{`---- Overfitting the Spam`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# The spam filter that has been 'learned' for you\n> spam_classifier <- function(x){\n    prediction <- rep(NA, length(x)) # initialize prediction vector\n    prediction[x > 4] <- 1\n    prediction[x >= 3 & x <= 4] <- 0\n    prediction[x >= 2.2 & x < 3] <- 1\n    prediction[x >= 1.4 & x < 2.2] <- 0\n    prediction[x > 1.25 & x < 1.4] <- 1\n    prediction[x <= 1.25] <- 0\n    return(factor(prediction, levels = c(\"1\", \"0\"))) # prediction is either 0 or 1\n  }\n>\n# Apply spam_classifier to emails_full: pred_full\n> pred_full <- spam_classifier(emails_full\\$avg_capital_seq)\n>\n# Build confusion matrix for emails_full: conf_full\n> conf_full <- table(emails_full\\$spam, pred_full)\n>\n# Calculate the accuracy with conf_full: acc_full\n> acc_full <- sum(diag(conf_full))/sum(conf_full)\n>\n# Print acc_full\n> acc_full\n[1] 0.6561617\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`This hard-coded classifier gave you an accuracy of around 65% on the full dataset, which is way worse than the 100% you had on the small dataset back in chapter 1. Hence, the classifier does not generalize well at all!`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`It's official now, the spamClassifier() from chapter 1 is bogus. It simply overfits on the emailsSmall set and, as a result, doesn't generalize to larger datasets such as emailsFull.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`So let's try something else. On average, emails with a high frequency of sequential capital letters are spam. What if you simply filtered spam based on one threshold for avgCapitalSeq?`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`For example, you could filter all emails with avgCapitalSeq > 4 as spam. By doing this, you increase the interpretability of the classifier and restrict its complexity. However, this increases the bias, i.e. the error due to restricting your model.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Your job is to simplify the rules of spamClassifier and calculate the accuracy for the full set emailsFull. Next, compare it to that of the small set emailsSmall, which is coded for you. Does the model generalize now?`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# The all-knowing classifier that has been learned for you\n# You should change the code of the classifier, simplifying it\n> spam_classifier <- function(x){\n    prediction <- rep(NA, length(x))\n    prediction[x > 4] <- 1\n    prediction[x <= 4] <- 0\n    return(factor(prediction, levels = c(\"1\", \"0\")))\n  }\n>\n# conf_small and acc_small have been calculated for you\n> conf_small <- table(emails_small\\$spam, spam_classifier(emails_small\\$avg_capital_seq))\n> acc_small <- sum(diag(conf_small)) / sum(conf_small)\n> acc_small\n[1] 0.7692308\n>\n# Apply spam_classifier to emails_full and calculate the confusion matrix: conf_full\n> conf_full <- table(emails_full\\$spam, spam_classifier(emails_full\\$avg_capital_seq))\n>\n# Calculate acc_full\n> acc_full <- sum(diag(conf_full)) / sum(conf_full)\n>\n# Print acc_full\n> acc_full\n[1] 0.7259291\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`The model no longer fits the small dataset perfectly but it fits the big dataset better. You increased the bias on the model and caused it to generalize better over the complete dataset. While the first classifier overfits the data, an accuracy of 73% is far from satisfying for a spam filter.`}</MDXTag>\n<div id=\"classification\"></div>\n<MDXTag name=\"hr\" components={components}></MDXTag>\n<MDXTag name=\"h2\" components={components} props={{\"id\":\"classification\"}}>{`Classification`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The task of automatically classifying fields given features.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Observation`}</MDXTag>{`: vector of features, with a class.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The classification model will automatically assign a class based on previous observations.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Binary classification`}</MDXTag>{`: Two classes.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Multiclass classification`}</MDXTag>{`: More than two classes.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Example`}</MDXTag></MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`a dataset consisting of persons`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`features: age, weight and income`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`class: - binary: happy or not happy - multiclass: happy, satisfied, not happy`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`features can be numerical - height - age`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`features can be categorical - travel class`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Decision Trees`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Suppose you want a patient as sick or not sick (1 or 0).`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Best task would be to start asking some questions.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Eg. are they young or old?\nIf old, have you smoked more than 10 years?\nIf young, is the patient vaccinated against measles?`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`These questions will begin to form a tree.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The tree consists of nodes and edges.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The start of the tree is the roots and the ends are the leafs.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`There is also a parent-child relation.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The questions on the tree are simply queries about the features.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Categorical feature`}</MDXTag></MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Can be a feature test on itself`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`travelClass: coach, business or first`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Learn a tree`}</MDXTag></MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`use a training set`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`come up with queries (feature tests) at each node`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`at each node - iterate over different feature tests - choose the best one`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`comes down to two parts - make a list - choose the best one`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Construct list of tests`}</MDXTag></MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`categorical - people/categories who haven't used the test yet`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`numerical - choose feature - choose threshold for split`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`choose best feature test - more complex - use splitting criteria to decide which is the best to use - `}<MDXTag name=\"inlineCode\" components={components} parentName=\"li\">{`information gain`}</MDXTag>{` - entropy`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Information Gain`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Defines how much info you gain about your training instances when you perform the split based on the feature test.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`If tests lead to nicely divided classees -> high information gain.\nIf tests lead to scrambled classes -> low information gain.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Choose the test with the best information gain.`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"strong\" components={components} parentName=\"p\">{`Pruning`}</MDXTag></MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`number of nodes influences the chance of overfit.`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`restrict size - higher bias - decreases the chance of an overfit`}</MDXTag>\n</MDXTag>\n<div id=\"classification1\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----learn-a-decision-tree\"}}>{`---- Learn a Decision Tree`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`To test your classification skills, you can build a decision tree that uses a person's age, gender, and travel class to predict whether or not they survived the Titanic. The titanic data frame has already been divided into training and test sets (named train and test).`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In this exercise, you'll need train to build a decision tree. You can use the rpart() function of the rpart package for this. Behind the scenes, it performs the steps that Vincent explained in the video: coming up with possible feature tests and building a tree with the best of these tests.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Finally, a fancy plot can help you interpret the tree. You will need the rattle, rpart.plot, and RColorBrewer packages to display this.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# The train and test set are loaded into your workspace.\n>\n# Set random seed. Don't remove this line\n> set.seed(1)\n>\n# Load the rpart, rattle, rpart.plot and RColorBrewer package\n> library(rpart)\n> library(rattle)\n> library(rpart.plot)\n> library(RColorBrewer)\n>\n# Fill in the ___, build a tree model: tree\n> tree <- rpart(Survived ~ ., train, method=\"class\")\n>\n# Draw the decision tree - this in the console generates the decision tree\n> fancyRpartPlot(tree)\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Remember how Vincent told you that a tree is learned by separating the training set step-by-step? In an ideal world, the separations lead to subsets that all have the same class. In reality, however, each division will contain both positive and negative training observations. In this node, 76% of the training instances are positive and 24% are negative. The majority class thus is positive, or 1, which is signaled by the number 1 on top. The 36% bit tells you which percentage of the entire training set passes through this particular node. On each tree level, these percentages thus sum up to 100%. Finally, the Pclass = 1,2 bit specifies the feature test on which this node will be separated next. If the test comes out positive, the left branch is taken; if it's negative, the right branch is taken.`}</MDXTag>\n<div id=\"classification2\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----classify-with-the-decision-tree\"}}>{`---- Classify with the Decision Tree`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The previous learning step involved proposing different tests on which to split nodes and then to select the best tests using an appropriate splitting criterion. You were spared from all the implementation hassles that come with that: the rpart() function did all of that for you.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Now you are going to classify the instances that are in the test set. As before, the data frames titanic, train and test are available in your workspace. You'll only want to work with the test set, though.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# The train and test set are loaded into your workspace.\n>\n# Code from previous exercise\n> set.seed(1)\n> library(rpart)\n> tree <- rpart(Survived ~ ., train, method = \"class\")\n>\n# Predict the values of the test set: pred\n> pred <- predict(tree, test, type=\"class\")\n>\n# Construct the confusion matrix: conf\n> conf <- table(test\\$Survived, pred)\n>\n# Print out the accuracy\n> sum(diag(conf)) / sum(conf)\n[1] 0.7990654\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Looking good! What does the accuracy tell you? Around 80 percent of all test instances have been classified correctly. That's not bad!`}</MDXTag>\n<div id=\"classification3\"></div>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----pruning-the-tree\"}}>{`---- Pruning the Tree`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# Calculation of a complex tree\n> set.seed(1)\n> tree <- rpart(Survived ~ ., train, method = \"class\", control = rpart.control(cp=0.00001))\n>\n# Draw the complex tree\n> fancyRpartPlot(tree)\n>\n# Prune the tree: pruned\n> pruned <- prune(tree, cp=0.01)\n>\n# Draw pruned\n> fancyRpartPlot(pruned)\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Another way to check if you overfit your model is by comparing the accuracy on the training set with the accuracy on the test set. You'd see that the difference between those two is smaller for the simpler tree. You can also set the `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`cp`}</MDXTag>{` argument while learning the tree with `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`rpart()`}</MDXTag>{` using `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`rpart.control`}</MDXTag>{`.`}</MDXTag>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----gini-criterion\"}}>{`---- Gini Criterion`}</MDXTag>\n<MDXTag name=\"p\" components={components}><MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`rpart`}</MDXTag>{` by default uses the `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Gini Criterion`}</MDXTag>{` for making decision trees.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# Set random seed. Don't remove this line.\n> set.seed(1)\n>\n# Train and test tree with gini criterion\n> tree_g <- rpart(spam ~ ., train, method = \"class\")\n> pred_g <- predict(tree_g, test, type = \"class\")\n> conf_g <- table(test\\$spam, pred_g)\n> acc_g <- sum(diag(conf_g)) / sum(conf_g)\n>\n# Change the first line of code to use information gain as splitting criterion\n> tree_i <- rpart(spam ~ ., train, method = \"class\", parms = list(split = \"information\"))\n> pred_i <- predict(tree_i, test, type = \"class\")\n> conf_i <- table(test\\$spam, pred_i)\n> acc_i <- sum(diag(conf_i)) / sum(conf_i)\n>\n# Draw a fancy plot of both tree_g and tree_i\n> fancyRpartPlot(tree_g)\n> fancyRpartPlot(tree_i)\n>\n>\n# Print out acc_g and acc_i\n> acc_i\n[1] 0.8963768\n> acc_g\n[1] 0.8905797\n`}</MDXTag></MDXTag>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----k-nearest-neighbors\"}}>{`---- k-Nearest Neighbors`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Getting acquinted with instance based learning.`}</MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Save training set in memory`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`No real model like `}<MDXTag name=\"inlineCode\" components={components} parentName=\"li\">{`decision tree`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"inlineCode\" components={components} parentName=\"li\">{`Compare`}</MDXTag>{` unseen instances to training set`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"inlineCode\" components={components} parentName=\"li\">{`Predict`}</MDXTag>{` using the `}<MDXTag name=\"inlineCode\" components={components} parentName=\"li\">{`comparison`}</MDXTag>{` of `}<MDXTag name=\"inlineCode\" components={components} parentName=\"li\">{`unseen data`}</MDXTag>{` and the `}<MDXTag name=\"inlineCode\" components={components} parentName=\"li\">{`training set`}</MDXTag></MDXTag>\n</MDXTag>\n<MDXTag name=\"p\" components={components}>{`k-Nearest Neighbour example`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`2 features: x1, x2`}</MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`all have red or blue class - binary classification problem`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"p\" components={components}>{`This will save the complete training set`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Given unseen observation with features, it will compare the new features with the old training set. It will find the closest observation and assign the same class.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`This is essentially a Euclidian distance measurement.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`That is for k = 1.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`If k = 5, it will use the 5 most similar observations (neighbours).`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Distance metric is important. We can use the standard Euclidian Distance. We can also use the Manhattan distance:`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Euclidian Distance: `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`sqr(sum((a[i]-b[i])**2))`}</MDXTag>{`\nManhattan Distance: `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`sum(abs(a[i] - b[i]))`}</MDXTag></MDXTag>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----scaling-example\"}}>{`---- Scaling Example`}</MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Dataset with`}<MDXTag name=\"ul\" components={components} parentName=\"li\">\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`2 features: weight and height`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`3 observations`}</MDXTag>\n</MDXTag></MDXTag>\n</MDXTag>\n<MDXTag name=\"ol\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ol\">{`Normalize all features - eg rescale values between 0 and 1`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`this gives a better measurement between the distances`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`don't forget to scale the new observations accordingly`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"ol\" components={components} props={{\"start\":2}}>\n<MDXTag name=\"li\" components={components} parentName=\"ol\">{`Categorical features`}</MDXTag>\n</MDXTag>\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`How to use in distance metric?`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`Use `}<MDXTag name=\"inlineCode\" components={components} parentName=\"li\">{`dummy`}</MDXTag>{` variables`}</MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`eg mother tongue: Spanish, Italian or French.`}<MDXTag name=\"ul\" components={components} parentName=\"li\">\n<MDXTag name=\"li\" components={components} parentName=\"ul\">{`create new features with possible 1 or 0`}</MDXTag>\n</MDXTag></MDXTag>\n</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`> train_labels <- train\\$Survived\n> test_labels <- test\\$Survived\n>\n# Copy train and test to knn_train and knn_test\n> knn_train <- train\n> knn_test <- test\n>\n# Drop Survived column for knn_train and knn_test\n> knn_train\\$Survived <- NULL\n> knn_test\\$Survived <- NULL\n>\n# Normalize Pclass\n> min_class <- min(knn_train\\$Pclass)\n> max_class <- max(knn_train\\$Pclass)\n> knn_train\\$Pclass <- (knn_train\\$Pclass - min_class) / (max_class - min_class)\n> knn_test\\$Pclass <- (knn_test\\$Pclass - min_class) / (max_class - min_class)\n>\n# Normalize Age\n> min_age <- min(knn_train\\$Age)\n> max_age <- max(knn_train\\$Age)\n> knn_train\\$Age <- (knn_train\\$Age - min_age) / (max_age - min_age)\n> knn_test\\$Age <- (knn_test\\$Age - min_age) / (max_age - min_age)\n`}</MDXTag></MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# knn_train, knn_test, train_labels and test_labels are pre-loaded\n>\n# Set random seed. Don't remove this line.\n> set.seed(1)\n>\n# Load the class package\n> library(class)\n>\n# Fill in the ___, make predictions using knn: pred\n> pred <- knn(train = knn_train, test = knn_test, cl = train_labels, k = 5)\n>\n# Construct the confusion matrix: conf\n> conf <- table(test_labels, pred)\n>\n# Print out the confusion matrix\n> conf\n           pred\ntest_labels   1   0\n          1  61  24\n          0  17 112\n`}</MDXTag></MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# knn_train, knn_test, train_labels and test_labels are pre-loaded\n>\n# Set random seed. Don't remove this line.\n> set.seed(1)\n>\n# Load the class package, define range and accs\n> library(class)\n> range <- 1:round(0.2 * nrow(knn_train))\n> accs <- rep(0, length(range))\n>\n> for (k in range) {\n\n    # Fill in the ___, make predictions using knn: pred\n    pred <- knn(train = knn_train, test = knn_test, cl = train_labels, k = k)\n\n    # Fill in the ___, construct the confusion matrix: conf\n    conf <- table(test_labels, pred)\n\n    # Fill in the ___, calculate the accuracy and store it in accs[k]\n    accs[k] <- sum(diag(conf)/sum(conf))\n  }\n>\n# Plot the accuracies. Title of x-axis is \"k\".\n> plot(range, accs, xlab = \"k\")\n>\n# Calculate the best k\n> which.max(accs)\n[1] 73\n`}</MDXTag></MDXTag>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"-----interpreting-a-voronoi-diagram\"}}>{`---- Interpreting a Voronoi Diagram`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`A cool way to visualize how 1-Nearest Neighbor works with two-dimensional features is the Voronoi Diagram. It's basically a plot of all the training instances, together with a set of tiles around the points. This tile represents the region of influence of each point. When you want to classify a new observation, it will receive the class of the tile in which the coordinates fall. Pretty cool, right?`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In the plot on the right you can see training instances that belong to either the blue or the red class. Each instance has two features: xx and yy. The top left instance, for example, has an xx value of around 0.05 and a yy value of 0.9.`}</MDXTag>\n           </MDXTag>\n  }\n}\n  "]}]}