{"version":3,"sources":["webpack:///./manual/Machine-Learning/CL-Logistic-Regression.md"],"names":["MDXContent","props","_this","_classCallCheck","this","_possibleConstructorReturn","_getPrototypeOf","call","layout","React","Component","_this$props","components","_objectWithoutProperties","react__WEBPACK_IMPORTED_MODULE_0___default","a","createElement","_mdx_js_tag__WEBPACK_IMPORTED_MODULE_1__","name","id","parentName","href","className"],"mappings":"g8CAKqBA,cACnB,SAAAA,EAAYC,GAAO,IAAAC,EAAA,mGAAAC,CAAAC,KAAAJ,IACjBE,EAAAG,EAAAD,KAAAE,EAAAN,GAAAO,KAAAH,KAAMH,KACDO,OAAS,KAFGN,yPADmBO,IAAMC,kDAKnC,IAAAC,EAC0BP,KAAKH,MAA9BW,EADDD,EACCC,WADDC,EAAAF,EAAA,gBAGP,OAAOG,EAAAC,EAAAC,cAACC,EAAA,OAAD,CACEC,KAAK,UAELN,WAAYA,GAAYE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYX,MAAO,CAACkB,GAAK,uCAAvD,uCAErCL,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,GAC9BE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYQ,WAAW,MAAKN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,EAAYQ,WAAW,KAAKnB,MAAO,CAACoB,KAAO,wCAAxE,uCAAgKP,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYQ,WAAW,MAC/QN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYQ,WAAW,MAAKN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,EAAYQ,WAAW,KAAKnB,MAAO,CAACoB,KAAO,mCAAxE,iCAAqJP,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYQ,WAAW,MACpQN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYQ,WAAW,MAAKN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,EAAYQ,WAAW,KAAKnB,MAAO,CAACoB,KAAO,6BAAxE,8BAE1DP,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYQ,WAAW,MAAKN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,EAAYQ,WAAW,KAAKnB,MAAO,CAACoB,KAAO,8BAAxE,4BAA2IP,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYQ,WAAW,MAC1PN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYQ,WAAW,MAAKN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,EAAYQ,WAAW,KAAKnB,MAAO,CAACoB,KAAO,+DAAxE,8DAC1DP,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYQ,WAAW,MAAKN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,EAAYQ,WAAW,KAAKnB,MAAO,CAACoB,KAAO,6DAAxE,4DAC1DP,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYQ,WAAW,MAAKN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,EAAYQ,WAAW,KAAKnB,MAAO,CAACoB,KAAO,oDAAxE,mDAC1DP,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYQ,WAAW,MAAKN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,EAAYQ,WAAW,KAAKnB,MAAO,CAACoB,KAAO,mCAAxE,mCAC1DP,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYQ,WAAW,MAAKN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,EAAYQ,WAAW,KAAKnB,MAAO,CAACoB,KAAO,0CAAxE,0CAC1DP,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYQ,WAAW,MAAKN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,EAAYQ,WAAW,KAAKnB,MAAO,CAACoB,KAAO,uDAAxE,2DAK1DP,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYX,MAAO,CAACkB,GAAK,kCAAvD,iCACAL,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,4DAAsGE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,SAASN,WAAYA,EAAYQ,WAAW,KAAzD,QAAtG,KACAN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,iBAA2DE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,qBAA3D,KAAgKN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,8BAAhK,6BACAN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,oMACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,6XACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYX,MAAO,CAACkB,GAAK,4BAAvD,2BACAL,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,yBAAmEE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,qBAAnE,4CAA+MN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,4BAA/M,kCAAwVN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,+BAAxV,6FACAN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,MAAMN,WAAYA,GAAYE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,OAAON,WAAYA,EAAYQ,WAAW,MAAMnB,MAAO,IAApE,kDAG3Ca,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,mGACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,0DAAoGE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,kBAApG,oFAAuRN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,KAAvR,OAA8WN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,KAA9W,6DAA2fN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,KAA3f,8CAAynBN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,kBAAznB,6BAAmvBN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,gBAAnvB,KACAN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,8DACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYX,MAAO,CAACkB,GAAK,6BAAvD,4BACAL,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,oGAA8IE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,YAA9I,6BAAkQN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,OAAlQ,QAA4VN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,UAA5V,KACAN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,uHACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,MAAMN,WAAYA,GAAYE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,OAAON,WAAYA,EAAYQ,WAAW,MAAMnB,MAAO,CAACqB,UAAY,oBAAjF,2jCAuC3CR,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYX,MAAO,CAACkB,GAAK,8DAAvD,6DACAL,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,MAAMN,WAAYA,GAAYE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,OAAON,WAAYA,EAAYQ,WAAW,MAAMnB,MAAO,CAACqB,UAAY,oBAAjF,wNAM3CR,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,gDACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,MAAMN,WAAYA,GAAYE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,OAAON,WAAYA,EAAYQ,WAAW,MAAMnB,MAAO,CAACqB,UAAY,oBAAjF,6GAI3CR,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYX,MAAO,CAACkB,GAAK,4DAAvD,2DACAL,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,0BAAoEE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,oBAApE,KACAN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,MAAMN,WAAYA,GAAYE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,OAAON,WAAYA,EAAYQ,WAAW,MAAMnB,MAAO,CAACqB,UAAY,oBAAjF,yKAM3CR,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYX,MAAO,CAACkB,GAAK,mDAAvD,kDACAL,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,sDACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,MAAMN,WAAYA,GAAYE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,OAAON,WAAYA,EAAYQ,WAAW,MAAMnB,MAAO,CAACqB,UAAY,oBAAjF,o4BAmB3CR,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYX,MAAO,CAACkB,GAAK,kCAAvD,kCACAL,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,oGACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,qEACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,qMACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,uHACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYX,MAAO,CAACkB,GAAK,yCAAvD,yCACAL,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,iGAA2IE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,aAAaN,WAAYA,EAAYQ,WAAW,KAA7D,sBAA3I,sHACAN,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,6DACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,kFACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,KAAKN,WAAYA,EAAYX,MAAO,CAACkB,GAAK,sDAAvD,qDACAL,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,IAAIN,WAAYA,GAA7B,0GACAE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,MAAMN,WAAYA,GAAYE,EAAAC,EAAAC,cAACC,EAAA,OAAD,CAAQC,KAAK,OAAON,WAAYA,EAAYQ,WAAW,MAAMnB,MAAO,CAACqB,UAAY,oBAAjF","file":"static/js/manual-machine-learning-cl-logistic-regression.9261794c.js","sourcesContent":["\n  import React from 'react'\n  import { MDXTag } from '@mdx-js/tag'\n  \n\nexport default class MDXContent extends React.Component {\n  constructor(props) {\n    super(props)\n    this.layout = null\n  }\n  render() {\n    const { components, ...props } = this.props\n\n    return <MDXTag\n             name=\"wrapper\"\n             \n             components={components}><MDXTag name=\"h1\" components={components} props={{\"id\":\"classification-logistic-regression\"}}>{`Classification: Logistic Regression`}</MDXTag>\n{/* TOC */}\n<MDXTag name=\"ul\" components={components}>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#classification-logistic-regression\"}}>{`Classification: Logistic Regression`}</MDXTag><MDXTag name=\"ul\" components={components} parentName=\"li\">\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#logistic-regression-intuition\"}}>{`Logistic Regression Intuition`}</MDXTag><MDXTag name=\"ul\" components={components} parentName=\"li\">\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#the-scientific-approach\"}}>{`The scientific approach`}</MDXTag></MDXTag>\n</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#implementation-in-python\"}}>{`Implementation in Python`}</MDXTag><MDXTag name=\"ul\" components={components} parentName=\"li\">\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#fitting-the-logistic-regression-model-to-the-training-set\"}}>{`Fitting the logistic regression model to the Training Set`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#checking-the-fit-predictions-using-the-confusion-matrix\"}}>{`Checking the fit predictions using the Confusion Matrix`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#visualising-the-predictive-power-using-a-graph\"}}>{`Visualising the predictive power using a graph`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#how-do-we-interpret-the-graph\"}}>{`How do we interpret the graph?`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#what-is-the-point-of-the-classifiers\"}}>{`What is the point of the classifiers?`}</MDXTag></MDXTag>\n<MDXTag name=\"li\" components={components} parentName=\"ul\"><MDXTag name=\"a\" components={components} parentName=\"li\" props={{\"href\":\"#checking-the-results-when-applied-to-the-test-set\"}}>{`Checking the results when applied to the Test Set`}</MDXTag></MDXTag>\n</MDXTag></MDXTag>\n</MDXTag></MDXTag>\n</MDXTag>\n{/* /TOC */}\n<MDXTag name=\"h2\" components={components} props={{\"id\":\"logistic-regression-intuition\"}}>{`Logistic Regression Intuition`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`This section can be quite difficult - there will be some `}<MDXTag name=\"strong\" components={components} parentName=\"p\">{`math`}</MDXTag>{`.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`We know about `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`linear regression`}</MDXTag>{`, `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`multiple linear regression`}</MDXTag>{` etc. (DV on y, IV on x).`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`What happens if we classify things along a graph? Eg. 0 and 1 on the y axis and age on the x axis. This one is very black and white, but at the same time we can intuitive see some correlation.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In the example given above, we wouldn't use a linear model (as you could imagine). How about instead, you were able throw in probabilies between 0 and 1. The could be a probability between the x intercept and the y-intecept at x`}{`[hat]`}{`. You could interpret the above and below 100% and 0% respectively. This would be a VERY basic but sensicle attempt to describe the model.`}</MDXTag>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"the-scientific-approach\"}}>{`The scientific approach`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`If we take the linear `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`y = b[0] + b[1]*x`}</MDXTag>{` and take that into the sigmoid function `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`p = 1 / (1 + pow(e, -y))`}</MDXTag>{` and then we through that into `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`ln(p/(1-p)) = b[0] + b[1]*x`}</MDXTag>{` then we can get the y. Therefore the last equation is the one for logistical regression.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{}}>{`# MAIN FORMULA\nln(p/(1-p)) = b[0] + b[1]*x\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`Based on the above formula and plugging in the example data, we will get the best fitting line.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`If we now take any particular ages along the x axis of `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`20, 30, 40, 50`}</MDXTag>{` etc, we can then find y`}{`[hat]`}{` to get the predicted value that it will be a `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`1`}</MDXTag>{` or `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`0`}</MDXTag>{` - the higher the probability, the higher the chance of a `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`1`}</MDXTag>{`. Any probability that is less than 0.5 is `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`projected down`}</MDXTag>{` whereas anything else is `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`projected up`}</MDXTag>{`.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`After applying to model, we can start drawing conclusions.`}</MDXTag>\n<MDXTag name=\"h2\" components={components} props={{\"id\":\"implementation-in-python\"}}>{`Implementation in Python`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Using our standard setup, we want to predict whether or not we can get a correlation between the `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`purchase`}</MDXTag>{` of something using their `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`age`}</MDXTag>{` and `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`salary`}</MDXTag>{`.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`For accurate predictions, we do use feature scaling and we will also create a classification test and training set.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{\"className\":\"language-python\"}}>{`# Data Preprocessing Template\n\n# Importing the libraries\nimport sys, json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# send() for Node.js Python Shell lib\ndef send(arg, type = 0):\n    if type == 1:\n        print json.dumps(json.loads(arg))\n    elif type == 2:\n        print arg\n    else:\n        print json.dumps(arg)\n\n# Importing the dataset\ndataset = pd.read_csv('data/Social_Network_Ads.csv')\n# We jut want the estimate of purchase using the Age and Estimated Salary\nX = dataset.iloc[:, 2:4].values\ny = dataset.iloc[:, 4].values\n\nsend(X.tolist());\nsend(y.tolist());\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\n# we use this here for accurate predicition\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.fit_transform(X_test)\n\nsend(X_train.tolist());\n`}</MDXTag></MDXTag>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"fitting-the-logistic-regression-model-to-the-training-set\"}}>{`Fitting the logistic regression model to the Training Set`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{\"className\":\"language-python\"}}>{`# Fitting Logistic Regression to the Training Set\n# Create the Regressor\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state=0)\nclassifier.fit(X_train, y_train)\n`}</MDXTag></MDXTag>\n<MDXTag name=\"p\" components={components}>{`In order to make a prediction on the X_test:`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{\"className\":\"language-python\"}}>{`# y_pred will be the vector of predictions\ny_pred = classifier.predict(X_test)\nsend(y_pred.tolist())\n`}</MDXTag></MDXTag>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"checking-the-fit-predictions-using-the-confusion-matrix\"}}>{`Checking the fit predictions using the Confusion Matrix`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`We do this by making a `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`Confusion Matrix`}</MDXTag>{`.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{\"className\":\"language-python\"}}>{`# Create the confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred);\nsend(\"\\nConfusion Matrix\")\nsend(cm.tolist())\n`}</MDXTag></MDXTag>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"visualising-the-predictive-power-using-a-graph\"}}>{`Visualising the predictive power using a graph`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`There is a lot of code required to visualise this:`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{\"className\":\"language-python\"}}>{`# Visualising the Training Set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                    np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n            alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n            c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Logistical Regression Training Set')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\n# plt.savefig('logistical-regression.png')\nplt.show()\nplt.close()\n`}</MDXTag></MDXTag>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"how-do-we-interpret-the-graph\"}}>{`How do we interpret the graph?`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The red points are the training set observations for when the IV purchased = 0, and 1 for green.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`In our example, red did not buy the SUV, green are those who did.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Given the x,y axis, those with the lower salary who also didn't have red are also those who didn't but the SUV. We can see those with the higher salaries are more likely to have bought the SUV.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`Another observation is that the older above the average even with the lower salary were more likely to buy the SUV.`}</MDXTag>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"what-is-the-point-of-the-classifiers\"}}>{`What is the point of the classifiers?`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The goal is to classify the right users into the right categories. We do this by plotting the `}<MDXTag name=\"inlineCode\" components={components} parentName=\"p\">{`prediction regions`}</MDXTag>{` - in the case of the graph, it's the red prediction and the green region is where the classifier does by the SUV.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The data point is the result, the region is the estimate.`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`When we have a linear classifier, the boundary will always be a straight line.`}</MDXTag>\n<MDXTag name=\"h3\" components={components} props={{\"id\":\"checking-the-results-when-applied-to-the-test-set\"}}>{`Checking the results when applied to the Test Set`}</MDXTag>\n<MDXTag name=\"p\" components={components}>{`The results that we can see from this actually come from the same confusion matrix that we saw before.`}</MDXTag>\n<MDXTag name=\"pre\" components={components}><MDXTag name=\"code\" components={components} parentName=\"pre\" props={{\"className\":\"language-python\"}}>{`# Visualising the Test Set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                    np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n            alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n            c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Logistical Regression Test Set')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\n# plt.savefig('logistical-regression.png')\nplt.legend()\nplt.show()\nplt.close()\n`}</MDXTag></MDXTag>\n           </MDXTag>\n  }\n}\n  "],"sourceRoot":""}